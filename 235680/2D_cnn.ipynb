{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.loaders.data_loader import load_train_data, load_basic_preprocessed_train\n",
    "from src.preprocessors.preprocessors import split_train_valid_test\n",
    "\n",
    "from src.model.multiple_output.convolution import Convolution2DVarious\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict, load_submission_data\n",
    "from src.loaders.window_generator import WindowGenerator\n",
    "from src.trainers import compile_and_fit_with_pinball_loss\n",
    "\n",
    "df = load_train_data()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.08</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.06</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>71.78</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>71.75</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>75.20</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  Hour  Minute  DHI  DNI   WS     RH   T  TARGET\n",
       "0    0     0       0    0    0  1.5  69.08 -12     0.0\n",
       "1    0     0      30    0    0  1.5  69.06 -12     0.0\n",
       "2    0     1       0    0    0  1.6  71.78 -12     0.0\n",
       "3    0     1      30    0    0  1.6  71.75 -12     0.0\n",
       "4    0     2       0    0    0  1.6  75.20 -12     0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21a7acc5e08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(df[\"DHI\"] + df[\"DNI\"] * -np.cos(df[\"Hour\"] * (2 * np.pi) / 24))[0:48].plot()\n",
    "df[\"TARGET\"][0:48].plot()\n",
    "(df[\"DHI\"] + df[\"DNI\"])[0:48].plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 9), (10511, 9), (5257, 9)\n",
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 16), (10511, 16), (5257, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>GHI</th>\n",
       "      <th>TARGET_ROLLING_MEAN_3_shift_1</th>\n",
       "      <th>TARGET_ROLLING_MEAN_5_shift_2</th>\n",
       "      <th>TARGET_ROLLING_MEAN_11_shift_5</th>\n",
       "      <th>TARGET_ROLLING_MEAN_23_shift_11</th>\n",
       "      <th>TARGET_ROLLING_MEAN_47_shift_23</th>\n",
       "      <th>scaled_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>3.679000e+04</td>\n",
       "      <td>36788.000000</td>\n",
       "      <td>3.678200e+04</td>\n",
       "      <td>36770.000000</td>\n",
       "      <td>36746.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.119412</td>\n",
       "      <td>0.219731</td>\n",
       "      <td>0.201327</td>\n",
       "      <td>0.542351</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>17.439978</td>\n",
       "      <td>0.507046</td>\n",
       "      <td>0.522326</td>\n",
       "      <td>0.500206</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.267026</td>\n",
       "      <td>1.754246e-01</td>\n",
       "      <td>0.177070</td>\n",
       "      <td>1.873707e-01</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.439553</td>\n",
       "      <td>0.174550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.194232</td>\n",
       "      <td>0.330292</td>\n",
       "      <td>0.117052</td>\n",
       "      <td>0.234989</td>\n",
       "      <td>0.192822</td>\n",
       "      <td>25.449577</td>\n",
       "      <td>0.346981</td>\n",
       "      <td>0.359263</td>\n",
       "      <td>0.353558</td>\n",
       "      <td>0.353558</td>\n",
       "      <td>0.263381</td>\n",
       "      <td>2.493107e-01</td>\n",
       "      <td>0.245814</td>\n",
       "      <td>2.357692e-01</td>\n",
       "      <td>0.221299</td>\n",
       "      <td>0.223309</td>\n",
       "      <td>0.254715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.364896</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159610</td>\n",
       "      <td>0.158025</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.088432</td>\n",
       "      <td>3.356260e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.852145e-16</td>\n",
       "      <td>0.044263</td>\n",
       "      <td>0.257553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.553620</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530107</td>\n",
       "      <td>0.536539</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.088432</td>\n",
       "      <td>1.006823e-02</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>7.214131e-02</td>\n",
       "      <td>0.186432</td>\n",
       "      <td>0.416421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.160985</td>\n",
       "      <td>0.430831</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.711963</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>31.085053</td>\n",
       "      <td>0.840390</td>\n",
       "      <td>0.891488</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>3.152762e-01</td>\n",
       "      <td>0.319363</td>\n",
       "      <td>3.255759e-01</td>\n",
       "      <td>0.378674</td>\n",
       "      <td>0.613566</td>\n",
       "      <td>0.311118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.913939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DHI           DNI            WS            RH             T  \\\n",
       "count  36792.000000  36792.000000  36792.000000  36792.000000  36792.000000   \n",
       "mean       0.119412      0.219731      0.201327      0.542351      0.512100   \n",
       "std        0.194232      0.330292      0.117052      0.234989      0.192822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.116667      0.364896      0.351852   \n",
       "50%        0.000000      0.000000      0.183333      0.553620      0.500000   \n",
       "75%        0.160985      0.430831      0.258333      0.711963      0.648148   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             TARGET       Day_sin       Day_cos      Hour_sin      Hour_cos  \\\n",
       "count  36792.000000  36792.000000  36792.000000  36792.000000  36792.000000   \n",
       "mean      17.439978      0.507046      0.522326      0.500206      0.500027   \n",
       "std       25.449577      0.346981      0.359263      0.353558      0.353558   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.159610      0.158025      0.146447      0.146447   \n",
       "50%        0.000000      0.530107      0.536539      0.500000      0.500000   \n",
       "75%       31.085053      0.840390      0.891488      0.853553      0.853553   \n",
       "max       99.913939      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                GHI  TARGET_ROLLING_MEAN_3_shift_1  \\\n",
       "count  36792.000000                   3.679000e+04   \n",
       "mean       0.267026                   1.754246e-01   \n",
       "std        0.263381                   2.493107e-01   \n",
       "min        0.000000                   0.000000e+00   \n",
       "25%        0.088432                   3.356260e-15   \n",
       "50%        0.088432                   1.006823e-02   \n",
       "75%        0.415900                   3.152762e-01   \n",
       "max        1.000000                   1.000000e+00   \n",
       "\n",
       "       TARGET_ROLLING_MEAN_5_shift_2  TARGET_ROLLING_MEAN_11_shift_5  \\\n",
       "count                   36788.000000                    3.678200e+04   \n",
       "mean                        0.177070                    1.873707e-01   \n",
       "std                         0.245814                    2.357692e-01   \n",
       "min                         0.000000                    0.000000e+00   \n",
       "25%                         0.000000                    1.852145e-16   \n",
       "50%                         0.023250                    7.214131e-02   \n",
       "75%                         0.319363                    3.255759e-01   \n",
       "max                         1.000000                    1.000000e+00   \n",
       "\n",
       "       TARGET_ROLLING_MEAN_23_shift_11  TARGET_ROLLING_MEAN_47_shift_23  \\\n",
       "count                     36770.000000                     36746.000000   \n",
       "mean                          0.239865                         0.439553   \n",
       "std                           0.221299                         0.223309   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           0.044263                         0.257553   \n",
       "50%                           0.186432                         0.416421   \n",
       "75%                           0.378674                         0.613566   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       scaled_TARGET  \n",
       "count   36792.000000  \n",
       "mean        0.174550  \n",
       "std         0.254715  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.311118  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, valid_df, test_df = split_train_valid_test(df, [0.7, 0.2, 0.1])\n",
    "\n",
    "train_df_target = train_df[\"TARGET\"]\n",
    "valid_df_target = valid_df[\"TARGET\"]\n",
    "test_df_target = test_df[\"TARGET\"]\n",
    "\n",
    "train_df, valid_df, test_df = load_basic_preprocessed_train(\"minmax\")\n",
    "\n",
    "train_df[\"scaled_TARGET\"] = train_df[\"TARGET\"]\n",
    "valid_df[\"scaled_TARGET\"] = valid_df[\"TARGET\"]\n",
    "test_df[\"scaled_TARGET\"] = test_df[\"TARGET\"]\n",
    "\n",
    "train_df[\"TARGET\"] = train_df_target\n",
    "valid_df[\"TARGET\"] = valid_df_target\n",
    "test_df[\"TARGET\"] = test_df_target\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = [\n",
    "#     'DHI', \n",
    "#     'DNI', \n",
    "#     'WS', \n",
    "    'RH', \n",
    "    'T', \n",
    "#     'Hour_sin',\n",
    "#     'Hour_cos', \n",
    "    'GHI', \n",
    "    'TARGET_ROLLING_MEAN_3_shift_1',\n",
    "    'TARGET_ROLLING_MEAN_5_shift_2', \n",
    "    'TARGET_ROLLING_MEAN_11_shift_5',\n",
    "    'TARGET_ROLLING_MEAN_23_shift_11', \n",
    "    'TARGET_ROLLING_MEAN_47_shift_23',\n",
    "    'scaled_TARGET',\n",
    "    \"TARGET\",\n",
    "]\n",
    "train_df = train_df[cutter]\n",
    "valid_df = valid_df[cutter]\n",
    "test_df = test_df[cutter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "            Total window size: 336\n",
       "            Input indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
       " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
       " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
       " 234 235 236 237 238 239]\n",
       "            Label indices: [240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257\n",
       " 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275\n",
       " 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293\n",
       " 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311\n",
       " 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329\n",
       " 330 331 332 333 334 335]\n",
       "            Label column name(s): ['TARGET']\n",
       "        "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=48 * 5,\n",
    "    label_width=96,\n",
    "    shift=96,\n",
    "    sequence_stride=1,\n",
    "    label_columns=[\"TARGET\"]\n",
    "    \n",
    ")\n",
    "one_days_window_label_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cutter = [\n",
    "    'DHI', \n",
    "    'DNI', \n",
    "#     'WS', \n",
    "#     'RH', \n",
    "#     'T', \n",
    "#     'Hour_sin',\n",
    "#     'Hour_cos', \n",
    "    'GHI', \n",
    "#     'TARGET_ROLLING_MEAN_3_shift_1',\n",
    "#     'TARGET_ROLLING_MEAN_5_shift_2', \n",
    "#     'TARGET_ROLLING_MEAN_11_shift_5',\n",
    "#     'TARGET_ROLLING_MEAN_23_shift_11', \n",
    "#     'TARGET_ROLLING_MEAN_47_shift_23',\n",
    "    'scaled_TARGET',\n",
    "    \"TARGET\",\n",
    "]\n",
    "train_df = train_df[cutter]\n",
    "valid_df = valid_df[cutter]\n",
    "test_df = test_df[cutter]\n",
    "\n",
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "\n",
    "days = 7\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=48 * days,\n",
    "    label_width=96,\n",
    "    shift=96,\n",
    "    sequence_stride=1,\n",
    "    label_columns=[\"TARGET\"]\n",
    "    \n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict(\"minmax\")\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * days)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various = Convolution2DVarious(days, 96, train_df.shape[-1] - 1)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various, one_days_window_label_columns, q)\n",
    "    evaluate_dict[q] = conv_various.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, days, 48, train_df.shape[-1] - 1)\n",
    "    pred_y = conv_various.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 16), (10511, 16), (5257, 16)\n",
      "0.1\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Convolution_2D_various/conv2d_1/Relu (defined at C:\\Users\\bees1\\PycharmProjects\\dacon\\235680\\src\\model\\multiple_output\\convolution.py:115) ]] [Op:__inference_train_function_1642]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-4dc21ea9e6a0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[0mconv_various\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mConvolution2DVarious\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m96\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m     \u001B[0mcompile_and_fit_with_pinball_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconv_various\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mone_days_window_label_columns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m     \u001B[0mevaluate_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mq\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconv_various\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mone_days_window_label_columns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[0mpredict_np\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m48\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\dacon\\235680\\src\\trainers.py\u001B[0m in \u001B[0;36mcompile_and_fit_with_pinball_loss\u001B[1;34m(model, window, tau, patience)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m     history = model.fit(\n\u001B[1;32m---> 29\u001B[1;33m         \u001B[0mwindow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMAX_EPOCHS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mwindow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mearly_stopping\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m     )\n\u001B[0;32m     31\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1098\u001B[0m                 _r=1):\n\u001B[0;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1100\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1101\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 828\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"xla\"\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    886\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    887\u001B[0m         \u001B[1;31m# stateless function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 888\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    889\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m       \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m-> 2943\u001B[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m   2944\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2945\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1917\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1918\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1919\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1921\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    558\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 560\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    561\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    562\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 60\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnknownError\u001B[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Convolution_2D_various/conv2d_1/Relu (defined at C:\\Users\\bees1\\PycharmProjects\\dacon\\235680\\src\\model\\multiple_output\\convolution.py:115) ]] [Op:__inference_train_function_1642]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "\n",
    "days = 7\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=48 * days,\n",
    "    label_width=96,\n",
    "    shift=96,\n",
    "    sequence_stride=1,\n",
    "    label_columns=[\"TARGET\"]\n",
    "    \n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict(\"minmax\")\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * days)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various = Convolution2DVarious(days, 96, train_df.shape[-1] - 1)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various, one_days_window_label_columns, q)\n",
    "    evaluate_dict[q] = conv_various.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, days, 48, train_df.shape[-1] - 1)\n",
    "    pred_y = conv_various.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4491426547368367"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for v in evaluate_dict.values():\n",
    "    s += v[0]\n",
    "\n",
    "s/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.377"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.039182</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>-0.262078</td>\n",
       "      <td>-0.077926</td>\n",
       "      <td>-0.096600</td>\n",
       "      <td>0.130238</td>\n",
       "      <td>0.450639</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>0.349209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>-0.034980</td>\n",
       "      <td>-0.244316</td>\n",
       "      <td>-0.063754</td>\n",
       "      <td>-0.078709</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.320132</td>\n",
       "      <td>0.480108</td>\n",
       "      <td>0.115070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.060547</td>\n",
       "      <td>-0.248588</td>\n",
       "      <td>-0.054182</td>\n",
       "      <td>-0.165178</td>\n",
       "      <td>0.078416</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.165277</td>\n",
       "      <td>0.056348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.031008</td>\n",
       "      <td>-0.071877</td>\n",
       "      <td>-0.210734</td>\n",
       "      <td>-0.029477</td>\n",
       "      <td>-0.249886</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.503179</td>\n",
       "      <td>0.142628</td>\n",
       "      <td>0.161601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.146226</td>\n",
       "      <td>-0.001650</td>\n",
       "      <td>-0.234336</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.368112</td>\n",
       "      <td>0.237302</td>\n",
       "      <td>0.601942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>-0.090645</td>\n",
       "      <td>-0.041090</td>\n",
       "      <td>-0.189414</td>\n",
       "      <td>0.323597</td>\n",
       "      <td>0.327198</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.317377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>-0.018719</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>-0.081886</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.460836</td>\n",
       "      <td>-0.030206</td>\n",
       "      <td>0.496373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>-0.032476</td>\n",
       "      <td>-0.008575</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.092084</td>\n",
       "      <td>0.216250</td>\n",
       "      <td>0.345425</td>\n",
       "      <td>-0.022759</td>\n",
       "      <td>0.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>-0.059161</td>\n",
       "      <td>-0.072543</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>0.040515</td>\n",
       "      <td>0.077895</td>\n",
       "      <td>0.282540</td>\n",
       "      <td>0.447998</td>\n",
       "      <td>-0.174177</td>\n",
       "      <td>1.322776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>-0.030486</td>\n",
       "      <td>-0.092298</td>\n",
       "      <td>-0.009905</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.317974</td>\n",
       "      <td>0.374573</td>\n",
       "      <td>-0.182292</td>\n",
       "      <td>1.541316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>-0.025213</td>\n",
       "      <td>-0.046930</td>\n",
       "      <td>0.034109</td>\n",
       "      <td>0.151615</td>\n",
       "      <td>0.020788</td>\n",
       "      <td>0.234134</td>\n",
       "      <td>0.427993</td>\n",
       "      <td>-0.402563</td>\n",
       "      <td>2.917747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>-0.031391</td>\n",
       "      <td>-0.090941</td>\n",
       "      <td>-0.006039</td>\n",
       "      <td>0.183631</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.344756</td>\n",
       "      <td>0.479726</td>\n",
       "      <td>-0.416585</td>\n",
       "      <td>4.352693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>-0.272570</td>\n",
       "      <td>-0.196883</td>\n",
       "      <td>-0.109149</td>\n",
       "      <td>0.152476</td>\n",
       "      <td>-0.146615</td>\n",
       "      <td>0.224117</td>\n",
       "      <td>0.893243</td>\n",
       "      <td>0.867148</td>\n",
       "      <td>6.299477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>-0.289198</td>\n",
       "      <td>-0.095153</td>\n",
       "      <td>-0.291651</td>\n",
       "      <td>0.094839</td>\n",
       "      <td>0.034288</td>\n",
       "      <td>0.669276</td>\n",
       "      <td>1.311682</td>\n",
       "      <td>3.699658</td>\n",
       "      <td>9.358292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>-0.446601</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>-0.052619</td>\n",
       "      <td>0.316926</td>\n",
       "      <td>1.027447</td>\n",
       "      <td>1.702670</td>\n",
       "      <td>3.148567</td>\n",
       "      <td>8.231083</td>\n",
       "      <td>14.817108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>1.170033</td>\n",
       "      <td>0.514478</td>\n",
       "      <td>1.778396</td>\n",
       "      <td>3.866920</td>\n",
       "      <td>4.771164</td>\n",
       "      <td>6.198891</td>\n",
       "      <td>13.483189</td>\n",
       "      <td>21.043011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>0.603466</td>\n",
       "      <td>2.604455</td>\n",
       "      <td>2.917023</td>\n",
       "      <td>4.593253</td>\n",
       "      <td>7.486020</td>\n",
       "      <td>9.308355</td>\n",
       "      <td>12.128261</td>\n",
       "      <td>20.635893</td>\n",
       "      <td>26.808273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>1.821614</td>\n",
       "      <td>5.366351</td>\n",
       "      <td>6.169957</td>\n",
       "      <td>8.816880</td>\n",
       "      <td>12.232697</td>\n",
       "      <td>14.792357</td>\n",
       "      <td>19.033533</td>\n",
       "      <td>27.821562</td>\n",
       "      <td>32.476967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>4.247874</td>\n",
       "      <td>8.139577</td>\n",
       "      <td>10.053808</td>\n",
       "      <td>13.764545</td>\n",
       "      <td>17.420172</td>\n",
       "      <td>20.196548</td>\n",
       "      <td>25.740473</td>\n",
       "      <td>33.724026</td>\n",
       "      <td>37.419456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>6.805990</td>\n",
       "      <td>12.041272</td>\n",
       "      <td>14.172252</td>\n",
       "      <td>19.039677</td>\n",
       "      <td>22.563673</td>\n",
       "      <td>25.881044</td>\n",
       "      <td>31.842136</td>\n",
       "      <td>38.674709</td>\n",
       "      <td>41.424519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>9.796557</td>\n",
       "      <td>15.332124</td>\n",
       "      <td>17.726885</td>\n",
       "      <td>23.330568</td>\n",
       "      <td>26.479294</td>\n",
       "      <td>31.892189</td>\n",
       "      <td>37.078766</td>\n",
       "      <td>43.759972</td>\n",
       "      <td>45.445316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>11.958274</td>\n",
       "      <td>18.185305</td>\n",
       "      <td>20.976429</td>\n",
       "      <td>27.342730</td>\n",
       "      <td>29.825043</td>\n",
       "      <td>36.495228</td>\n",
       "      <td>41.103031</td>\n",
       "      <td>47.240467</td>\n",
       "      <td>48.481194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>14.892960</td>\n",
       "      <td>20.990072</td>\n",
       "      <td>23.518324</td>\n",
       "      <td>30.214069</td>\n",
       "      <td>32.435047</td>\n",
       "      <td>39.501034</td>\n",
       "      <td>43.726486</td>\n",
       "      <td>49.432091</td>\n",
       "      <td>50.891693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>17.588879</td>\n",
       "      <td>21.693304</td>\n",
       "      <td>24.978914</td>\n",
       "      <td>31.876633</td>\n",
       "      <td>33.842255</td>\n",
       "      <td>40.527149</td>\n",
       "      <td>44.881321</td>\n",
       "      <td>50.654995</td>\n",
       "      <td>52.467781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>18.248976</td>\n",
       "      <td>21.763687</td>\n",
       "      <td>26.146961</td>\n",
       "      <td>31.852884</td>\n",
       "      <td>34.138477</td>\n",
       "      <td>40.860291</td>\n",
       "      <td>45.611366</td>\n",
       "      <td>50.885868</td>\n",
       "      <td>52.567024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>18.397192</td>\n",
       "      <td>21.023363</td>\n",
       "      <td>26.999397</td>\n",
       "      <td>31.615480</td>\n",
       "      <td>34.163532</td>\n",
       "      <td>40.055851</td>\n",
       "      <td>45.472126</td>\n",
       "      <td>49.481857</td>\n",
       "      <td>51.055668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>17.560436</td>\n",
       "      <td>20.232290</td>\n",
       "      <td>26.836237</td>\n",
       "      <td>30.712679</td>\n",
       "      <td>33.179123</td>\n",
       "      <td>38.319248</td>\n",
       "      <td>44.552670</td>\n",
       "      <td>46.689537</td>\n",
       "      <td>49.609081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>16.587851</td>\n",
       "      <td>17.426888</td>\n",
       "      <td>25.085615</td>\n",
       "      <td>27.678873</td>\n",
       "      <td>30.679623</td>\n",
       "      <td>34.858601</td>\n",
       "      <td>42.446491</td>\n",
       "      <td>43.312790</td>\n",
       "      <td>46.900673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>14.743177</td>\n",
       "      <td>15.074840</td>\n",
       "      <td>22.572157</td>\n",
       "      <td>25.236439</td>\n",
       "      <td>27.511950</td>\n",
       "      <td>31.240870</td>\n",
       "      <td>39.128674</td>\n",
       "      <td>38.915852</td>\n",
       "      <td>42.637218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>12.786992</td>\n",
       "      <td>11.717649</td>\n",
       "      <td>18.989038</td>\n",
       "      <td>22.489347</td>\n",
       "      <td>22.751638</td>\n",
       "      <td>26.937178</td>\n",
       "      <td>33.560871</td>\n",
       "      <td>33.142521</td>\n",
       "      <td>36.202568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>9.763635</td>\n",
       "      <td>9.030738</td>\n",
       "      <td>14.531198</td>\n",
       "      <td>17.737574</td>\n",
       "      <td>17.853407</td>\n",
       "      <td>21.246086</td>\n",
       "      <td>27.234476</td>\n",
       "      <td>26.599081</td>\n",
       "      <td>30.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>6.506858</td>\n",
       "      <td>5.968741</td>\n",
       "      <td>10.483469</td>\n",
       "      <td>12.069837</td>\n",
       "      <td>12.438204</td>\n",
       "      <td>14.360655</td>\n",
       "      <td>20.193790</td>\n",
       "      <td>19.611094</td>\n",
       "      <td>23.357414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>3.687265</td>\n",
       "      <td>3.828326</td>\n",
       "      <td>6.889744</td>\n",
       "      <td>7.007932</td>\n",
       "      <td>7.512821</td>\n",
       "      <td>8.260777</td>\n",
       "      <td>13.458804</td>\n",
       "      <td>13.004804</td>\n",
       "      <td>17.664673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>1.449636</td>\n",
       "      <td>2.127152</td>\n",
       "      <td>3.520343</td>\n",
       "      <td>3.334645</td>\n",
       "      <td>4.074371</td>\n",
       "      <td>3.739337</td>\n",
       "      <td>8.050194</td>\n",
       "      <td>7.565793</td>\n",
       "      <td>12.084809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.294037</td>\n",
       "      <td>0.770210</td>\n",
       "      <td>0.936472</td>\n",
       "      <td>0.987449</td>\n",
       "      <td>1.744060</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>4.050910</td>\n",
       "      <td>3.978846</td>\n",
       "      <td>7.931828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>-0.160009</td>\n",
       "      <td>0.120410</td>\n",
       "      <td>-0.066243</td>\n",
       "      <td>0.091244</td>\n",
       "      <td>0.276093</td>\n",
       "      <td>0.362064</td>\n",
       "      <td>1.796248</td>\n",
       "      <td>1.512815</td>\n",
       "      <td>5.167080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>-0.411161</td>\n",
       "      <td>-0.236605</td>\n",
       "      <td>-0.212947</td>\n",
       "      <td>0.046958</td>\n",
       "      <td>-0.047038</td>\n",
       "      <td>0.127984</td>\n",
       "      <td>0.603453</td>\n",
       "      <td>0.342510</td>\n",
       "      <td>3.236153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>-0.186458</td>\n",
       "      <td>-0.301121</td>\n",
       "      <td>-0.021107</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>0.156873</td>\n",
       "      <td>0.156581</td>\n",
       "      <td>0.113709</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>1.613174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>-0.217244</td>\n",
       "      <td>0.037745</td>\n",
       "      <td>0.026173</td>\n",
       "      <td>-0.099757</td>\n",
       "      <td>-0.031206</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>-0.072420</td>\n",
       "      <td>1.346886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>-0.276484</td>\n",
       "      <td>-0.022262</td>\n",
       "      <td>0.038624</td>\n",
       "      <td>-0.075733</td>\n",
       "      <td>-0.109060</td>\n",
       "      <td>-0.068618</td>\n",
       "      <td>-0.016675</td>\n",
       "      <td>1.056659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>-0.022466</td>\n",
       "      <td>-0.180903</td>\n",
       "      <td>-0.065141</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>-0.058739</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.314953</td>\n",
       "      <td>0.646702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>-0.020036</td>\n",
       "      <td>-0.179377</td>\n",
       "      <td>-0.047001</td>\n",
       "      <td>0.028465</td>\n",
       "      <td>-0.128809</td>\n",
       "      <td>0.161465</td>\n",
       "      <td>0.134818</td>\n",
       "      <td>0.517022</td>\n",
       "      <td>0.401942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>-0.053018</td>\n",
       "      <td>-0.115350</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.076545</td>\n",
       "      <td>0.210849</td>\n",
       "      <td>0.255126</td>\n",
       "      <td>0.362541</td>\n",
       "      <td>0.586290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>-0.023360</td>\n",
       "      <td>-0.138472</td>\n",
       "      <td>-0.110470</td>\n",
       "      <td>-0.036610</td>\n",
       "      <td>0.103335</td>\n",
       "      <td>0.099819</td>\n",
       "      <td>0.282048</td>\n",
       "      <td>0.216156</td>\n",
       "      <td>0.520361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>-0.025908</td>\n",
       "      <td>-0.120994</td>\n",
       "      <td>-0.062186</td>\n",
       "      <td>-0.028411</td>\n",
       "      <td>0.149277</td>\n",
       "      <td>-0.152933</td>\n",
       "      <td>0.181949</td>\n",
       "      <td>0.221340</td>\n",
       "      <td>0.453362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>-0.021236</td>\n",
       "      <td>-0.118108</td>\n",
       "      <td>0.048013</td>\n",
       "      <td>-0.129194</td>\n",
       "      <td>0.091142</td>\n",
       "      <td>-0.048188</td>\n",
       "      <td>0.179037</td>\n",
       "      <td>0.272020</td>\n",
       "      <td>0.622102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>-0.027322</td>\n",
       "      <td>-0.146872</td>\n",
       "      <td>0.086473</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.153528</td>\n",
       "      <td>-0.161517</td>\n",
       "      <td>0.486251</td>\n",
       "      <td>0.565686</td>\n",
       "      <td>0.571066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>-0.031661</td>\n",
       "      <td>0.081536</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.328194</td>\n",
       "      <td>-0.101593</td>\n",
       "      <td>0.703268</td>\n",
       "      <td>0.802840</td>\n",
       "      <td>0.353628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m  -0.039182   0.022454  -0.262078  -0.077926  -0.096600   \n",
       "1    0.csv_Day7_0h30m   0.014708  -0.034980  -0.244316  -0.063754  -0.078709   \n",
       "2    0.csv_Day7_1h00m  -0.029718  -0.060547  -0.248588  -0.054182  -0.165178   \n",
       "3    0.csv_Day7_1h30m  -0.031008  -0.071877  -0.210734  -0.029477  -0.249886   \n",
       "4    0.csv_Day7_2h00m   0.029828  -0.004916  -0.146226  -0.001650  -0.234336   \n",
       "5    0.csv_Day7_2h30m   0.035505   0.011142  -0.090645  -0.041090  -0.189414   \n",
       "6    0.csv_Day7_3h00m   0.008044   0.003094  -0.018719   0.010431  -0.081886   \n",
       "7    0.csv_Day7_3h30m  -0.032476  -0.008575   0.033354   0.012751   0.092084   \n",
       "8    0.csv_Day7_4h00m  -0.059161  -0.072543   0.037384   0.040515   0.077895   \n",
       "9    0.csv_Day7_4h30m  -0.030486  -0.092298  -0.009905   0.029081   0.127106   \n",
       "10   0.csv_Day7_5h00m  -0.025213  -0.046930   0.034109   0.151615   0.020788   \n",
       "11   0.csv_Day7_5h30m  -0.031391  -0.090941  -0.006039   0.183631  -0.130140   \n",
       "12   0.csv_Day7_6h00m  -0.272570  -0.196883  -0.109149   0.152476  -0.146615   \n",
       "13   0.csv_Day7_6h30m  -0.289198  -0.095153  -0.291651   0.094839   0.034288   \n",
       "14   0.csv_Day7_7h00m  -0.446601   0.034586  -0.052619   0.316926   1.027447   \n",
       "15   0.csv_Day7_7h30m  -0.241279   1.170033   0.514478   1.778396   3.866920   \n",
       "16   0.csv_Day7_8h00m   0.603466   2.604455   2.917023   4.593253   7.486020   \n",
       "17   0.csv_Day7_8h30m   1.821614   5.366351   6.169957   8.816880  12.232697   \n",
       "18   0.csv_Day7_9h00m   4.247874   8.139577  10.053808  13.764545  17.420172   \n",
       "19   0.csv_Day7_9h30m   6.805990  12.041272  14.172252  19.039677  22.563673   \n",
       "20  0.csv_Day7_10h00m   9.796557  15.332124  17.726885  23.330568  26.479294   \n",
       "21  0.csv_Day7_10h30m  11.958274  18.185305  20.976429  27.342730  29.825043   \n",
       "22  0.csv_Day7_11h00m  14.892960  20.990072  23.518324  30.214069  32.435047   \n",
       "23  0.csv_Day7_11h30m  17.588879  21.693304  24.978914  31.876633  33.842255   \n",
       "24  0.csv_Day7_12h00m  18.248976  21.763687  26.146961  31.852884  34.138477   \n",
       "25  0.csv_Day7_12h30m  18.397192  21.023363  26.999397  31.615480  34.163532   \n",
       "26  0.csv_Day7_13h00m  17.560436  20.232290  26.836237  30.712679  33.179123   \n",
       "27  0.csv_Day7_13h30m  16.587851  17.426888  25.085615  27.678873  30.679623   \n",
       "28  0.csv_Day7_14h00m  14.743177  15.074840  22.572157  25.236439  27.511950   \n",
       "29  0.csv_Day7_14h30m  12.786992  11.717649  18.989038  22.489347  22.751638   \n",
       "30  0.csv_Day7_15h00m   9.763635   9.030738  14.531198  17.737574  17.853407   \n",
       "31  0.csv_Day7_15h30m   6.506858   5.968741  10.483469  12.069837  12.438204   \n",
       "32  0.csv_Day7_16h00m   3.687265   3.828326   6.889744   7.007932   7.512821   \n",
       "33  0.csv_Day7_16h30m   1.449636   2.127152   3.520343   3.334645   4.074371   \n",
       "34  0.csv_Day7_17h00m   0.294037   0.770210   0.936472   0.987449   1.744060   \n",
       "35  0.csv_Day7_17h30m  -0.160009   0.120410  -0.066243   0.091244   0.276093   \n",
       "36  0.csv_Day7_18h00m  -0.411161  -0.236605  -0.212947   0.046958  -0.047038   \n",
       "37  0.csv_Day7_18h30m  -0.186458  -0.301121  -0.021107  -0.001146   0.156873   \n",
       "38  0.csv_Day7_19h00m  -0.004934  -0.217244   0.037745   0.026173  -0.099757   \n",
       "39  0.csv_Day7_19h30m   0.002572  -0.276484  -0.022262   0.038624  -0.075733   \n",
       "40  0.csv_Day7_20h00m  -0.022466  -0.180903  -0.065141   0.047100   0.044632   \n",
       "41  0.csv_Day7_20h30m  -0.020036  -0.179377  -0.047001   0.028465  -0.128809   \n",
       "42  0.csv_Day7_21h00m  -0.053018  -0.115350   0.001401  -0.003701  -0.076545   \n",
       "43  0.csv_Day7_21h30m  -0.023360  -0.138472  -0.110470  -0.036610   0.103335   \n",
       "44  0.csv_Day7_22h00m  -0.025908  -0.120994  -0.062186  -0.028411   0.149277   \n",
       "45  0.csv_Day7_22h30m  -0.021236  -0.118108   0.048013  -0.129194   0.091142   \n",
       "46  0.csv_Day7_23h00m  -0.027322  -0.146872   0.086473   0.031374   0.153528   \n",
       "47  0.csv_Day7_23h30m   0.000421  -0.031661   0.081536   0.001737   0.328194   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.130238   0.450639   0.902081   0.349209  \n",
       "1    0.106796   0.320132   0.480108   0.115070  \n",
       "2    0.078416   0.437620   0.165277   0.056348  \n",
       "3    0.042626   0.503179   0.142628   0.161601  \n",
       "4    0.217769   0.368112   0.237302   0.601942  \n",
       "5    0.323597   0.327198   0.015087   0.317377  \n",
       "6    0.175781   0.460836  -0.030206   0.496373  \n",
       "7    0.216250   0.345425  -0.022759   0.861100  \n",
       "8    0.282540   0.447998  -0.174177   1.322776  \n",
       "9    0.317974   0.374573  -0.182292   1.541316  \n",
       "10   0.234134   0.427993  -0.402563   2.917747  \n",
       "11   0.344756   0.479726  -0.416585   4.352693  \n",
       "12   0.224117   0.893243   0.867148   6.299477  \n",
       "13   0.669276   1.311682   3.699658   9.358292  \n",
       "14   1.702670   3.148567   8.231083  14.817108  \n",
       "15   4.771164   6.198891  13.483189  21.043011  \n",
       "16   9.308355  12.128261  20.635893  26.808273  \n",
       "17  14.792357  19.033533  27.821562  32.476967  \n",
       "18  20.196548  25.740473  33.724026  37.419456  \n",
       "19  25.881044  31.842136  38.674709  41.424519  \n",
       "20  31.892189  37.078766  43.759972  45.445316  \n",
       "21  36.495228  41.103031  47.240467  48.481194  \n",
       "22  39.501034  43.726486  49.432091  50.891693  \n",
       "23  40.527149  44.881321  50.654995  52.467781  \n",
       "24  40.860291  45.611366  50.885868  52.567024  \n",
       "25  40.055851  45.472126  49.481857  51.055668  \n",
       "26  38.319248  44.552670  46.689537  49.609081  \n",
       "27  34.858601  42.446491  43.312790  46.900673  \n",
       "28  31.240870  39.128674  38.915852  42.637218  \n",
       "29  26.937178  33.560871  33.142521  36.202568  \n",
       "30  21.246086  27.234476  26.599081  30.003389  \n",
       "31  14.360655  20.193790  19.611094  23.357414  \n",
       "32   8.260777  13.458804  13.004804  17.664673  \n",
       "33   3.739337   8.050194   7.565793  12.084809  \n",
       "34   1.544856   4.050910   3.978846   7.931828  \n",
       "35   0.362064   1.796248   1.512815   5.167080  \n",
       "36   0.127984   0.603453   0.342510   3.236153  \n",
       "37   0.156581   0.113709   0.025465   1.613174  \n",
       "38  -0.031206   0.030501  -0.072420   1.346886  \n",
       "39  -0.109060  -0.068618  -0.016675   1.056659  \n",
       "40  -0.058739   0.011441   0.314953   0.646702  \n",
       "41   0.161465   0.134818   0.517022   0.401942  \n",
       "42   0.210849   0.255126   0.362541   0.586290  \n",
       "43   0.099819   0.282048   0.216156   0.520361  \n",
       "44  -0.152933   0.181949   0.221340   0.453362  \n",
       "45  -0.048188   0.179037   0.272020   0.622102  \n",
       "46  -0.161517   0.486251   0.565686   0.571066  \n",
       "47  -0.101593   0.703268   0.802840   0.353628  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[0:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.032475</td>\n",
       "      <td>-0.105103</td>\n",
       "      <td>-0.098774</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>-0.027927</td>\n",
       "      <td>-0.022728</td>\n",
       "      <td>-0.108168</td>\n",
       "      <td>0.074562</td>\n",
       "      <td>0.595425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>-0.228631</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.082372</td>\n",
       "      <td>-0.084517</td>\n",
       "      <td>-0.059915</td>\n",
       "      <td>1.063461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.047746</td>\n",
       "      <td>-0.016477</td>\n",
       "      <td>-0.366813</td>\n",
       "      <td>-0.010404</td>\n",
       "      <td>-0.088813</td>\n",
       "      <td>0.032507</td>\n",
       "      <td>0.035325</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>1.504606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.045246</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>-0.087656</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.061755</td>\n",
       "      <td>0.199537</td>\n",
       "      <td>0.171587</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>1.511725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>-0.037601</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.113075</td>\n",
       "      <td>-0.053915</td>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.453990</td>\n",
       "      <td>0.407158</td>\n",
       "      <td>0.145288</td>\n",
       "      <td>1.324745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>-0.028831</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>-0.070114</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.295865</td>\n",
       "      <td>0.312074</td>\n",
       "      <td>0.099051</td>\n",
       "      <td>0.968625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>-0.011036</td>\n",
       "      <td>-0.076511</td>\n",
       "      <td>0.148333</td>\n",
       "      <td>0.151301</td>\n",
       "      <td>0.406871</td>\n",
       "      <td>0.055930</td>\n",
       "      <td>0.957362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>-0.038073</td>\n",
       "      <td>-0.029464</td>\n",
       "      <td>-0.327148</td>\n",
       "      <td>-0.026507</td>\n",
       "      <td>-0.012956</td>\n",
       "      <td>-0.038526</td>\n",
       "      <td>0.247233</td>\n",
       "      <td>0.030798</td>\n",
       "      <td>0.219046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>-0.038016</td>\n",
       "      <td>-0.060692</td>\n",
       "      <td>-0.689418</td>\n",
       "      <td>0.036708</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>-0.103541</td>\n",
       "      <td>0.319506</td>\n",
       "      <td>0.039582</td>\n",
       "      <td>0.495112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>-0.033922</td>\n",
       "      <td>-0.113797</td>\n",
       "      <td>-1.062824</td>\n",
       "      <td>0.134667</td>\n",
       "      <td>0.109588</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>0.484153</td>\n",
       "      <td>0.431663</td>\n",
       "      <td>0.559823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>-0.044573</td>\n",
       "      <td>-0.198870</td>\n",
       "      <td>-1.418363</td>\n",
       "      <td>0.258881</td>\n",
       "      <td>0.202406</td>\n",
       "      <td>0.295156</td>\n",
       "      <td>0.441591</td>\n",
       "      <td>0.528161</td>\n",
       "      <td>-0.087109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>-0.230250</td>\n",
       "      <td>-0.577085</td>\n",
       "      <td>-1.719793</td>\n",
       "      <td>0.095863</td>\n",
       "      <td>0.194881</td>\n",
       "      <td>0.324341</td>\n",
       "      <td>0.190489</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.617961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>-0.156363</td>\n",
       "      <td>-0.289281</td>\n",
       "      <td>-1.788932</td>\n",
       "      <td>-0.015102</td>\n",
       "      <td>0.049515</td>\n",
       "      <td>0.096941</td>\n",
       "      <td>0.089325</td>\n",
       "      <td>1.246120</td>\n",
       "      <td>1.621673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>-0.097249</td>\n",
       "      <td>0.032490</td>\n",
       "      <td>-1.394271</td>\n",
       "      <td>-0.008496</td>\n",
       "      <td>-0.004574</td>\n",
       "      <td>-0.053907</td>\n",
       "      <td>0.441158</td>\n",
       "      <td>1.455138</td>\n",
       "      <td>3.089519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.388660</td>\n",
       "      <td>-0.214347</td>\n",
       "      <td>0.231003</td>\n",
       "      <td>-0.022536</td>\n",
       "      <td>0.591490</td>\n",
       "      <td>1.744735</td>\n",
       "      <td>2.592998</td>\n",
       "      <td>5.093650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>1.145264</td>\n",
       "      <td>1.771394</td>\n",
       "      <td>0.622307</td>\n",
       "      <td>1.797454</td>\n",
       "      <td>1.238429</td>\n",
       "      <td>1.915306</td>\n",
       "      <td>4.540763</td>\n",
       "      <td>5.262686</td>\n",
       "      <td>8.937643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>2.383642</td>\n",
       "      <td>3.587969</td>\n",
       "      <td>2.915865</td>\n",
       "      <td>4.347979</td>\n",
       "      <td>4.637251</td>\n",
       "      <td>4.823846</td>\n",
       "      <td>8.629528</td>\n",
       "      <td>9.494079</td>\n",
       "      <td>13.571690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>3.891693</td>\n",
       "      <td>6.636632</td>\n",
       "      <td>5.512778</td>\n",
       "      <td>7.801158</td>\n",
       "      <td>8.834262</td>\n",
       "      <td>9.745342</td>\n",
       "      <td>14.793843</td>\n",
       "      <td>15.650631</td>\n",
       "      <td>19.707041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>5.920645</td>\n",
       "      <td>10.082118</td>\n",
       "      <td>8.638920</td>\n",
       "      <td>11.743272</td>\n",
       "      <td>13.582507</td>\n",
       "      <td>15.869155</td>\n",
       "      <td>20.750513</td>\n",
       "      <td>22.549725</td>\n",
       "      <td>26.517036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>7.578732</td>\n",
       "      <td>12.495900</td>\n",
       "      <td>13.091483</td>\n",
       "      <td>15.564502</td>\n",
       "      <td>18.910107</td>\n",
       "      <td>21.792852</td>\n",
       "      <td>27.005182</td>\n",
       "      <td>29.240368</td>\n",
       "      <td>34.093887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>9.202325</td>\n",
       "      <td>14.370083</td>\n",
       "      <td>17.380587</td>\n",
       "      <td>18.922745</td>\n",
       "      <td>21.778227</td>\n",
       "      <td>26.887941</td>\n",
       "      <td>33.066570</td>\n",
       "      <td>35.087997</td>\n",
       "      <td>40.060902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>10.377932</td>\n",
       "      <td>16.560617</td>\n",
       "      <td>21.049261</td>\n",
       "      <td>22.855680</td>\n",
       "      <td>26.007191</td>\n",
       "      <td>30.495989</td>\n",
       "      <td>37.841412</td>\n",
       "      <td>39.055458</td>\n",
       "      <td>44.992802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>11.315662</td>\n",
       "      <td>17.851332</td>\n",
       "      <td>23.594387</td>\n",
       "      <td>26.603224</td>\n",
       "      <td>29.110861</td>\n",
       "      <td>32.556499</td>\n",
       "      <td>41.089462</td>\n",
       "      <td>41.923168</td>\n",
       "      <td>48.452892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>11.923900</td>\n",
       "      <td>18.096512</td>\n",
       "      <td>25.127829</td>\n",
       "      <td>28.512575</td>\n",
       "      <td>31.546825</td>\n",
       "      <td>35.788204</td>\n",
       "      <td>43.759438</td>\n",
       "      <td>43.584980</td>\n",
       "      <td>49.854446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>12.259184</td>\n",
       "      <td>17.972837</td>\n",
       "      <td>24.602896</td>\n",
       "      <td>29.206108</td>\n",
       "      <td>32.086597</td>\n",
       "      <td>37.434673</td>\n",
       "      <td>44.159756</td>\n",
       "      <td>44.015755</td>\n",
       "      <td>50.155651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>11.664116</td>\n",
       "      <td>16.960072</td>\n",
       "      <td>23.584049</td>\n",
       "      <td>27.749851</td>\n",
       "      <td>31.522541</td>\n",
       "      <td>36.887539</td>\n",
       "      <td>44.263329</td>\n",
       "      <td>43.224564</td>\n",
       "      <td>48.869244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>10.191174</td>\n",
       "      <td>16.064186</td>\n",
       "      <td>22.387798</td>\n",
       "      <td>25.843534</td>\n",
       "      <td>29.914156</td>\n",
       "      <td>35.671467</td>\n",
       "      <td>42.116119</td>\n",
       "      <td>40.326588</td>\n",
       "      <td>46.095654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>8.338793</td>\n",
       "      <td>14.031995</td>\n",
       "      <td>20.028107</td>\n",
       "      <td>23.580259</td>\n",
       "      <td>26.111427</td>\n",
       "      <td>33.341022</td>\n",
       "      <td>38.915386</td>\n",
       "      <td>36.632172</td>\n",
       "      <td>42.542233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>6.438894</td>\n",
       "      <td>11.798625</td>\n",
       "      <td>17.772745</td>\n",
       "      <td>20.204332</td>\n",
       "      <td>22.745476</td>\n",
       "      <td>30.142757</td>\n",
       "      <td>34.384727</td>\n",
       "      <td>32.552292</td>\n",
       "      <td>37.896477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>4.642674</td>\n",
       "      <td>8.917039</td>\n",
       "      <td>14.868993</td>\n",
       "      <td>16.636839</td>\n",
       "      <td>19.511023</td>\n",
       "      <td>25.442408</td>\n",
       "      <td>28.204422</td>\n",
       "      <td>27.932016</td>\n",
       "      <td>32.630417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>2.930609</td>\n",
       "      <td>6.400648</td>\n",
       "      <td>11.751292</td>\n",
       "      <td>12.728077</td>\n",
       "      <td>15.909344</td>\n",
       "      <td>19.699924</td>\n",
       "      <td>20.741110</td>\n",
       "      <td>21.636147</td>\n",
       "      <td>25.989923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>1.649050</td>\n",
       "      <td>3.933033</td>\n",
       "      <td>8.617319</td>\n",
       "      <td>8.952081</td>\n",
       "      <td>11.080450</td>\n",
       "      <td>13.816643</td>\n",
       "      <td>14.024981</td>\n",
       "      <td>15.228221</td>\n",
       "      <td>19.284466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>1.807476</td>\n",
       "      <td>5.380528</td>\n",
       "      <td>5.751849</td>\n",
       "      <td>5.436456</td>\n",
       "      <td>7.641447</td>\n",
       "      <td>8.822656</td>\n",
       "      <td>9.219543</td>\n",
       "      <td>12.351213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>0.201524</td>\n",
       "      <td>0.623902</td>\n",
       "      <td>3.130742</td>\n",
       "      <td>2.934508</td>\n",
       "      <td>1.469816</td>\n",
       "      <td>3.469676</td>\n",
       "      <td>5.192949</td>\n",
       "      <td>5.178250</td>\n",
       "      <td>7.116824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>-0.015940</td>\n",
       "      <td>-0.053902</td>\n",
       "      <td>1.742528</td>\n",
       "      <td>0.971621</td>\n",
       "      <td>0.092404</td>\n",
       "      <td>0.868362</td>\n",
       "      <td>2.794237</td>\n",
       "      <td>3.109246</td>\n",
       "      <td>3.915729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>-0.043710</td>\n",
       "      <td>-0.165341</td>\n",
       "      <td>1.029288</td>\n",
       "      <td>0.069415</td>\n",
       "      <td>-0.352298</td>\n",
       "      <td>-0.082172</td>\n",
       "      <td>1.894108</td>\n",
       "      <td>2.155954</td>\n",
       "      <td>2.454201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>-0.040556</td>\n",
       "      <td>-0.103839</td>\n",
       "      <td>0.429723</td>\n",
       "      <td>-0.155786</td>\n",
       "      <td>-0.193194</td>\n",
       "      <td>-0.187773</td>\n",
       "      <td>1.143442</td>\n",
       "      <td>1.366849</td>\n",
       "      <td>1.423467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>-0.057124</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>0.096232</td>\n",
       "      <td>-0.367589</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>-0.059490</td>\n",
       "      <td>1.029982</td>\n",
       "      <td>0.804624</td>\n",
       "      <td>0.757860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>-0.036151</td>\n",
       "      <td>-0.031596</td>\n",
       "      <td>-0.154644</td>\n",
       "      <td>-0.245674</td>\n",
       "      <td>-0.094616</td>\n",
       "      <td>-0.124035</td>\n",
       "      <td>0.505330</td>\n",
       "      <td>0.283033</td>\n",
       "      <td>0.461291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>-0.024918</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>-0.078590</td>\n",
       "      <td>-0.166324</td>\n",
       "      <td>-0.043196</td>\n",
       "      <td>-0.143338</td>\n",
       "      <td>0.338303</td>\n",
       "      <td>-0.070067</td>\n",
       "      <td>0.242706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>-0.039703</td>\n",
       "      <td>-0.014718</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>-0.170821</td>\n",
       "      <td>-0.066030</td>\n",
       "      <td>-0.101935</td>\n",
       "      <td>0.066204</td>\n",
       "      <td>0.110954</td>\n",
       "      <td>0.373869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>-0.040474</td>\n",
       "      <td>0.047775</td>\n",
       "      <td>-0.007638</td>\n",
       "      <td>-0.075785</td>\n",
       "      <td>-0.143889</td>\n",
       "      <td>-0.159693</td>\n",
       "      <td>-0.094389</td>\n",
       "      <td>-0.194270</td>\n",
       "      <td>0.490138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>-0.044599</td>\n",
       "      <td>0.031964</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>-0.013890</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>-0.052794</td>\n",
       "      <td>0.114666</td>\n",
       "      <td>-0.047797</td>\n",
       "      <td>0.169868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>-0.040397</td>\n",
       "      <td>0.017927</td>\n",
       "      <td>-0.026830</td>\n",
       "      <td>-0.018662</td>\n",
       "      <td>-0.084809</td>\n",
       "      <td>-0.035200</td>\n",
       "      <td>0.142241</td>\n",
       "      <td>-0.186230</td>\n",
       "      <td>0.260162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>-0.021974</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>-0.078171</td>\n",
       "      <td>-0.085914</td>\n",
       "      <td>-0.109154</td>\n",
       "      <td>-0.090836</td>\n",
       "      <td>-0.059531</td>\n",
       "      <td>-0.018495</td>\n",
       "      <td>0.028261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>-0.031366</td>\n",
       "      <td>-0.034161</td>\n",
       "      <td>-0.092709</td>\n",
       "      <td>-0.065930</td>\n",
       "      <td>-0.013743</td>\n",
       "      <td>0.116565</td>\n",
       "      <td>0.130139</td>\n",
       "      <td>-0.095092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>-0.090818</td>\n",
       "      <td>-0.108225</td>\n",
       "      <td>-0.112969</td>\n",
       "      <td>-0.039415</td>\n",
       "      <td>-0.071323</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.177514</td>\n",
       "      <td>-0.042162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>-0.010059</td>\n",
       "      <td>-0.039430</td>\n",
       "      <td>-0.084664</td>\n",
       "      <td>-0.129694</td>\n",
       "      <td>-0.097498</td>\n",
       "      <td>-0.092663</td>\n",
       "      <td>0.146892</td>\n",
       "      <td>0.271685</td>\n",
       "      <td>0.165213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m  -0.032475  -0.105103  -0.098774   0.063773  -0.027927   \n",
       "1    0.csv_Day7_0h30m  -0.025982   0.013037  -0.228631   0.023997   0.006828   \n",
       "2    0.csv_Day7_1h00m  -0.047746  -0.016477  -0.366813  -0.010404  -0.088813   \n",
       "3    0.csv_Day7_1h30m  -0.045246  -0.011987  -0.087656   0.076161   0.061755   \n",
       "4    0.csv_Day7_2h00m  -0.037601   0.000744  -0.113075  -0.053915   0.035461   \n",
       "5    0.csv_Day7_2h30m  -0.028831   0.000839  -0.070114  -0.067453   0.020227   \n",
       "6    0.csv_Day7_3h00m   0.002505   0.028633  -0.011036  -0.076511   0.148333   \n",
       "7    0.csv_Day7_3h30m  -0.038073  -0.029464  -0.327148  -0.026507  -0.012956   \n",
       "8    0.csv_Day7_4h00m  -0.038016  -0.060692  -0.689418   0.036708   0.017185   \n",
       "9    0.csv_Day7_4h30m  -0.033922  -0.113797  -1.062824   0.134667   0.109588   \n",
       "10   0.csv_Day7_5h00m  -0.044573  -0.198870  -1.418363   0.258881   0.202406   \n",
       "11   0.csv_Day7_5h30m  -0.230250  -0.577085  -1.719793   0.095863   0.194881   \n",
       "12   0.csv_Day7_6h00m  -0.156363  -0.289281  -1.788932  -0.015102   0.049515   \n",
       "13   0.csv_Day7_6h30m  -0.097249   0.032490  -1.394271  -0.008496  -0.004574   \n",
       "14   0.csv_Day7_7h00m   0.030976   0.388660  -0.214347   0.231003  -0.022536   \n",
       "15   0.csv_Day7_7h30m   1.145264   1.771394   0.622307   1.797454   1.238429   \n",
       "16   0.csv_Day7_8h00m   2.383642   3.587969   2.915865   4.347979   4.637251   \n",
       "17   0.csv_Day7_8h30m   3.891693   6.636632   5.512778   7.801158   8.834262   \n",
       "18   0.csv_Day7_9h00m   5.920645  10.082118   8.638920  11.743272  13.582507   \n",
       "19   0.csv_Day7_9h30m   7.578732  12.495900  13.091483  15.564502  18.910107   \n",
       "20  0.csv_Day7_10h00m   9.202325  14.370083  17.380587  18.922745  21.778227   \n",
       "21  0.csv_Day7_10h30m  10.377932  16.560617  21.049261  22.855680  26.007191   \n",
       "22  0.csv_Day7_11h00m  11.315662  17.851332  23.594387  26.603224  29.110861   \n",
       "23  0.csv_Day7_11h30m  11.923900  18.096512  25.127829  28.512575  31.546825   \n",
       "24  0.csv_Day7_12h00m  12.259184  17.972837  24.602896  29.206108  32.086597   \n",
       "25  0.csv_Day7_12h30m  11.664116  16.960072  23.584049  27.749851  31.522541   \n",
       "26  0.csv_Day7_13h00m  10.191174  16.064186  22.387798  25.843534  29.914156   \n",
       "27  0.csv_Day7_13h30m   8.338793  14.031995  20.028107  23.580259  26.111427   \n",
       "28  0.csv_Day7_14h00m   6.438894  11.798625  17.772745  20.204332  22.745476   \n",
       "29  0.csv_Day7_14h30m   4.642674   8.917039  14.868993  16.636839  19.511023   \n",
       "30  0.csv_Day7_15h00m   2.930609   6.400648  11.751292  12.728077  15.909344   \n",
       "31  0.csv_Day7_15h30m   1.649050   3.933033   8.617319   8.952081  11.080450   \n",
       "32  0.csv_Day7_16h00m   0.974194   1.807476   5.380528   5.751849   5.436456   \n",
       "33  0.csv_Day7_16h30m   0.201524   0.623902   3.130742   2.934508   1.469816   \n",
       "34  0.csv_Day7_17h00m  -0.015940  -0.053902   1.742528   0.971621   0.092404   \n",
       "35  0.csv_Day7_17h30m  -0.043710  -0.165341   1.029288   0.069415  -0.352298   \n",
       "36  0.csv_Day7_18h00m  -0.040556  -0.103839   0.429723  -0.155786  -0.193194   \n",
       "37  0.csv_Day7_18h30m  -0.057124  -0.022649   0.096232  -0.367589  -0.001791   \n",
       "38  0.csv_Day7_19h00m  -0.036151  -0.031596  -0.154644  -0.245674  -0.094616   \n",
       "39  0.csv_Day7_19h30m  -0.024918   0.039934  -0.078590  -0.166324  -0.043196   \n",
       "40  0.csv_Day7_20h00m  -0.039703  -0.014718   0.026451  -0.170821  -0.066030   \n",
       "41  0.csv_Day7_20h30m  -0.040474   0.047775  -0.007638  -0.075785  -0.143889   \n",
       "42  0.csv_Day7_21h00m  -0.044599   0.031964   0.016413  -0.013890   0.031991   \n",
       "43  0.csv_Day7_21h30m  -0.040397   0.017927  -0.026830  -0.018662  -0.084809   \n",
       "44  0.csv_Day7_22h00m  -0.021974   0.001427  -0.078171  -0.085914  -0.109154   \n",
       "45  0.csv_Day7_22h30m   0.002654  -0.031366  -0.034161  -0.092709  -0.065930   \n",
       "46  0.csv_Day7_23h00m   0.015975  -0.090818  -0.108225  -0.112969  -0.039415   \n",
       "47  0.csv_Day7_23h30m  -0.010059  -0.039430  -0.084664  -0.129694  -0.097498   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0   -0.022728  -0.108168   0.074562   0.595425  \n",
       "1    0.082372  -0.084517  -0.059915   1.063461  \n",
       "2    0.032507   0.035325   0.019248   1.504606  \n",
       "3    0.199537   0.171587   0.039975   1.511725  \n",
       "4    0.453990   0.407158   0.145288   1.324745  \n",
       "5    0.295865   0.312074   0.099051   0.968625  \n",
       "6    0.151301   0.406871   0.055930   0.957362  \n",
       "7   -0.038526   0.247233   0.030798   0.219046  \n",
       "8   -0.103541   0.319506   0.039582   0.495112  \n",
       "9    0.042954   0.484153   0.431663   0.559823  \n",
       "10   0.295156   0.441591   0.528161  -0.087109  \n",
       "11   0.324341   0.190489   0.708684   0.617961  \n",
       "12   0.096941   0.089325   1.246120   1.621673  \n",
       "13  -0.053907   0.441158   1.455138   3.089519  \n",
       "14   0.591490   1.744735   2.592998   5.093650  \n",
       "15   1.915306   4.540763   5.262686   8.937643  \n",
       "16   4.823846   8.629528   9.494079  13.571690  \n",
       "17   9.745342  14.793843  15.650631  19.707041  \n",
       "18  15.869155  20.750513  22.549725  26.517036  \n",
       "19  21.792852  27.005182  29.240368  34.093887  \n",
       "20  26.887941  33.066570  35.087997  40.060902  \n",
       "21  30.495989  37.841412  39.055458  44.992802  \n",
       "22  32.556499  41.089462  41.923168  48.452892  \n",
       "23  35.788204  43.759438  43.584980  49.854446  \n",
       "24  37.434673  44.159756  44.015755  50.155651  \n",
       "25  36.887539  44.263329  43.224564  48.869244  \n",
       "26  35.671467  42.116119  40.326588  46.095654  \n",
       "27  33.341022  38.915386  36.632172  42.542233  \n",
       "28  30.142757  34.384727  32.552292  37.896477  \n",
       "29  25.442408  28.204422  27.932016  32.630417  \n",
       "30  19.699924  20.741110  21.636147  25.989923  \n",
       "31  13.816643  14.024981  15.228221  19.284466  \n",
       "32   7.641447   8.822656   9.219543  12.351213  \n",
       "33   3.469676   5.192949   5.178250   7.116824  \n",
       "34   0.868362   2.794237   3.109246   3.915729  \n",
       "35  -0.082172   1.894108   2.155954   2.454201  \n",
       "36  -0.187773   1.143442   1.366849   1.423467  \n",
       "37  -0.059490   1.029982   0.804624   0.757860  \n",
       "38  -0.124035   0.505330   0.283033   0.461291  \n",
       "39  -0.143338   0.338303  -0.070067   0.242706  \n",
       "40  -0.101935   0.066204   0.110954   0.373869  \n",
       "41  -0.159693  -0.094389  -0.194270   0.490138  \n",
       "42  -0.052794   0.114666  -0.047797   0.169868  \n",
       "43  -0.035200   0.142241  -0.186230   0.260162  \n",
       "44  -0.090836  -0.059531  -0.018495   0.028261  \n",
       "45  -0.013743   0.116565   0.130139  -0.095092  \n",
       "46  -0.071323   0.076300   0.177514  -0.042162  \n",
       "47  -0.092663   0.146892   0.271685   0.165213  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[0:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"2D_cnn_rh_t_ghi_target_zero_2021_01_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.024459</td>\n",
       "      <td>0.248415</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.075851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.155249</td>\n",
       "      <td>0.416311</td>\n",
       "      <td>0.062507</td>\n",
       "      <td>0.153227</td>\n",
       "      <td>0.566945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108166</td>\n",
       "      <td>0.486160</td>\n",
       "      <td>0.026218</td>\n",
       "      <td>0.060943</td>\n",
       "      <td>0.833769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036263</td>\n",
       "      <td>0.393928</td>\n",
       "      <td>0.103710</td>\n",
       "      <td>0.115405</td>\n",
       "      <td>1.756800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039786</td>\n",
       "      <td>0.410431</td>\n",
       "      <td>0.120652</td>\n",
       "      <td>0.221357</td>\n",
       "      <td>1.862369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.268127</td>\n",
       "      <td>0.086977</td>\n",
       "      <td>0.189148</td>\n",
       "      <td>2.161273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154889</td>\n",
       "      <td>0.150176</td>\n",
       "      <td>0.191131</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>2.100234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366272</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.190883</td>\n",
       "      <td>0.131992</td>\n",
       "      <td>2.122616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264122</td>\n",
       "      <td>0.109683</td>\n",
       "      <td>1.861814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016423</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318891</td>\n",
       "      <td>0.108144</td>\n",
       "      <td>1.331446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090126</td>\n",
       "      <td>0.180337</td>\n",
       "      <td>0.070356</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.256771</td>\n",
       "      <td>0.662574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454358</td>\n",
       "      <td>0.245066</td>\n",
       "      <td>0.701513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.554959</td>\n",
       "      <td>0.252887</td>\n",
       "      <td>1.632933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021006</td>\n",
       "      <td>0.346317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560878</td>\n",
       "      <td>0.468717</td>\n",
       "      <td>2.488226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236164</td>\n",
       "      <td>1.175739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179268</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>1.033104</td>\n",
       "      <td>0.713560</td>\n",
       "      <td>3.242707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.578636</td>\n",
       "      <td>1.113971</td>\n",
       "      <td>3.224488</td>\n",
       "      <td>0.705005</td>\n",
       "      <td>1.601493</td>\n",
       "      <td>2.834792</td>\n",
       "      <td>2.456396</td>\n",
       "      <td>1.830976</td>\n",
       "      <td>5.948169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>0.857037</td>\n",
       "      <td>3.111234</td>\n",
       "      <td>6.391695</td>\n",
       "      <td>2.885820</td>\n",
       "      <td>4.275249</td>\n",
       "      <td>5.745633</td>\n",
       "      <td>5.974579</td>\n",
       "      <td>5.657425</td>\n",
       "      <td>11.137670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>1.089000</td>\n",
       "      <td>5.421488</td>\n",
       "      <td>9.667347</td>\n",
       "      <td>5.943766</td>\n",
       "      <td>7.380421</td>\n",
       "      <td>10.058351</td>\n",
       "      <td>11.702416</td>\n",
       "      <td>11.190063</td>\n",
       "      <td>17.317545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>2.835825</td>\n",
       "      <td>7.577049</td>\n",
       "      <td>13.517652</td>\n",
       "      <td>10.528769</td>\n",
       "      <td>12.282667</td>\n",
       "      <td>15.143912</td>\n",
       "      <td>18.044386</td>\n",
       "      <td>17.560671</td>\n",
       "      <td>23.464003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>5.718123</td>\n",
       "      <td>9.837213</td>\n",
       "      <td>17.245510</td>\n",
       "      <td>15.947038</td>\n",
       "      <td>18.756084</td>\n",
       "      <td>20.687981</td>\n",
       "      <td>24.770813</td>\n",
       "      <td>24.250671</td>\n",
       "      <td>30.012592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>9.088234</td>\n",
       "      <td>12.721240</td>\n",
       "      <td>20.291571</td>\n",
       "      <td>19.662510</td>\n",
       "      <td>24.832355</td>\n",
       "      <td>25.903341</td>\n",
       "      <td>30.357445</td>\n",
       "      <td>30.512123</td>\n",
       "      <td>35.444607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>11.865187</td>\n",
       "      <td>15.879188</td>\n",
       "      <td>23.074936</td>\n",
       "      <td>22.466448</td>\n",
       "      <td>29.583475</td>\n",
       "      <td>29.413542</td>\n",
       "      <td>34.560925</td>\n",
       "      <td>35.554855</td>\n",
       "      <td>39.786758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>14.164206</td>\n",
       "      <td>17.866051</td>\n",
       "      <td>25.465023</td>\n",
       "      <td>26.717970</td>\n",
       "      <td>33.263161</td>\n",
       "      <td>32.786831</td>\n",
       "      <td>36.976250</td>\n",
       "      <td>39.841385</td>\n",
       "      <td>43.009266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>15.847144</td>\n",
       "      <td>19.333908</td>\n",
       "      <td>26.346649</td>\n",
       "      <td>30.158176</td>\n",
       "      <td>35.428768</td>\n",
       "      <td>35.136528</td>\n",
       "      <td>38.788433</td>\n",
       "      <td>42.510258</td>\n",
       "      <td>44.458641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>16.395981</td>\n",
       "      <td>20.081894</td>\n",
       "      <td>26.681541</td>\n",
       "      <td>30.909370</td>\n",
       "      <td>35.086285</td>\n",
       "      <td>36.261780</td>\n",
       "      <td>39.741875</td>\n",
       "      <td>43.174759</td>\n",
       "      <td>44.588531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>16.447851</td>\n",
       "      <td>20.045219</td>\n",
       "      <td>26.500900</td>\n",
       "      <td>30.238354</td>\n",
       "      <td>34.017578</td>\n",
       "      <td>35.912167</td>\n",
       "      <td>39.257256</td>\n",
       "      <td>42.341366</td>\n",
       "      <td>42.907059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>15.216608</td>\n",
       "      <td>19.154551</td>\n",
       "      <td>25.775475</td>\n",
       "      <td>28.478827</td>\n",
       "      <td>32.038612</td>\n",
       "      <td>33.804379</td>\n",
       "      <td>36.871754</td>\n",
       "      <td>39.877983</td>\n",
       "      <td>40.596447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>13.839969</td>\n",
       "      <td>17.282318</td>\n",
       "      <td>23.972883</td>\n",
       "      <td>26.516737</td>\n",
       "      <td>29.632017</td>\n",
       "      <td>30.815773</td>\n",
       "      <td>32.948467</td>\n",
       "      <td>35.620346</td>\n",
       "      <td>36.998383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>11.777872</td>\n",
       "      <td>15.651600</td>\n",
       "      <td>21.363985</td>\n",
       "      <td>23.583805</td>\n",
       "      <td>27.355911</td>\n",
       "      <td>27.364347</td>\n",
       "      <td>29.410925</td>\n",
       "      <td>30.742031</td>\n",
       "      <td>32.750027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>9.521804</td>\n",
       "      <td>12.807563</td>\n",
       "      <td>18.079062</td>\n",
       "      <td>19.782211</td>\n",
       "      <td>23.140364</td>\n",
       "      <td>22.401583</td>\n",
       "      <td>24.732416</td>\n",
       "      <td>25.973129</td>\n",
       "      <td>26.549379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>6.930637</td>\n",
       "      <td>9.402040</td>\n",
       "      <td>13.785226</td>\n",
       "      <td>14.705339</td>\n",
       "      <td>17.838438</td>\n",
       "      <td>17.482220</td>\n",
       "      <td>19.861652</td>\n",
       "      <td>19.612658</td>\n",
       "      <td>19.780514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>4.548853</td>\n",
       "      <td>6.067210</td>\n",
       "      <td>9.284438</td>\n",
       "      <td>9.925286</td>\n",
       "      <td>11.913049</td>\n",
       "      <td>12.059415</td>\n",
       "      <td>13.552946</td>\n",
       "      <td>13.750473</td>\n",
       "      <td>12.843350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>2.327496</td>\n",
       "      <td>3.062645</td>\n",
       "      <td>5.296256</td>\n",
       "      <td>5.841122</td>\n",
       "      <td>6.681399</td>\n",
       "      <td>7.783895</td>\n",
       "      <td>8.140921</td>\n",
       "      <td>9.061798</td>\n",
       "      <td>7.381904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>0.860970</td>\n",
       "      <td>0.816270</td>\n",
       "      <td>2.740322</td>\n",
       "      <td>2.988168</td>\n",
       "      <td>3.218038</td>\n",
       "      <td>4.361392</td>\n",
       "      <td>4.164828</td>\n",
       "      <td>5.456505</td>\n",
       "      <td>3.817426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>0.212970</td>\n",
       "      <td>0.718535</td>\n",
       "      <td>1.138129</td>\n",
       "      <td>1.416115</td>\n",
       "      <td>2.101928</td>\n",
       "      <td>1.665654</td>\n",
       "      <td>2.802065</td>\n",
       "      <td>2.570606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.648864</td>\n",
       "      <td>0.522676</td>\n",
       "      <td>0.360717</td>\n",
       "      <td>1.142965</td>\n",
       "      <td>1.871365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408719</td>\n",
       "      <td>0.046687</td>\n",
       "      <td>0.298456</td>\n",
       "      <td>0.316156</td>\n",
       "      <td>1.031514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447460</td>\n",
       "      <td>0.191004</td>\n",
       "      <td>0.434409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284502</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.560612</td>\n",
       "      <td>0.125210</td>\n",
       "      <td>0.159216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186229</td>\n",
       "      <td>0.188963</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.290121</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093319</td>\n",
       "      <td>0.155530</td>\n",
       "      <td>0.452042</td>\n",
       "      <td>0.107292</td>\n",
       "      <td>0.200448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059194</td>\n",
       "      <td>0.050083</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065391</td>\n",
       "      <td>0.307254</td>\n",
       "      <td>0.229447</td>\n",
       "      <td>0.050596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.236222</td>\n",
       "      <td>0.245973</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.237142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323254</td>\n",
       "      <td>0.160147</td>\n",
       "      <td>0.232587</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.128856</td>\n",
       "      <td>0.124363</td>\n",
       "      <td>0.302809</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056548</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>0.028230</td>\n",
       "      <td>0.041192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426655</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m   0.000000   0.000000   0.000000   0.032120   0.024459   \n",
       "1    0.csv_Day7_0h30m   0.000000   0.000000   0.000000   0.003321   0.155249   \n",
       "2    0.csv_Day7_1h00m   0.000000   0.000000   0.000000   0.000000   0.108166   \n",
       "3    0.csv_Day7_1h30m   0.000000   0.000000   0.000000   0.000000   0.036263   \n",
       "4    0.csv_Day7_2h00m   0.000000   0.000000   0.000000   0.000000   0.039786   \n",
       "5    0.csv_Day7_2h30m   0.000000   0.000000   0.000000   0.000000   0.001158   \n",
       "6    0.csv_Day7_3h00m   0.000000   0.000000   0.000000   0.000000   0.154889   \n",
       "7    0.csv_Day7_3h30m   0.000000   0.000000   0.000000   0.000000   0.366272   \n",
       "8    0.csv_Day7_4h00m   0.000000   0.000000   0.011474   0.000000   0.277044   \n",
       "9    0.csv_Day7_4h30m   0.000000   0.000000   0.000000   0.016423   0.359771   \n",
       "10   0.csv_Day7_5h00m   0.000000   0.000000   0.000000   0.090126   0.180337   \n",
       "11   0.csv_Day7_5h30m   0.000000   0.000000   0.000000   0.141743   0.000000   \n",
       "12   0.csv_Day7_6h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13   0.csv_Day7_6h30m   0.000000   0.021006   0.346317   0.000000   0.017322   \n",
       "14   0.csv_Day7_7h00m   0.000000   0.236164   1.175739   0.000000   0.179268   \n",
       "15   0.csv_Day7_7h30m   0.578636   1.113971   3.224488   0.705005   1.601493   \n",
       "16   0.csv_Day7_8h00m   0.857037   3.111234   6.391695   2.885820   4.275249   \n",
       "17   0.csv_Day7_8h30m   1.089000   5.421488   9.667347   5.943766   7.380421   \n",
       "18   0.csv_Day7_9h00m   2.835825   7.577049  13.517652  10.528769  12.282667   \n",
       "19   0.csv_Day7_9h30m   5.718123   9.837213  17.245510  15.947038  18.756084   \n",
       "20  0.csv_Day7_10h00m   9.088234  12.721240  20.291571  19.662510  24.832355   \n",
       "21  0.csv_Day7_10h30m  11.865187  15.879188  23.074936  22.466448  29.583475   \n",
       "22  0.csv_Day7_11h00m  14.164206  17.866051  25.465023  26.717970  33.263161   \n",
       "23  0.csv_Day7_11h30m  15.847144  19.333908  26.346649  30.158176  35.428768   \n",
       "24  0.csv_Day7_12h00m  16.395981  20.081894  26.681541  30.909370  35.086285   \n",
       "25  0.csv_Day7_12h30m  16.447851  20.045219  26.500900  30.238354  34.017578   \n",
       "26  0.csv_Day7_13h00m  15.216608  19.154551  25.775475  28.478827  32.038612   \n",
       "27  0.csv_Day7_13h30m  13.839969  17.282318  23.972883  26.516737  29.632017   \n",
       "28  0.csv_Day7_14h00m  11.777872  15.651600  21.363985  23.583805  27.355911   \n",
       "29  0.csv_Day7_14h30m   9.521804  12.807563  18.079062  19.782211  23.140364   \n",
       "30  0.csv_Day7_15h00m   6.930637   9.402040  13.785226  14.705339  17.838438   \n",
       "31  0.csv_Day7_15h30m   4.548853   6.067210   9.284438   9.925286  11.913049   \n",
       "32  0.csv_Day7_16h00m   2.327496   3.062645   5.296256   5.841122   6.681399   \n",
       "33  0.csv_Day7_16h30m   0.860970   0.816270   2.740322   2.988168   3.218038   \n",
       "34  0.csv_Day7_17h00m   0.054211   0.212970   0.718535   1.138129   1.416115   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.223529   0.025157   0.648864   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.408719   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.328722   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.032109   0.000000   0.284502   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.007990   0.000000   0.000000   0.186229   \n",
       "40  0.csv_Day7_20h00m   0.000000   0.000000   0.005730   0.000000   0.093319   \n",
       "41  0.csv_Day7_20h30m   0.000000   0.001156   0.000000   0.000000   0.059194   \n",
       "42  0.csv_Day7_21h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "43  0.csv_Day7_21h30m   0.000000   0.000000   0.000000   0.000000   0.007486   \n",
       "44  0.csv_Day7_22h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "45  0.csv_Day7_22h30m   0.000000   0.000000   0.000000   0.015605   0.005552   \n",
       "46  0.csv_Day7_23h00m   0.000000   0.000000   0.041830   0.000000   0.000000   \n",
       "47  0.csv_Day7_23h30m   0.000000   0.000000   0.056548   0.027014   0.028230   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.248415   0.019367   0.075851   0.000000  \n",
       "1    0.416311   0.062507   0.153227   0.566945  \n",
       "2    0.486160   0.026218   0.060943   0.833769  \n",
       "3    0.393928   0.103710   0.115405   1.756800  \n",
       "4    0.410431   0.120652   0.221357   1.862369  \n",
       "5    0.268127   0.086977   0.189148   2.161273  \n",
       "6    0.150176   0.191131   0.309339   2.100234  \n",
       "7    0.028479   0.190883   0.131992   2.122616  \n",
       "8    0.000000   0.264122   0.109683   1.861814  \n",
       "9    0.000000   0.318891   0.108144   1.331446  \n",
       "10   0.070356   0.290400   0.256771   0.662574  \n",
       "11   0.000000   0.454358   0.245066   0.701513  \n",
       "12   0.000000   0.554959   0.252887   1.632933  \n",
       "13   0.000000   0.560878   0.468717   2.488226  \n",
       "14   0.765857   1.033104   0.713560   3.242707  \n",
       "15   2.834792   2.456396   1.830976   5.948169  \n",
       "16   5.745633   5.974579   5.657425  11.137670  \n",
       "17  10.058351  11.702416  11.190063  17.317545  \n",
       "18  15.143912  18.044386  17.560671  23.464003  \n",
       "19  20.687981  24.770813  24.250671  30.012592  \n",
       "20  25.903341  30.357445  30.512123  35.444607  \n",
       "21  29.413542  34.560925  35.554855  39.786758  \n",
       "22  32.786831  36.976250  39.841385  43.009266  \n",
       "23  35.136528  38.788433  42.510258  44.458641  \n",
       "24  36.261780  39.741875  43.174759  44.588531  \n",
       "25  35.912167  39.257256  42.341366  42.907059  \n",
       "26  33.804379  36.871754  39.877983  40.596447  \n",
       "27  30.815773  32.948467  35.620346  36.998383  \n",
       "28  27.364347  29.410925  30.742031  32.750027  \n",
       "29  22.401583  24.732416  25.973129  26.549379  \n",
       "30  17.482220  19.861652  19.612658  19.780514  \n",
       "31  12.059415  13.552946  13.750473  12.843350  \n",
       "32   7.783895   8.140921   9.061798   7.381904  \n",
       "33   4.361392   4.164828   5.456505   3.817426  \n",
       "34   2.101928   1.665654   2.802065   2.570606  \n",
       "35   0.522676   0.360717   1.142965   1.871365  \n",
       "36   0.046687   0.298456   0.316156   1.031514  \n",
       "37   0.000000   0.447460   0.191004   0.434409  \n",
       "38   0.156480   0.560612   0.125210   0.159216  \n",
       "39   0.188963   0.503301   0.290121   0.000000  \n",
       "40   0.155530   0.452042   0.107292   0.200448  \n",
       "41   0.050083   0.314010   0.000000   0.145911  \n",
       "42   0.065391   0.307254   0.229447   0.050596  \n",
       "43   0.236222   0.245973   0.050950   0.237142  \n",
       "44   0.323254   0.160147   0.232587   0.000000  \n",
       "45   0.128856   0.124363   0.302809   0.000000  \n",
       "46   0.000000   0.000000   0.300983   0.000000  \n",
       "47   0.041192   0.000000   0.426655   0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 0] = 0\n",
    "submission_df[0:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.3: [1.505661964416504,\n",
       "  3.5561978816986084,\n",
       "  56.22322082519531,\n",
       "  1.5056190490722656]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{0.3: [1.59465754032135,\n",
    "  3.8922789096832275,\n",
    "  62.40233612060547,\n",
    "  1.5945602655410767]}\n",
    "{0.3: [1.5206161737442017,\n",
    "  3.520108461380005,\n",
    "  55.35062026977539,\n",
    "  1.5206190347671509]}\n",
    "{0.3: [1.505661964416504,\n",
    "  3.5561978816986084,\n",
    "  56.22322082519531,\n",
    "  1.5056190490722656]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.075737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051865</td>\n",
       "      <td>0.429422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125713</td>\n",
       "      <td>0.132835</td>\n",
       "      <td>0.425520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341038</td>\n",
       "      <td>0.397704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165248</td>\n",
       "      <td>0.049708</td>\n",
       "      <td>0.367383</td>\n",
       "      <td>0.262605</td>\n",
       "      <td>0.636854</td>\n",
       "      <td>0.203558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.617736</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.385116</td>\n",
       "      <td>0.566612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.013990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323615</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.554969</td>\n",
       "      <td>0.536913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123434</td>\n",
       "      <td>0.237913</td>\n",
       "      <td>0.787921</td>\n",
       "      <td>0.529678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692273</td>\n",
       "      <td>0.418214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085588</td>\n",
       "      <td>0.066988</td>\n",
       "      <td>1.056911</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004436</td>\n",
       "      <td>0.149318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960197</td>\n",
       "      <td>0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187459</td>\n",
       "      <td>1.003103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843586</td>\n",
       "      <td>0.065198</td>\n",
       "      <td>2.301388</td>\n",
       "      <td>2.199021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492276</td>\n",
       "      <td>2.665259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316023</td>\n",
       "      <td>2.723710</td>\n",
       "      <td>1.775952</td>\n",
       "      <td>3.998145</td>\n",
       "      <td>5.423578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.589180</td>\n",
       "      <td>4.855118</td>\n",
       "      <td>0.778672</td>\n",
       "      <td>2.880782</td>\n",
       "      <td>5.520342</td>\n",
       "      <td>6.410540</td>\n",
       "      <td>7.064509</td>\n",
       "      <td>11.412713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.761744</td>\n",
       "      <td>7.857065</td>\n",
       "      <td>4.049734</td>\n",
       "      <td>6.125292</td>\n",
       "      <td>9.419258</td>\n",
       "      <td>12.569093</td>\n",
       "      <td>13.103045</td>\n",
       "      <td>17.501560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.051432</td>\n",
       "      <td>11.461951</td>\n",
       "      <td>8.429073</td>\n",
       "      <td>10.919353</td>\n",
       "      <td>14.156559</td>\n",
       "      <td>19.976631</td>\n",
       "      <td>20.243694</td>\n",
       "      <td>23.619379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>9.290476</td>\n",
       "      <td>15.885969</td>\n",
       "      <td>13.368224</td>\n",
       "      <td>15.005770</td>\n",
       "      <td>19.588079</td>\n",
       "      <td>26.758629</td>\n",
       "      <td>27.184805</td>\n",
       "      <td>29.851683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     q_0.1     q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0   0.csv_Day7_0h00m  0.000000  0.000000   0.000000   0.000000   0.018542   \n",
       "1   0.csv_Day7_0h30m  0.000000  0.022888   0.000000   0.000000   0.000000   \n",
       "2   0.csv_Day7_1h00m  0.000000  0.000000   0.006969   0.075737   0.000000   \n",
       "3   0.csv_Day7_1h30m  0.000000  0.002482   0.000000   0.149559   0.000000   \n",
       "4   0.csv_Day7_2h00m  0.000000  0.004925   0.000000   0.125713   0.132835   \n",
       "5   0.csv_Day7_2h30m  0.000000  0.005199   0.000000   0.165248   0.049708   \n",
       "6   0.csv_Day7_3h00m  0.000056  0.000000   0.000000   0.000000   0.035667   \n",
       "7   0.csv_Day7_3h30m  0.000058  0.013990   0.000000   0.000000   0.000000   \n",
       "8   0.csv_Day7_4h00m  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "9   0.csv_Day7_4h30m  0.000128  0.000000   0.000000   0.000000   0.000000   \n",
       "10  0.csv_Day7_5h00m  0.000000  0.009108   0.000000   0.000000   0.000000   \n",
       "11  0.csv_Day7_5h30m  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "12  0.csv_Day7_6h00m  0.000000  0.012701   0.000000   0.000000   0.000000   \n",
       "13  0.csv_Day7_6h30m  0.000043  0.000000   0.292543   0.000000   0.000000   \n",
       "14  0.csv_Day7_7h00m  0.000161  0.000000   1.142528   0.000000   0.000000   \n",
       "15  0.csv_Day7_7h30m  0.000000  0.492276   2.665259   0.000000   0.316023   \n",
       "16  0.csv_Day7_8h00m  0.000076  1.589180   4.855118   0.778672   2.880782   \n",
       "17  0.csv_Day7_8h30m  0.000000  3.761744   7.857065   4.049734   6.125292   \n",
       "18  0.csv_Day7_9h00m  0.000000  6.051432  11.461951   8.429073  10.919353   \n",
       "19  0.csv_Day7_9h30m  0.000333  9.290476  15.885969  13.368224  15.005770   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000000   0.006062   0.000000   0.131488  \n",
       "1    0.000000   0.000000   0.000000   0.073663  \n",
       "2    0.000000   0.000000   0.000000   0.665925  \n",
       "3    0.174456   0.000000   0.051865   0.429422  \n",
       "4    0.425520   0.000000   0.341038   0.397704  \n",
       "5    0.367383   0.262605   0.636854   0.203558  \n",
       "6    0.617736   0.207500   0.385116   0.566612  \n",
       "7    0.323615   0.231200   0.554969   0.536913  \n",
       "8    0.123434   0.237913   0.787921   0.529678  \n",
       "9    0.036401   0.000000   0.692273   0.418214  \n",
       "10   0.085588   0.066988   1.056911   0.000000  \n",
       "11   0.086340   0.000000   1.004436   0.149318  \n",
       "12   0.038318   0.000000   0.960197   0.274340  \n",
       "13   0.145326   0.000000   1.187459   1.003103  \n",
       "14   0.843586   0.065198   2.301388   2.199021  \n",
       "15   2.723710   1.775952   3.998145   5.423578  \n",
       "16   5.520342   6.410540   7.064509  11.412713  \n",
       "17   9.419258  12.569093  13.103045  17.501560  \n",
       "18  14.156559  19.976631  20.243694  23.619379  \n",
       "19  19.588079  26.758629  27.184805  29.851683  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 0] = 0\n",
    "\n",
    "submission_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{0.1: [0.8983700275421143,\n",
    "  6.469372272491455,\n",
    "  157.601806640625,\n",
    "  0.898374617099762]}  \n",
    "  {0.1: [0.8474237322807312,\n",
    "  6.678616046905518,\n",
    "  168.7744140625,\n",
    "  0.8474520444869995]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 9), (10511, 9), (5257, 9)\n",
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 16), (10511, 16), (5257, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>GHI</th>\n",
       "      <th>TARGET_ROLLING_MEAN_3_shift_1</th>\n",
       "      <th>TARGET_ROLLING_MEAN_5_shift_2</th>\n",
       "      <th>TARGET_ROLLING_MEAN_11_shift_5</th>\n",
       "      <th>TARGET_ROLLING_MEAN_23_shift_11</th>\n",
       "      <th>TARGET_ROLLING_MEAN_47_shift_23</th>\n",
       "      <th>scaled_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>3.679200e+04</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>3.679200e+04</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "      <td>36792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.119412</td>\n",
       "      <td>0.219731</td>\n",
       "      <td>0.201327</td>\n",
       "      <td>0.542351</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>17.439978</td>\n",
       "      <td>0.507046</td>\n",
       "      <td>0.522326</td>\n",
       "      <td>0.500206</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.267026</td>\n",
       "      <td>1.754282e-01</td>\n",
       "      <td>0.177078</td>\n",
       "      <td>1.873781e-01</td>\n",
       "      <td>0.239824</td>\n",
       "      <td>0.469365</td>\n",
       "      <td>0.174550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.194232</td>\n",
       "      <td>0.330292</td>\n",
       "      <td>0.117052</td>\n",
       "      <td>0.234989</td>\n",
       "      <td>0.192822</td>\n",
       "      <td>25.449577</td>\n",
       "      <td>0.346981</td>\n",
       "      <td>0.359263</td>\n",
       "      <td>0.353558</td>\n",
       "      <td>0.353558</td>\n",
       "      <td>0.263381</td>\n",
       "      <td>2.493108e-01</td>\n",
       "      <td>0.245816</td>\n",
       "      <td>2.357651e-01</td>\n",
       "      <td>0.221283</td>\n",
       "      <td>0.211497</td>\n",
       "      <td>0.254715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.364896</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159610</td>\n",
       "      <td>0.158025</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.088432</td>\n",
       "      <td>3.356260e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.852145e-16</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>0.297058</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.553620</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530107</td>\n",
       "      <td>0.536539</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.088432</td>\n",
       "      <td>1.006823e-02</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>7.214131e-02</td>\n",
       "      <td>0.186432</td>\n",
       "      <td>0.447393</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.160985</td>\n",
       "      <td>0.430831</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.711963</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>31.085053</td>\n",
       "      <td>0.840390</td>\n",
       "      <td>0.891488</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>3.152806e-01</td>\n",
       "      <td>0.319378</td>\n",
       "      <td>3.256305e-01</td>\n",
       "      <td>0.378664</td>\n",
       "      <td>0.634329</td>\n",
       "      <td>0.311118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.913939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DHI           DNI            WS            RH             T  \\\n",
       "count  36792.000000  36792.000000  36792.000000  36792.000000  36792.000000   \n",
       "mean       0.119412      0.219731      0.201327      0.542351      0.512100   \n",
       "std        0.194232      0.330292      0.117052      0.234989      0.192822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.116667      0.364896      0.351852   \n",
       "50%        0.000000      0.000000      0.183333      0.553620      0.500000   \n",
       "75%        0.160985      0.430831      0.258333      0.711963      0.648148   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             TARGET       Day_sin       Day_cos      Hour_sin      Hour_cos  \\\n",
       "count  36792.000000  36792.000000  36792.000000  36792.000000  36792.000000   \n",
       "mean      17.439978      0.507046      0.522326      0.500206      0.500027   \n",
       "std       25.449577      0.346981      0.359263      0.353558      0.353558   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.159610      0.158025      0.146447      0.146447   \n",
       "50%        0.000000      0.530107      0.536539      0.500000      0.500000   \n",
       "75%       31.085053      0.840390      0.891488      0.853553      0.853553   \n",
       "max       99.913939      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                GHI  TARGET_ROLLING_MEAN_3_shift_1  \\\n",
       "count  36792.000000                   3.679200e+04   \n",
       "mean       0.267026                   1.754282e-01   \n",
       "std        0.263381                   2.493108e-01   \n",
       "min        0.000000                   0.000000e+00   \n",
       "25%        0.088432                   3.356260e-15   \n",
       "50%        0.088432                   1.006823e-02   \n",
       "75%        0.415900                   3.152806e-01   \n",
       "max        1.000000                   1.000000e+00   \n",
       "\n",
       "       TARGET_ROLLING_MEAN_5_shift_2  TARGET_ROLLING_MEAN_11_shift_5  \\\n",
       "count                   36792.000000                    3.679200e+04   \n",
       "mean                        0.177078                    1.873781e-01   \n",
       "std                         0.245816                    2.357651e-01   \n",
       "min                         0.000000                    0.000000e+00   \n",
       "25%                         0.000000                    1.852145e-16   \n",
       "50%                         0.023250                    7.214131e-02   \n",
       "75%                         0.319378                    3.256305e-01   \n",
       "max                         1.000000                    1.000000e+00   \n",
       "\n",
       "       TARGET_ROLLING_MEAN_23_shift_11  TARGET_ROLLING_MEAN_47_shift_23  \\\n",
       "count                     36792.000000                     36792.000000   \n",
       "mean                          0.239824                         0.469365   \n",
       "std                           0.221283                         0.211497   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           0.044158                         0.297058   \n",
       "50%                           0.186432                         0.447393   \n",
       "75%                           0.378664                         0.634329   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       scaled_TARGET  \n",
       "count   36792.000000  \n",
       "mean        0.174550  \n",
       "std         0.254715  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.311118  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, valid_df, test_df = split_train_valid_test(df, [0.7, 0.2, 0.1])\n",
    "\n",
    "train_df_target = train_df[\"TARGET\"]\n",
    "valid_df_target = valid_df[\"TARGET\"]\n",
    "test_df_target = test_df[\"TARGET\"]\n",
    "\n",
    "train_df, valid_df, test_df = load_basic_preprocessed_train(\"minmax\")\n",
    "\n",
    "train_df[\"scaled_TARGET\"] = train_df[\"TARGET\"]\n",
    "valid_df[\"scaled_TARGET\"] = valid_df[\"TARGET\"]\n",
    "test_df[\"scaled_TARGET\"] = test_df[\"TARGET\"]\n",
    "\n",
    "train_df[\"TARGET\"] = train_df_target\n",
    "valid_df[\"TARGET\"] = valid_df_target\n",
    "test_df[\"TARGET\"] = test_df_target\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = [\n",
    "    'DHI', \n",
    "    'DNI', \n",
    "     'WS', \n",
    "    'RH', \n",
    "    'T', \n",
    "     'Hour_sin',\n",
    "     'Hour_cos', \n",
    "    'GHI', \n",
    "     'TARGET_ROLLING_MEAN_3_shift_1',\n",
    "     'TARGET_ROLLING_MEAN_5_shift_2', \n",
    "     'TARGET_ROLLING_MEAN_11_shift_5',\n",
    "     'TARGET_ROLLING_MEAN_23_shift_11', \n",
    "     'TARGET_ROLLING_MEAN_47_shift_23',\n",
    "    'scaled_TARGET',\n",
    "    \"TARGET\",\n",
    "]\n",
    "train_df = train_df[cutter]\n",
    "valid_df = valid_df[cutter]\n",
    "test_df = test_df[cutter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 16), (10511, 16), (5257, 16)\n",
      "0.1\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 26s 16ms/step - loss: 1.5047 - mean_absolute_error: 13.6584 - mean_squared_error: 598.4279 - _pinball_loss: 1.5047 - val_loss: 1.6736 - val_mean_absolute_error: 13.5540 - val_mean_squared_error: 529.3325 - val__pinball_loss: 1.6736\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.2991 - mean_absolute_error: 10.7893 - mean_squared_error: 383.3972 - _pinball_loss: 1.2991 - val_loss: 1.6314 - val_mean_absolute_error: 13.0589 - val_mean_squared_error: 508.9373 - val__pinball_loss: 1.6314\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.2680 - mean_absolute_error: 10.4794 - mean_squared_error: 370.3380 - _pinball_loss: 1.2680 - val_loss: 1.6104 - val_mean_absolute_error: 13.0681 - val_mean_squared_error: 510.0778 - val__pinball_loss: 1.6104\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.2468 - mean_absolute_error: 10.2531 - mean_squared_error: 360.4882 - _pinball_loss: 1.2468 - val_loss: 1.5981 - val_mean_absolute_error: 12.9394 - val_mean_squared_error: 505.4697 - val__pinball_loss: 1.5981\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.2321 - mean_absolute_error: 10.1290 - mean_squared_error: 355.5213 - _pinball_loss: 1.2321 - val_loss: 1.5804 - val_mean_absolute_error: 12.7439 - val_mean_squared_error: 493.8891 - val__pinball_loss: 1.5804\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 12s 10ms/step - loss: 1.2201 - mean_absolute_error: 9.9983 - mean_squared_error: 350.0172 - _pinball_loss: 1.2201 - val_loss: 1.5752 - val_mean_absolute_error: 12.7930 - val_mean_squared_error: 496.1561 - val__pinball_loss: 1.5752\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.2124 - mean_absolute_error: 9.9334 - mean_squared_error: 347.6757 - _pinball_loss: 1.2124 - val_loss: 1.5625 - val_mean_absolute_error: 12.5509 - val_mean_squared_error: 489.6274 - val__pinball_loss: 1.5625\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.2048 - mean_absolute_error: 9.8721 - mean_squared_error: 345.6752 - _pinball_loss: 1.2048 - val_loss: 1.5600 - val_mean_absolute_error: 12.6697 - val_mean_squared_error: 496.2101 - val__pinball_loss: 1.5600\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1973 - mean_absolute_error: 9.8275 - mean_squared_error: 343.8624 - _pinball_loss: 1.1973 - val_loss: 1.5592 - val_mean_absolute_error: 12.3898 - val_mean_squared_error: 479.4992 - val__pinball_loss: 1.5592\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1908 - mean_absolute_error: 9.7592 - mean_squared_error: 341.1013 - _pinball_loss: 1.1908 - val_loss: 1.5536 - val_mean_absolute_error: 12.3858 - val_mean_squared_error: 474.9269 - val__pinball_loss: 1.5536\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1850 - mean_absolute_error: 9.7101 - mean_squared_error: 338.9691 - _pinball_loss: 1.1850 - val_loss: 1.5590 - val_mean_absolute_error: 12.7964 - val_mean_squared_error: 502.6900 - val__pinball_loss: 1.5590\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1792 - mean_absolute_error: 9.6721 - mean_squared_error: 337.8264 - _pinball_loss: 1.1792 - val_loss: 1.5563 - val_mean_absolute_error: 12.3402 - val_mean_squared_error: 475.9934 - val__pinball_loss: 1.5563\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1754 - mean_absolute_error: 9.6532 - mean_squared_error: 337.2619 - _pinball_loss: 1.1754 - val_loss: 1.5459 - val_mean_absolute_error: 12.3764 - val_mean_squared_error: 484.8332 - val__pinball_loss: 1.5459\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1693 - mean_absolute_error: 9.5936 - mean_squared_error: 334.2650 - _pinball_loss: 1.1693 - val_loss: 1.5632 - val_mean_absolute_error: 11.8496 - val_mean_squared_error: 449.3615 - val__pinball_loss: 1.5632\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1670 - mean_absolute_error: 9.5545 - mean_squared_error: 332.1129 - _pinball_loss: 1.1670 - val_loss: 1.5475 - val_mean_absolute_error: 12.3463 - val_mean_squared_error: 475.6871 - val__pinball_loss: 1.5475\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1613 - mean_absolute_error: 9.5272 - mean_squared_error: 331.0920 - _pinball_loss: 1.1613 - val_loss: 1.5426 - val_mean_absolute_error: 12.5277 - val_mean_squared_error: 487.3673 - val__pinball_loss: 1.5426\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1572 - mean_absolute_error: 9.4948 - mean_squared_error: 329.7560 - _pinball_loss: 1.1572 - val_loss: 1.5416 - val_mean_absolute_error: 12.4091 - val_mean_squared_error: 488.8802 - val__pinball_loss: 1.5416\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1539 - mean_absolute_error: 9.4633 - mean_squared_error: 328.1390 - _pinball_loss: 1.1539 - val_loss: 1.5369 - val_mean_absolute_error: 12.2544 - val_mean_squared_error: 473.6070 - val__pinball_loss: 1.5369\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1474 - mean_absolute_error: 9.4069 - mean_squared_error: 325.5197 - _pinball_loss: 1.1474 - val_loss: 1.5518 - val_mean_absolute_error: 11.8083 - val_mean_squared_error: 447.1150 - val__pinball_loss: 1.5518\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1447 - mean_absolute_error: 9.3719 - mean_squared_error: 323.7652 - _pinball_loss: 1.1447 - val_loss: 1.5318 - val_mean_absolute_error: 12.4882 - val_mean_squared_error: 491.2029 - val__pinball_loss: 1.5318\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1404 - mean_absolute_error: 9.3550 - mean_squared_error: 323.1269 - _pinball_loss: 1.1404 - val_loss: 1.5428 - val_mean_absolute_error: 11.8752 - val_mean_squared_error: 451.9731 - val__pinball_loss: 1.5428\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1390 - mean_absolute_error: 9.3356 - mean_squared_error: 321.9957 - _pinball_loss: 1.1390 - val_loss: 1.5333 - val_mean_absolute_error: 11.8237 - val_mean_squared_error: 447.8629 - val__pinball_loss: 1.5333\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1324 - mean_absolute_error: 9.2810 - mean_squared_error: 319.8773 - _pinball_loss: 1.1324 - val_loss: 1.5311 - val_mean_absolute_error: 12.3723 - val_mean_squared_error: 483.9882 - val__pinball_loss: 1.5311\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1296 - mean_absolute_error: 9.2502 - mean_squared_error: 317.3194 - _pinball_loss: 1.1296 - val_loss: 1.5313 - val_mean_absolute_error: 11.9829 - val_mean_squared_error: 460.0618 - val__pinball_loss: 1.5313\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1257 - mean_absolute_error: 9.2137 - mean_squared_error: 315.8439 - _pinball_loss: 1.1257 - val_loss: 1.5376 - val_mean_absolute_error: 11.8525 - val_mean_squared_error: 451.9845 - val__pinball_loss: 1.5376\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.1210 - mean_absolute_error: 9.1574 - mean_squared_error: 312.9481 - _pinball_loss: 1.1210 - val_loss: 1.5403 - val_mean_absolute_error: 12.0412 - val_mean_squared_error: 463.9633 - val__pinball_loss: 1.5403\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000267816A8F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 12s 10ms/step - loss: 2.6045 - mean_absolute_error: 10.9928 - mean_squared_error: 406.7802 - _pinball_loss: 2.6045 - val_loss: 2.7202 - val_mean_absolute_error: 9.6590 - val_mean_squared_error: 278.3925 - val__pinball_loss: 2.7202\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 2.0939 - mean_absolute_error: 7.8009 - mean_squared_error: 205.6968 - _pinball_loss: 2.0939 - val_loss: 2.6421 - val_mean_absolute_error: 9.5834 - val_mean_squared_error: 279.3486 - val__pinball_loss: 2.6421\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.0289 - mean_absolute_error: 7.5192 - mean_squared_error: 198.3588 - _pinball_loss: 2.0289 - val_loss: 2.6058 - val_mean_absolute_error: 9.6657 - val_mean_squared_error: 287.0864 - val__pinball_loss: 2.6058\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9991 - mean_absolute_error: 7.4039 - mean_squared_error: 195.7076 - _pinball_loss: 1.9991 - val_loss: 2.5546 - val_mean_absolute_error: 9.3270 - val_mean_squared_error: 275.0760 - val__pinball_loss: 2.5546\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9707 - mean_absolute_error: 7.2776 - mean_squared_error: 192.3399 - _pinball_loss: 1.9707 - val_loss: 2.5359 - val_mean_absolute_error: 9.0735 - val_mean_squared_error: 266.4058 - val__pinball_loss: 2.5359\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9520 - mean_absolute_error: 7.2105 - mean_squared_error: 190.6654 - _pinball_loss: 1.9520 - val_loss: 2.5000 - val_mean_absolute_error: 9.2299 - val_mean_squared_error: 276.4506 - val__pinball_loss: 2.5000\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9357 - mean_absolute_error: 7.1622 - mean_squared_error: 190.1814 - _pinball_loss: 1.9357 - val_loss: 2.4963 - val_mean_absolute_error: 9.3532 - val_mean_squared_error: 284.3462 - val__pinball_loss: 2.4963\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9217 - mean_absolute_error: 7.0998 - mean_squared_error: 187.9885 - _pinball_loss: 1.9217 - val_loss: 2.4876 - val_mean_absolute_error: 9.4526 - val_mean_squared_error: 290.5293 - val__pinball_loss: 2.4876\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9109 - mean_absolute_error: 7.0582 - mean_squared_error: 186.7677 - _pinball_loss: 1.9109 - val_loss: 2.4884 - val_mean_absolute_error: 8.7201 - val_mean_squared_error: 256.6643 - val__pinball_loss: 2.4884\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9023 - mean_absolute_error: 7.0137 - mean_squared_error: 185.4878 - _pinball_loss: 1.9023 - val_loss: 2.4541 - val_mean_absolute_error: 9.1804 - val_mean_squared_error: 278.8311 - val__pinball_loss: 2.4541\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8922 - mean_absolute_error: 6.9777 - mean_squared_error: 184.5911 - _pinball_loss: 1.8922 - val_loss: 2.4559 - val_mean_absolute_error: 9.3750 - val_mean_squared_error: 287.1664 - val__pinball_loss: 2.4559\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8846 - mean_absolute_error: 6.9587 - mean_squared_error: 184.3216 - _pinball_loss: 1.8846 - val_loss: 2.4514 - val_mean_absolute_error: 9.1875 - val_mean_squared_error: 284.0271 - val__pinball_loss: 2.4514\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8760 - mean_absolute_error: 6.9168 - mean_squared_error: 182.8774 - _pinball_loss: 1.8760 - val_loss: 2.4352 - val_mean_absolute_error: 8.7806 - val_mean_squared_error: 259.0623 - val__pinball_loss: 2.4352\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8675 - mean_absolute_error: 6.8859 - mean_squared_error: 181.7632 - _pinball_loss: 1.8675 - val_loss: 2.4302 - val_mean_absolute_error: 9.1326 - val_mean_squared_error: 278.3347 - val__pinball_loss: 2.4302\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.8622 - mean_absolute_error: 6.8508 - mean_squared_error: 180.3194 - _pinball_loss: 1.8622 - val_loss: 2.4318 - val_mean_absolute_error: 9.0640 - val_mean_squared_error: 274.1381 - val__pinball_loss: 2.4318\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8562 - mean_absolute_error: 6.8370 - mean_squared_error: 179.6814 - _pinball_loss: 1.8562 - val_loss: 2.4313 - val_mean_absolute_error: 8.9804 - val_mean_squared_error: 271.5995 - val__pinball_loss: 2.4313\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8473 - mean_absolute_error: 6.7877 - mean_squared_error: 177.8088 - _pinball_loss: 1.8473 - val_loss: 2.4282 - val_mean_absolute_error: 9.0737 - val_mean_squared_error: 272.3094 - val__pinball_loss: 2.4282\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8391 - mean_absolute_error: 6.7669 - mean_squared_error: 177.1095 - _pinball_loss: 1.8391 - val_loss: 2.4199 - val_mean_absolute_error: 8.8080 - val_mean_squared_error: 262.2791 - val__pinball_loss: 2.4199\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8335 - mean_absolute_error: 6.7442 - mean_squared_error: 176.6241 - _pinball_loss: 1.8335 - val_loss: 2.4181 - val_mean_absolute_error: 8.7907 - val_mean_squared_error: 260.2855 - val__pinball_loss: 2.4181\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8260 - mean_absolute_error: 6.7122 - mean_squared_error: 175.3270 - _pinball_loss: 1.8260 - val_loss: 2.4251 - val_mean_absolute_error: 8.5067 - val_mean_squared_error: 249.2532 - val__pinball_loss: 2.4251\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8178 - mean_absolute_error: 6.6747 - mean_squared_error: 174.3109 - _pinball_loss: 1.8178 - val_loss: 2.4212 - val_mean_absolute_error: 8.7361 - val_mean_squared_error: 261.4553 - val__pinball_loss: 2.4212\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8120 - mean_absolute_error: 6.6596 - mean_squared_error: 173.1317 - _pinball_loss: 1.8120 - val_loss: 2.4142 - val_mean_absolute_error: 8.8076 - val_mean_squared_error: 266.5725 - val__pinball_loss: 2.4142\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8064 - mean_absolute_error: 6.6570 - mean_squared_error: 173.9667 - _pinball_loss: 1.8064 - val_loss: 2.4098 - val_mean_absolute_error: 8.6748 - val_mean_squared_error: 254.4124 - val__pinball_loss: 2.4098\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8008 - mean_absolute_error: 6.6178 - mean_squared_error: 171.8236 - _pinball_loss: 1.8008 - val_loss: 2.4243 - val_mean_absolute_error: 8.8667 - val_mean_squared_error: 267.0129 - val__pinball_loss: 2.4243\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.7960 - mean_absolute_error: 6.6157 - mean_squared_error: 171.9695 - _pinball_loss: 1.7960 - val_loss: 2.4199 - val_mean_absolute_error: 8.5215 - val_mean_squared_error: 250.2938 - val__pinball_loss: 2.4199\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.7855 - mean_absolute_error: 6.5708 - mean_squared_error: 170.7061 - _pinball_loss: 1.7855 - val_loss: 2.4226 - val_mean_absolute_error: 8.7689 - val_mean_squared_error: 261.5353 - val__pinball_loss: 2.4226\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000269F5CC75E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 3.3975 - mean_absolute_error: 9.4513 - mean_squared_error: 314.3611 - _pinball_loss: 3.3975 - val_loss: 3.2831 - val_mean_absolute_error: 8.0008 - val_mean_squared_error: 197.7634 - val__pinball_loss: 3.2831\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5413 - mean_absolute_error: 6.2413 - mean_squared_error: 137.6738 - _pinball_loss: 2.5413 - val_loss: 3.1681 - val_mean_absolute_error: 7.5629 - val_mean_squared_error: 187.2613 - val__pinball_loss: 3.1681\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4609 - mean_absolute_error: 6.0198 - mean_squared_error: 132.8116 - _pinball_loss: 2.4609 - val_loss: 3.1186 - val_mean_absolute_error: 7.5807 - val_mean_squared_error: 188.1870 - val__pinball_loss: 3.1186\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4115 - mean_absolute_error: 5.8882 - mean_squared_error: 129.9067 - _pinball_loss: 2.4115 - val_loss: 3.0647 - val_mean_absolute_error: 7.3704 - val_mean_squared_error: 184.5678 - val__pinball_loss: 3.0647\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3793 - mean_absolute_error: 5.8097 - mean_squared_error: 128.1167 - _pinball_loss: 2.3793 - val_loss: 3.0215 - val_mean_absolute_error: 7.3786 - val_mean_squared_error: 184.4928 - val__pinball_loss: 3.0215\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3527 - mean_absolute_error: 5.7482 - mean_squared_error: 126.8111 - _pinball_loss: 2.3527 - val_loss: 3.0381 - val_mean_absolute_error: 7.1962 - val_mean_squared_error: 180.9523 - val__pinball_loss: 3.0381\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3334 - mean_absolute_error: 5.6877 - mean_squared_error: 125.3611 - _pinball_loss: 2.3334 - val_loss: 3.0392 - val_mean_absolute_error: 7.1523 - val_mean_squared_error: 178.6919 - val__pinball_loss: 3.0392\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.3201 - mean_absolute_error: 5.6603 - mean_squared_error: 124.6648 - _pinball_loss: 2.3201 - val_loss: 2.9856 - val_mean_absolute_error: 7.1075 - val_mean_squared_error: 176.7619 - val__pinball_loss: 2.9856\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3035 - mean_absolute_error: 5.6073 - mean_squared_error: 123.3669 - _pinball_loss: 2.3035 - val_loss: 2.9616 - val_mean_absolute_error: 7.0836 - val_mean_squared_error: 176.0862 - val__pinball_loss: 2.9616\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2903 - mean_absolute_error: 5.5873 - mean_squared_error: 122.7867 - _pinball_loss: 2.2903 - val_loss: 2.9740 - val_mean_absolute_error: 7.1035 - val_mean_squared_error: 177.0668 - val__pinball_loss: 2.9740\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2803 - mean_absolute_error: 5.5530 - mean_squared_error: 121.9201 - _pinball_loss: 2.2803 - val_loss: 2.9686 - val_mean_absolute_error: 7.3799 - val_mean_squared_error: 184.1653 - val__pinball_loss: 2.9686\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2679 - mean_absolute_error: 5.5322 - mean_squared_error: 121.5696 - _pinball_loss: 2.2679 - val_loss: 2.9440 - val_mean_absolute_error: 7.0551 - val_mean_squared_error: 175.4521 - val__pinball_loss: 2.9440\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2581 - mean_absolute_error: 5.4938 - mean_squared_error: 120.4070 - _pinball_loss: 2.2581 - val_loss: 2.9591 - val_mean_absolute_error: 7.1519 - val_mean_squared_error: 179.2772 - val__pinball_loss: 2.9591\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.2474 - mean_absolute_error: 5.4706 - mean_squared_error: 119.9465 - _pinball_loss: 2.2474 - val_loss: 2.9400 - val_mean_absolute_error: 7.3240 - val_mean_squared_error: 183.7836 - val__pinball_loss: 2.9400\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2405 - mean_absolute_error: 5.4533 - mean_squared_error: 119.5896 - _pinball_loss: 2.2405 - val_loss: 2.9307 - val_mean_absolute_error: 6.8363 - val_mean_squared_error: 169.8284 - val__pinball_loss: 2.9307\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2313 - mean_absolute_error: 5.4163 - mean_squared_error: 118.4213 - _pinball_loss: 2.2313 - val_loss: 2.9208 - val_mean_absolute_error: 6.8749 - val_mean_squared_error: 172.1979 - val__pinball_loss: 2.9208\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.2200 - mean_absolute_error: 5.3949 - mean_squared_error: 117.9304 - _pinball_loss: 2.2200 - val_loss: 2.9236 - val_mean_absolute_error: 6.9842 - val_mean_squared_error: 175.7980 - val__pinball_loss: 2.9236\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.2140 - mean_absolute_error: 5.3831 - mean_squared_error: 117.5591 - _pinball_loss: 2.2140 - val_loss: 2.9173 - val_mean_absolute_error: 6.9445 - val_mean_squared_error: 174.9252 - val__pinball_loss: 2.9173\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2080 - mean_absolute_error: 5.3711 - mean_squared_error: 117.3685 - _pinball_loss: 2.2080 - val_loss: 2.9096 - val_mean_absolute_error: 7.3469 - val_mean_squared_error: 187.0658 - val__pinball_loss: 2.9096\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1994 - mean_absolute_error: 5.3573 - mean_squared_error: 116.9636 - _pinball_loss: 2.1994 - val_loss: 2.9339 - val_mean_absolute_error: 6.8600 - val_mean_squared_error: 172.0595 - val__pinball_loss: 2.9339\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1929 - mean_absolute_error: 5.3305 - mean_squared_error: 116.1739 - _pinball_loss: 2.1929 - val_loss: 2.9163 - val_mean_absolute_error: 7.1287 - val_mean_squared_error: 180.2412 - val__pinball_loss: 2.9163\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1855 - mean_absolute_error: 5.3183 - mean_squared_error: 115.8191 - _pinball_loss: 2.1855 - val_loss: 2.9204 - val_mean_absolute_error: 6.7437 - val_mean_squared_error: 170.2689 - val__pinball_loss: 2.9204\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000267899CEC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.4\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 3.9516 - mean_absolute_error: 8.7337 - mean_squared_error: 272.0300 - _pinball_loss: 3.9516 - val_loss: 3.5018 - val_mean_absolute_error: 7.2414 - val_mean_squared_error: 178.1272 - val__pinball_loss: 3.5018\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6996 - mean_absolute_error: 5.5148 - mean_squared_error: 119.3915 - _pinball_loss: 2.6996 - val_loss: 3.3829 - val_mean_absolute_error: 6.9514 - val_mean_squared_error: 170.2863 - val__pinball_loss: 3.3829\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6095 - mean_absolute_error: 5.3156 - mean_squared_error: 114.9513 - _pinball_loss: 2.6095 - val_loss: 3.3362 - val_mean_absolute_error: 6.8706 - val_mean_squared_error: 167.0997 - val__pinball_loss: 3.3362\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5538 - mean_absolute_error: 5.1962 - mean_squared_error: 112.2186 - _pinball_loss: 2.5538 - val_loss: 3.2759 - val_mean_absolute_error: 6.7392 - val_mean_squared_error: 164.1526 - val__pinball_loss: 3.2759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5177 - mean_absolute_error: 5.1217 - mean_squared_error: 110.1409 - _pinball_loss: 2.5177 - val_loss: 3.2501 - val_mean_absolute_error: 6.6501 - val_mean_squared_error: 162.0579 - val__pinball_loss: 3.2501\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4893 - mean_absolute_error: 5.0559 - mean_squared_error: 108.6293 - _pinball_loss: 2.4893 - val_loss: 3.2288 - val_mean_absolute_error: 6.6059 - val_mean_squared_error: 160.7237 - val__pinball_loss: 3.2288\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4673 - mean_absolute_error: 5.0106 - mean_squared_error: 107.3469 - _pinball_loss: 2.4673 - val_loss: 3.1829 - val_mean_absolute_error: 6.5676 - val_mean_squared_error: 159.6398 - val__pinball_loss: 3.1829\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4442 - mean_absolute_error: 4.9609 - mean_squared_error: 106.1783 - _pinball_loss: 2.4442 - val_loss: 3.1763 - val_mean_absolute_error: 6.5381 - val_mean_squared_error: 158.8288 - val__pinball_loss: 3.1763\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4304 - mean_absolute_error: 4.9310 - mean_squared_error: 105.3758 - _pinball_loss: 2.4304 - val_loss: 3.1452 - val_mean_absolute_error: 6.4879 - val_mean_squared_error: 157.2439 - val__pinball_loss: 3.1452\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4122 - mean_absolute_error: 4.8926 - mean_squared_error: 104.5429 - _pinball_loss: 2.4122 - val_loss: 3.1392 - val_mean_absolute_error: 6.4917 - val_mean_squared_error: 156.4787 - val__pinball_loss: 3.1392\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3974 - mean_absolute_error: 4.8630 - mean_squared_error: 103.9097 - _pinball_loss: 2.3974 - val_loss: 3.1310 - val_mean_absolute_error: 6.4128 - val_mean_squared_error: 156.0146 - val__pinball_loss: 3.1310\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3867 - mean_absolute_error: 4.8374 - mean_squared_error: 103.2722 - _pinball_loss: 2.3867 - val_loss: 3.1110 - val_mean_absolute_error: 6.3956 - val_mean_squared_error: 154.6611 - val__pinball_loss: 3.1110\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3757 - mean_absolute_error: 4.8140 - mean_squared_error: 102.8769 - _pinball_loss: 2.3757 - val_loss: 3.0984 - val_mean_absolute_error: 6.2490 - val_mean_squared_error: 155.2173 - val__pinball_loss: 3.0984\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3653 - mean_absolute_error: 4.7921 - mean_squared_error: 102.3368 - _pinball_loss: 2.3653 - val_loss: 3.1062 - val_mean_absolute_error: 6.3649 - val_mean_squared_error: 155.2272 - val__pinball_loss: 3.1062\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3578 - mean_absolute_error: 4.7781 - mean_squared_error: 101.9380 - _pinball_loss: 2.3578 - val_loss: 3.1147 - val_mean_absolute_error: 6.3517 - val_mean_squared_error: 154.0798 - val__pinball_loss: 3.1147\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3462 - mean_absolute_error: 4.7491 - mean_squared_error: 101.2676 - _pinball_loss: 2.3462 - val_loss: 3.1027 - val_mean_absolute_error: 6.3523 - val_mean_squared_error: 154.9649 - val__pinball_loss: 3.1027\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026A3A896AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.5\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 4.1777 - mean_absolute_error: 8.3553 - mean_squared_error: 246.9445 - _pinball_loss: 4.1777 - val_loss: 3.4343 - val_mean_absolute_error: 6.8685 - val_mean_squared_error: 184.6454 - val__pinball_loss: 3.4343\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6631 - mean_absolute_error: 5.3261 - mean_squared_error: 123.7169 - _pinball_loss: 2.6631 - val_loss: 3.3745 - val_mean_absolute_error: 6.7489 - val_mean_squared_error: 176.8571 - val__pinball_loss: 3.3745\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5680 - mean_absolute_error: 5.1360 - mean_squared_error: 119.6372 - _pinball_loss: 2.5680 - val_loss: 3.2566 - val_mean_absolute_error: 6.5133 - val_mean_squared_error: 168.5129 - val__pinball_loss: 3.2566\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5125 - mean_absolute_error: 5.0250 - mean_squared_error: 117.1834 - _pinball_loss: 2.5125 - val_loss: 3.2414 - val_mean_absolute_error: 6.4829 - val_mean_squared_error: 167.1075 - val__pinball_loss: 3.2414\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4714 - mean_absolute_error: 4.9429 - mean_squared_error: 115.2757 - _pinball_loss: 2.4714 - val_loss: 3.1638 - val_mean_absolute_error: 6.3275 - val_mean_squared_error: 169.9989 - val__pinball_loss: 3.1638\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4455 - mean_absolute_error: 4.8910 - mean_squared_error: 113.9931 - _pinball_loss: 2.4455 - val_loss: 3.1435 - val_mean_absolute_error: 6.2870 - val_mean_squared_error: 167.0947 - val__pinball_loss: 3.1435\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4148 - mean_absolute_error: 4.8296 - mean_squared_error: 112.6255 - _pinball_loss: 2.4148 - val_loss: 3.1557 - val_mean_absolute_error: 6.3115 - val_mean_squared_error: 162.5967 - val__pinball_loss: 3.1557\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3971 - mean_absolute_error: 4.7942 - mean_squared_error: 111.6269 - _pinball_loss: 2.3971 - val_loss: 3.1131 - val_mean_absolute_error: 6.2262 - val_mean_squared_error: 165.4009 - val__pinball_loss: 3.1131\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3803 - mean_absolute_error: 4.7606 - mean_squared_error: 111.0268 - _pinball_loss: 2.3803 - val_loss: 3.0864 - val_mean_absolute_error: 6.1727 - val_mean_squared_error: 163.2530 - val__pinball_loss: 3.0864\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3654 - mean_absolute_error: 4.7308 - mean_squared_error: 110.2962 - _pinball_loss: 2.3654 - val_loss: 3.0730 - val_mean_absolute_error: 6.1461 - val_mean_squared_error: 160.4391 - val__pinball_loss: 3.0730\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3501 - mean_absolute_error: 4.7003 - mean_squared_error: 109.6970 - _pinball_loss: 2.3501 - val_loss: 3.0615 - val_mean_absolute_error: 6.1231 - val_mean_squared_error: 157.9790 - val__pinball_loss: 3.0615\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.3303 - mean_absolute_error: 4.6607 - mean_squared_error: 108.8256 - _pinball_loss: 2.3303 - val_loss: 3.0629 - val_mean_absolute_error: 6.1259 - val_mean_squared_error: 166.0853 - val__pinball_loss: 3.0629\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3256 - mean_absolute_error: 4.6513 - mean_squared_error: 108.5449 - _pinball_loss: 2.3256 - val_loss: 3.0247 - val_mean_absolute_error: 6.0494 - val_mean_squared_error: 161.9604 - val__pinball_loss: 3.0247\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3115 - mean_absolute_error: 4.6231 - mean_squared_error: 107.9848 - _pinball_loss: 2.3115 - val_loss: 3.0290 - val_mean_absolute_error: 6.0580 - val_mean_squared_error: 160.3078 - val__pinball_loss: 3.0290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.2988 - mean_absolute_error: 4.5976 - mean_squared_error: 107.2081 - _pinball_loss: 2.2988 - val_loss: 3.0302 - val_mean_absolute_error: 6.0604 - val_mean_squared_error: 164.8270 - val__pinball_loss: 3.0302\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.2903 - mean_absolute_error: 4.5807 - mean_squared_error: 106.8034 - _pinball_loss: 2.2903 - val_loss: 3.0170 - val_mean_absolute_error: 6.0340 - val_mean_squared_error: 162.1796 - val__pinball_loss: 3.0170\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.2797 - mean_absolute_error: 4.5593 - mean_squared_error: 106.5370 - _pinball_loss: 2.2797 - val_loss: 2.9969 - val_mean_absolute_error: 5.9938 - val_mean_squared_error: 160.8394 - val__pinball_loss: 2.9969\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2692 - mean_absolute_error: 4.5385 - mean_squared_error: 105.9044 - _pinball_loss: 2.2692 - val_loss: 3.0098 - val_mean_absolute_error: 6.0196 - val_mean_squared_error: 165.1266 - val__pinball_loss: 3.0098\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2613 - mean_absolute_error: 4.5227 - mean_squared_error: 105.6536 - _pinball_loss: 2.2613 - val_loss: 3.0035 - val_mean_absolute_error: 6.0070 - val_mean_squared_error: 158.0494 - val__pinball_loss: 3.0035\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2514 - mean_absolute_error: 4.5028 - mean_squared_error: 104.9794 - _pinball_loss: 2.2514 - val_loss: 3.0133 - val_mean_absolute_error: 6.0265 - val_mean_squared_error: 164.0970 - val__pinball_loss: 3.0133\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000267816A8288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.6\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 4.3871 - mean_absolute_error: 8.8801 - mean_squared_error: 257.1516 - _pinball_loss: 4.3871 - val_loss: 3.2028 - val_mean_absolute_error: 7.0042 - val_mean_squared_error: 197.8118 - val__pinball_loss: 3.2028\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4699 - mean_absolute_error: 5.4772 - mean_squared_error: 136.5365 - _pinball_loss: 2.4699 - val_loss: 3.0663 - val_mean_absolute_error: 6.6924 - val_mean_squared_error: 192.4663 - val__pinball_loss: 3.0663\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.3539 - mean_absolute_error: 5.2441 - mean_squared_error: 132.8681 - _pinball_loss: 2.3539 - val_loss: 3.0720 - val_mean_absolute_error: 6.6157 - val_mean_squared_error: 183.4514 - val__pinball_loss: 3.0720\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.2986 - mean_absolute_error: 5.1367 - mean_squared_error: 130.9813 - _pinball_loss: 2.2986 - val_loss: 2.9488 - val_mean_absolute_error: 6.4940 - val_mean_squared_error: 188.4846 - val__pinball_loss: 2.9488\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2554 - mean_absolute_error: 5.0523 - mean_squared_error: 129.7233 - _pinball_loss: 2.2554 - val_loss: 2.8867 - val_mean_absolute_error: 6.3582 - val_mean_squared_error: 185.0540 - val__pinball_loss: 2.8867\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2237 - mean_absolute_error: 4.9899 - mean_squared_error: 128.3864 - _pinball_loss: 2.2237 - val_loss: 2.8768 - val_mean_absolute_error: 6.3997 - val_mean_squared_error: 190.3047 - val__pinball_loss: 2.8768\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1958 - mean_absolute_error: 4.9360 - mean_squared_error: 127.6050 - _pinball_loss: 2.1958 - val_loss: 2.8274 - val_mean_absolute_error: 6.3378 - val_mean_squared_error: 189.5997 - val__pinball_loss: 2.8274\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1772 - mean_absolute_error: 4.9023 - mean_squared_error: 127.1105 - _pinball_loss: 2.1772 - val_loss: 2.8329 - val_mean_absolute_error: 6.2572 - val_mean_squared_error: 181.9863 - val__pinball_loss: 2.8329\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1566 - mean_absolute_error: 4.8592 - mean_squared_error: 126.2391 - _pinball_loss: 2.1566 - val_loss: 2.8173 - val_mean_absolute_error: 6.2525 - val_mean_squared_error: 182.6884 - val__pinball_loss: 2.8173\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1360 - mean_absolute_error: 4.8195 - mean_squared_error: 125.7114 - _pinball_loss: 2.1360 - val_loss: 2.7730 - val_mean_absolute_error: 6.2545 - val_mean_squared_error: 187.7830 - val__pinball_loss: 2.7730\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.1224 - mean_absolute_error: 4.7964 - mean_squared_error: 125.5456 - _pinball_loss: 2.1224 - val_loss: 2.7719 - val_mean_absolute_error: 6.2632 - val_mean_squared_error: 189.0852 - val__pinball_loss: 2.7719\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.1091 - mean_absolute_error: 4.7669 - mean_squared_error: 124.6188 - _pinball_loss: 2.1091 - val_loss: 2.7967 - val_mean_absolute_error: 6.3315 - val_mean_squared_error: 189.5202 - val__pinball_loss: 2.7967\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.1002 - mean_absolute_error: 4.7517 - mean_squared_error: 124.6055 - _pinball_loss: 2.1002 - val_loss: 2.7569 - val_mean_absolute_error: 6.1676 - val_mean_squared_error: 182.4693 - val__pinball_loss: 2.7569\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.0884 - mean_absolute_error: 4.7258 - mean_squared_error: 123.8808 - _pinball_loss: 2.0884 - val_loss: 2.7663 - val_mean_absolute_error: 6.1447 - val_mean_squared_error: 182.3062 - val__pinball_loss: 2.7663\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.0771 - mean_absolute_error: 4.7026 - mean_squared_error: 123.4981 - _pinball_loss: 2.0771 - val_loss: 2.7474 - val_mean_absolute_error: 6.2177 - val_mean_squared_error: 190.9944 - val__pinball_loss: 2.7474\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.0674 - mean_absolute_error: 4.6843 - mean_squared_error: 123.1039 - _pinball_loss: 2.0674 - val_loss: 2.7376 - val_mean_absolute_error: 6.2773 - val_mean_squared_error: 197.3357 - val__pinball_loss: 2.7376\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.0552 - mean_absolute_error: 4.6615 - mean_squared_error: 122.9385 - _pinball_loss: 2.0552 - val_loss: 2.7164 - val_mean_absolute_error: 6.1253 - val_mean_squared_error: 186.6932 - val__pinball_loss: 2.7164\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.0442 - mean_absolute_error: 4.6368 - mean_squared_error: 122.1202 - _pinball_loss: 2.0442 - val_loss: 2.7375 - val_mean_absolute_error: 6.1125 - val_mean_squared_error: 183.1403 - val__pinball_loss: 2.7375\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.0382 - mean_absolute_error: 4.6243 - mean_squared_error: 121.8330 - _pinball_loss: 2.0382 - val_loss: 2.7319 - val_mean_absolute_error: 6.1602 - val_mean_squared_error: 187.7780 - val__pinball_loss: 2.7319\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.0319 - mean_absolute_error: 4.6097 - mean_squared_error: 121.4264 - _pinball_loss: 2.0319 - val_loss: 2.7150 - val_mean_absolute_error: 6.0489 - val_mean_squared_error: 181.2214 - val__pinball_loss: 2.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 2.0217 - mean_absolute_error: 4.5894 - mean_squared_error: 121.0099 - _pinball_loss: 2.0217 - val_loss: 2.7178 - val_mean_absolute_error: 6.1806 - val_mean_squared_error: 189.4162 - val__pinball_loss: 2.7178\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.0152 - mean_absolute_error: 4.5762 - mean_squared_error: 120.6292 - _pinball_loss: 2.0152 - val_loss: 2.7053 - val_mean_absolute_error: 6.0905 - val_mean_squared_error: 184.4009 - val__pinball_loss: 2.7053\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.0037 - mean_absolute_error: 4.5517 - mean_squared_error: 120.0696 - _pinball_loss: 2.0037 - val_loss: 2.6973 - val_mean_absolute_error: 6.1488 - val_mean_squared_error: 191.1049 - val__pinball_loss: 2.6973\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9982 - mean_absolute_error: 4.5414 - mean_squared_error: 119.9745 - _pinball_loss: 1.9982 - val_loss: 2.7107 - val_mean_absolute_error: 6.1077 - val_mean_squared_error: 185.5687 - val__pinball_loss: 2.7107\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9989 - mean_absolute_error: 4.5370 - mean_squared_error: 119.2114 - _pinball_loss: 1.9989 - val_loss: 2.6996 - val_mean_absolute_error: 6.0737 - val_mean_squared_error: 185.0783 - val__pinball_loss: 2.6996\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9844 - mean_absolute_error: 4.5117 - mean_squared_error: 119.1005 - _pinball_loss: 1.9844 - val_loss: 2.6890 - val_mean_absolute_error: 6.0783 - val_mean_squared_error: 185.1681 - val__pinball_loss: 2.6890\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9825 - mean_absolute_error: 4.5066 - mean_squared_error: 118.8092 - _pinball_loss: 1.9825 - val_loss: 2.7105 - val_mean_absolute_error: 6.0482 - val_mean_squared_error: 182.2280 - val__pinball_loss: 2.7105\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 1.9768 - mean_absolute_error: 4.4926 - mean_squared_error: 118.2310 - _pinball_loss: 1.9768 - val_loss: 2.6995 - val_mean_absolute_error: 6.0410 - val_mean_squared_error: 179.0440 - val__pinball_loss: 2.6995\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9717 - mean_absolute_error: 4.4806 - mean_squared_error: 117.6990 - _pinball_loss: 1.9717 - val_loss: 2.6805 - val_mean_absolute_error: 6.0633 - val_mean_squared_error: 185.3777 - val__pinball_loss: 2.6805\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 1.9664 - mean_absolute_error: 4.4694 - mean_squared_error: 117.3767 - _pinball_loss: 1.9664 - val_loss: 2.6922 - val_mean_absolute_error: 5.9789 - val_mean_squared_error: 177.7341 - val__pinball_loss: 2.6922\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 1.9611 - mean_absolute_error: 4.4572 - mean_squared_error: 116.9044 - _pinball_loss: 1.9611 - val_loss: 2.6829 - val_mean_absolute_error: 6.0505 - val_mean_squared_error: 185.6910 - val__pinball_loss: 2.6829\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9520 - mean_absolute_error: 4.4407 - mean_squared_error: 116.7144 - _pinball_loss: 1.9520 - val_loss: 2.6874 - val_mean_absolute_error: 6.0954 - val_mean_squared_error: 187.8825 - val__pinball_loss: 2.6874\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026A43E48948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.7\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 4.4861 - mean_absolute_error: 10.3755 - mean_squared_error: 293.4345 - _pinball_loss: 4.4861 - val_loss: 2.7622 - val_mean_absolute_error: 7.5561 - val_mean_squared_error: 230.7968 - val__pinball_loss: 2.7622\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.1704 - mean_absolute_error: 6.0059 - mean_squared_error: 158.2348 - _pinball_loss: 2.1704 - val_loss: 2.5885 - val_mean_absolute_error: 7.0823 - val_mean_squared_error: 221.1999 - val__pinball_loss: 2.5885\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.0407 - mean_absolute_error: 5.7083 - mean_squared_error: 154.6252 - _pinball_loss: 2.0407 - val_loss: 2.4927 - val_mean_absolute_error: 6.8868 - val_mean_squared_error: 218.3573 - val__pinball_loss: 2.4927\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9802 - mean_absolute_error: 5.5776 - mean_squared_error: 153.4937 - _pinball_loss: 1.9802 - val_loss: 2.4937 - val_mean_absolute_error: 6.9155 - val_mean_squared_error: 214.6703 - val__pinball_loss: 2.4937\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9384 - mean_absolute_error: 5.4906 - mean_squared_error: 152.4645 - _pinball_loss: 1.9384 - val_loss: 2.4543 - val_mean_absolute_error: 7.1586 - val_mean_squared_error: 233.9495 - val__pinball_loss: 2.4543\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.9044 - mean_absolute_error: 5.4202 - mean_squared_error: 151.8717 - _pinball_loss: 1.9044 - val_loss: 2.3880 - val_mean_absolute_error: 6.7504 - val_mean_squared_error: 220.7026 - val__pinball_loss: 2.3880\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8748 - mean_absolute_error: 5.3576 - mean_squared_error: 151.0219 - _pinball_loss: 1.8748 - val_loss: 2.3903 - val_mean_absolute_error: 7.0353 - val_mean_squared_error: 236.7123 - val__pinball_loss: 2.3903\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 56s 49ms/step - loss: 1.8562 - mean_absolute_error: 5.3170 - mean_squared_error: 150.3148 - _pinball_loss: 1.8562 - val_loss: 2.3606 - val_mean_absolute_error: 6.9523 - val_mean_squared_error: 234.2416 - val__pinball_loss: 2.3606\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 341s 298ms/step - loss: 1.8349 - mean_absolute_error: 5.2736 - mean_squared_error: 149.9428 - _pinball_loss: 1.8349 - val_loss: 2.3378 - val_mean_absolute_error: 6.8595 - val_mean_squared_error: 231.6712 - val__pinball_loss: 2.3378\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 336s 294ms/step - loss: 1.8152 - mean_absolute_error: 5.2281 - mean_squared_error: 149.2150 - _pinball_loss: 1.8152 - val_loss: 2.3434 - val_mean_absolute_error: 6.7145 - val_mean_squared_error: 222.5712 - val__pinball_loss: 2.3434\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 337s 294ms/step - loss: 1.8051 - mean_absolute_error: 5.2046 - mean_squared_error: 148.7607 - _pinball_loss: 1.8051 - val_loss: 2.3248 - val_mean_absolute_error: 6.6595 - val_mean_squared_error: 219.1013 - val__pinball_loss: 2.3248\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 342s 298ms/step - loss: 1.7937 - mean_absolute_error: 5.1804 - mean_squared_error: 148.5253 - _pinball_loss: 1.7937 - val_loss: 2.3077 - val_mean_absolute_error: 6.6196 - val_mean_squared_error: 219.4037 - val__pinball_loss: 2.3077\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 349s 305ms/step - loss: 1.7810 - mean_absolute_error: 5.1528 - mean_squared_error: 148.2599 - _pinball_loss: 1.7810 - val_loss: 2.3264 - val_mean_absolute_error: 6.9680 - val_mean_squared_error: 239.3263 - val__pinball_loss: 2.3264\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 343s 300ms/step - loss: 1.7687 - mean_absolute_error: 5.1261 - mean_squared_error: 148.0053 - _pinball_loss: 1.7687 - val_loss: 2.2828 - val_mean_absolute_error: 6.7014 - val_mean_squared_error: 227.4557 - val__pinball_loss: 2.2828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 340s 297ms/step - loss: 1.7588 - mean_absolute_error: 5.1015 - mean_squared_error: 147.5875 - _pinball_loss: 1.7588 - val_loss: 2.2862 - val_mean_absolute_error: 6.6220 - val_mean_squared_error: 225.5252 - val__pinball_loss: 2.2862\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 347s 302ms/step - loss: 1.7531 - mean_absolute_error: 5.0881 - mean_squared_error: 147.2567 - _pinball_loss: 1.7531 - val_loss: 2.2639 - val_mean_absolute_error: 6.6967 - val_mean_squared_error: 228.3308 - val__pinball_loss: 2.2639\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 334s 291ms/step - loss: 1.7437 - mean_absolute_error: 5.0641 - mean_squared_error: 146.6617 - _pinball_loss: 1.7437 - val_loss: 2.2747 - val_mean_absolute_error: 6.6094 - val_mean_squared_error: 224.0950 - val__pinball_loss: 2.2747\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 335s 292ms/step - loss: 1.7334 - mean_absolute_error: 5.0397 - mean_squared_error: 146.2742 - _pinball_loss: 1.7334 - val_loss: 2.2516 - val_mean_absolute_error: 6.5302 - val_mean_squared_error: 219.1706 - val__pinball_loss: 2.2516\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 360s 314ms/step - loss: 1.7264 - mean_absolute_error: 5.0270 - mean_squared_error: 146.0949 - _pinball_loss: 1.7264 - val_loss: 2.2529 - val_mean_absolute_error: 6.5195 - val_mean_squared_error: 222.7088 - val__pinball_loss: 2.2529\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 305s 267ms/step - loss: 1.7161 - mean_absolute_error: 4.9977 - mean_squared_error: 145.3406 - _pinball_loss: 1.7161 - val_loss: 2.2598 - val_mean_absolute_error: 6.6278 - val_mean_squared_error: 223.5333 - val__pinball_loss: 2.2598\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 263s 229ms/step - loss: 1.7145 - mean_absolute_error: 4.9925 - mean_squared_error: 145.0094 - _pinball_loss: 1.7145 - val_loss: 2.2465 - val_mean_absolute_error: 6.4790 - val_mean_squared_error: 219.1065 - val__pinball_loss: 2.2465\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 1.7062 - mean_absolute_error: 4.9693 - mean_squared_error: 144.3381 - _pinball_loss: 1.7062 - val_loss: 2.2499 - val_mean_absolute_error: 6.4086 - val_mean_squared_error: 214.4107 - val__pinball_loss: 2.2499\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 266s 232ms/step - loss: 1.6999 - mean_absolute_error: 4.9578 - mean_squared_error: 144.2702 - _pinball_loss: 1.6999 - val_loss: 2.2451 - val_mean_absolute_error: 6.7075 - val_mean_squared_error: 231.3961 - val__pinball_loss: 2.2451\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 1.6930 - mean_absolute_error: 4.9427 - mean_squared_error: 143.9075 - _pinball_loss: 1.6930 - val_loss: 2.2304 - val_mean_absolute_error: 6.3907 - val_mean_squared_error: 214.9556 - val__pinball_loss: 2.2304\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 286s 250ms/step - loss: 1.6891 - mean_absolute_error: 4.9317 - mean_squared_error: 143.3966 - _pinball_loss: 1.6891 - val_loss: 2.2400 - val_mean_absolute_error: 6.6334 - val_mean_squared_error: 226.7534 - val__pinball_loss: 2.2400\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 341s 297ms/step - loss: 1.6834 - mean_absolute_error: 4.9153 - mean_squared_error: 142.7521 - _pinball_loss: 1.6834 - val_loss: 2.2389 - val_mean_absolute_error: 6.7438 - val_mean_squared_error: 231.7751 - val__pinball_loss: 2.2389\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 263s 229ms/step - loss: 1.6817 - mean_absolute_error: 4.9121 - mean_squared_error: 142.6359 - _pinball_loss: 1.6817 - val_loss: 2.2505 - val_mean_absolute_error: 6.4272 - val_mean_squared_error: 214.4413 - val__pinball_loss: 2.2505\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026781A610D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.8\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 4.4923 - mean_absolute_error: 14.0404 - mean_squared_error: 449.0038 - _pinball_loss: 4.4923 - val_loss: 2.1886 - val_mean_absolute_error: 8.0475 - val_mean_squared_error: 254.6308 - val__pinball_loss: 2.1886\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 360s 314ms/step - loss: 1.7058 - mean_absolute_error: 6.8964 - mean_squared_error: 188.3062 - _pinball_loss: 1.7058 - val_loss: 1.9831 - val_mean_absolute_error: 7.8498 - val_mean_squared_error: 262.3571 - val__pinball_loss: 1.9831\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 366s 319ms/step - loss: 1.5783 - mean_absolute_error: 6.4937 - mean_squared_error: 182.7586 - _pinball_loss: 1.5783 - val_loss: 1.9338 - val_mean_absolute_error: 7.4807 - val_mean_squared_error: 247.8465 - val__pinball_loss: 1.9338\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 367s 320ms/step - loss: 1.5076 - mean_absolute_error: 6.2565 - mean_squared_error: 179.5408 - _pinball_loss: 1.5076 - val_loss: 1.8583 - val_mean_absolute_error: 7.4430 - val_mean_squared_error: 252.3376 - val__pinball_loss: 1.8583\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 270s 236ms/step - loss: 1.4611 - mean_absolute_error: 6.1108 - mean_squared_error: 177.5595 - _pinball_loss: 1.4611 - val_loss: 1.8317 - val_mean_absolute_error: 7.3348 - val_mean_squared_error: 250.3602 - val__pinball_loss: 1.8317\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 1.4301 - mean_absolute_error: 6.0164 - mean_squared_error: 176.2583 - _pinball_loss: 1.4301 - val_loss: 1.7764 - val_mean_absolute_error: 7.5433 - val_mean_squared_error: 263.9936 - val__pinball_loss: 1.7764\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 1.3975 - mean_absolute_error: 5.9206 - mean_squared_error: 175.2171 - _pinball_loss: 1.3975 - val_loss: 1.7641 - val_mean_absolute_error: 7.6688 - val_mean_squared_error: 268.8944 - val__pinball_loss: 1.7641\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 1.3775 - mean_absolute_error: 5.8643 - mean_squared_error: 174.5458 - _pinball_loss: 1.3775 - val_loss: 1.7594 - val_mean_absolute_error: 7.2183 - val_mean_squared_error: 253.8093 - val__pinball_loss: 1.7594\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 263s 230ms/step - loss: 1.3598 - mean_absolute_error: 5.7941 - mean_squared_error: 173.3421 - _pinball_loss: 1.3598 - val_loss: 1.7669 - val_mean_absolute_error: 7.1578 - val_mean_squared_error: 246.5345 - val__pinball_loss: 1.7669\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 264s 231ms/step - loss: 1.3447 - mean_absolute_error: 5.7530 - mean_squared_error: 173.0450 - _pinball_loss: 1.3447 - val_loss: 1.7878 - val_mean_absolute_error: 6.9239 - val_mean_squared_error: 241.5739 - val__pinball_loss: 1.7878\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 1.3360 - mean_absolute_error: 5.7236 - mean_squared_error: 172.6055 - _pinball_loss: 1.3360 - val_loss: 1.7011 - val_mean_absolute_error: 7.3263 - val_mean_squared_error: 261.7825 - val__pinball_loss: 1.7011\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 271s 237ms/step - loss: 1.3186 - mean_absolute_error: 5.6689 - mean_squared_error: 171.6092 - _pinball_loss: 1.3186 - val_loss: 1.7117 - val_mean_absolute_error: 7.0413 - val_mean_squared_error: 246.4352 - val__pinball_loss: 1.7117\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 264s 231ms/step - loss: 1.3099 - mean_absolute_error: 5.6428 - mean_squared_error: 171.3207 - _pinball_loss: 1.3099 - val_loss: 1.7038 - val_mean_absolute_error: 6.9687 - val_mean_squared_error: 245.1763 - val__pinball_loss: 1.7038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 262s 229ms/step - loss: 1.2992 - mean_absolute_error: 5.6056 - mean_squared_error: 170.7159 - _pinball_loss: 1.2992 - val_loss: 1.7018 - val_mean_absolute_error: 7.1433 - val_mean_squared_error: 253.1074 - val__pinball_loss: 1.7018\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000267816A8B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.9\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 276s 241ms/step - loss: 3.7929 - mean_absolute_error: 21.3226 - mean_squared_error: 906.1551 - _pinball_loss: 3.7929 - val_loss: 1.3948 - val_mean_absolute_error: 9.8257 - val_mean_squared_error: 329.4081 - val__pinball_loss: 1.3948\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 263s 229ms/step - loss: 1.0798 - mean_absolute_error: 8.8552 - mean_squared_error: 250.0107 - _pinball_loss: 1.0798 - val_loss: 1.1951 - val_mean_absolute_error: 9.2043 - val_mean_squared_error: 314.4237 - val__pinball_loss: 1.1951\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 263s 229ms/step - loss: 0.9661 - mean_absolute_error: 8.0655 - mean_squared_error: 234.8569 - _pinball_loss: 0.9661 - val_loss: 1.1269 - val_mean_absolute_error: 8.6488 - val_mean_squared_error: 297.5486 - val__pinball_loss: 1.1269\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 263s 229ms/step - loss: 0.9085 - mean_absolute_error: 7.6452 - mean_squared_error: 226.9658 - _pinball_loss: 0.9085 - val_loss: 1.0675 - val_mean_absolute_error: 8.7219 - val_mean_squared_error: 306.0605 - val__pinball_loss: 1.0675\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 263s 230ms/step - loss: 0.8717 - mean_absolute_error: 7.4088 - mean_squared_error: 223.0774 - _pinball_loss: 0.8717 - val_loss: 1.0535 - val_mean_absolute_error: 9.0499 - val_mean_squared_error: 322.1768 - val__pinball_loss: 1.0535\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 265s 232ms/step - loss: 0.8470 - mean_absolute_error: 7.2473 - mean_squared_error: 220.5212 - _pinball_loss: 0.8470 - val_loss: 1.0259 - val_mean_absolute_error: 8.6647 - val_mean_squared_error: 308.9952 - val__pinball_loss: 1.0259\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 263s 230ms/step - loss: 0.8235 - mean_absolute_error: 7.0882 - mean_squared_error: 217.6539 - _pinball_loss: 0.8235 - val_loss: 1.0015 - val_mean_absolute_error: 8.5140 - val_mean_squared_error: 306.7207 - val__pinball_loss: 1.0015\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 311s 272ms/step - loss: 0.8063 - mean_absolute_error: 6.9685 - mean_squared_error: 215.1061 - _pinball_loss: 0.8063 - val_loss: 1.0381 - val_mean_absolute_error: 9.0587 - val_mean_squared_error: 324.5799 - val__pinball_loss: 1.0381\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 363s 317ms/step - loss: 0.7931 - mean_absolute_error: 6.8855 - mean_squared_error: 213.7374 - _pinball_loss: 0.7931 - val_loss: 0.9830 - val_mean_absolute_error: 8.8463 - val_mean_squared_error: 318.2766 - val__pinball_loss: 0.9830\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 362s 316ms/step - loss: 0.7818 - mean_absolute_error: 6.8122 - mean_squared_error: 212.2171 - _pinball_loss: 0.7818 - val_loss: 0.9845 - val_mean_absolute_error: 8.1826 - val_mean_squared_error: 298.6965 - val__pinball_loss: 0.9845\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 361s 315ms/step - loss: 0.7725 - mean_absolute_error: 6.7430 - mean_squared_error: 210.7010 - _pinball_loss: 0.7725 - val_loss: 0.9598 - val_mean_absolute_error: 8.0015 - val_mean_squared_error: 293.8710 - val__pinball_loss: 0.9598\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 361s 315ms/step - loss: 0.7609 - mean_absolute_error: 6.6654 - mean_squared_error: 209.2450 - _pinball_loss: 0.7609 - val_loss: 0.9653 - val_mean_absolute_error: 8.2140 - val_mean_squared_error: 301.4631 - val__pinball_loss: 0.9653\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 338s 295ms/step - loss: 0.7546 - mean_absolute_error: 6.6223 - mean_squared_error: 208.3892 - _pinball_loss: 0.7546 - val_loss: 0.9479 - val_mean_absolute_error: 7.9904 - val_mean_squared_error: 293.3451 - val__pinball_loss: 0.9479\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 265s 231ms/step - loss: 0.7487 - mean_absolute_error: 6.5804 - mean_squared_error: 207.4299 - _pinball_loss: 0.7487 - val_loss: 0.9563 - val_mean_absolute_error: 8.0063 - val_mean_squared_error: 294.8924 - val__pinball_loss: 0.9563\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 263s 229ms/step - loss: 0.7403 - mean_absolute_error: 6.5222 - mean_squared_error: 206.3093 - _pinball_loss: 0.7403 - val_loss: 0.9391 - val_mean_absolute_error: 8.3291 - val_mean_squared_error: 307.0670 - val__pinball_loss: 0.9391\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 0.7345 - mean_absolute_error: 6.4881 - mean_squared_error: 205.4205 - _pinball_loss: 0.7345 - val_loss: 0.9512 - val_mean_absolute_error: 7.7370 - val_mean_squared_error: 283.6495 - val__pinball_loss: 0.9512\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 264s 231ms/step - loss: 0.7312 - mean_absolute_error: 6.4632 - mean_squared_error: 204.7532 - _pinball_loss: 0.7312 - val_loss: 0.9453 - val_mean_absolute_error: 7.9495 - val_mean_squared_error: 292.3123 - val__pinball_loss: 0.9453\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 306s 267ms/step - loss: 0.7237 - mean_absolute_error: 6.4017 - mean_squared_error: 203.5331 - _pinball_loss: 0.7237 - val_loss: 0.9327 - val_mean_absolute_error: 7.8930 - val_mean_squared_error: 289.8111 - val__pinball_loss: 0.9327\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 277s 241ms/step - loss: 0.7198 - mean_absolute_error: 6.3795 - mean_squared_error: 202.9193 - _pinball_loss: 0.7198 - val_loss: 0.9340 - val_mean_absolute_error: 7.9078 - val_mean_squared_error: 291.0332 - val__pinball_loss: 0.9340\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 0.7155 - mean_absolute_error: 6.3550 - mean_squared_error: 202.4422 - _pinball_loss: 0.7155 - val_loss: 0.9281 - val_mean_absolute_error: 8.0380 - val_mean_squared_error: 302.1860 - val__pinball_loss: 0.9281\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 263s 230ms/step - loss: 0.7127 - mean_absolute_error: 6.3287 - mean_squared_error: 201.7505 - _pinball_loss: 0.7127 - val_loss: 0.9077 - val_mean_absolute_error: 8.1183 - val_mean_squared_error: 301.8106 - val__pinball_loss: 0.9077\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 0.7092 - mean_absolute_error: 6.3082 - mean_squared_error: 201.1518 - _pinball_loss: 0.7092 - val_loss: 0.9280 - val_mean_absolute_error: 7.7675 - val_mean_squared_error: 287.8058 - val__pinball_loss: 0.9280\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 339s 296ms/step - loss: 0.7043 - mean_absolute_error: 6.2750 - mean_squared_error: 200.6083 - _pinball_loss: 0.7043 - val_loss: 0.9302 - val_mean_absolute_error: 7.6641 - val_mean_squared_error: 284.8539 - val__pinball_loss: 0.9302\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 264s 230ms/step - loss: 0.7020 - mean_absolute_error: 6.2585 - mean_squared_error: 200.2016 - _pinball_loss: 0.7020 - val_loss: 0.9110 - val_mean_absolute_error: 8.0195 - val_mean_squared_error: 299.9245 - val__pinball_loss: 0.9110\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000269E5642EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "from src.model.multiple_output.convolution import ConvolutionVarious\n",
    "\n",
    "days = 1\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=48,\n",
    "    label_width=96,\n",
    "    shift=96,\n",
    "    sequence_stride=1,\n",
    "    label_columns=[\"TARGET\"]\n",
    "    \n",
    ")\n",
    "submission_df_1 = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict(\"minmax\")\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * days)\n",
    "\n",
    "evaluate_dict_1 = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various = ConvolutionVarious(48)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various, one_days_window_label_columns, q)\n",
    "    evaluate_dict_1[q] = conv_various.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, train_df.shape[-1] - 1)\n",
    "    pred_y = conv_various.predict(predict_np)[:, :, -1]\n",
    "    submission_df_1[f\"q_{q}\"] = pred_y.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: [0.8651361465454102,\n",
       "  6.411491870880127,\n",
       "  160.1835479736328,\n",
       "  0.8650573492050171],\n",
       " 0.2: [1.3709611892700195,\n",
       "  4.5218658447265625,\n",
       "  82.00414276123047,\n",
       "  1.3708319664001465],\n",
       " 0.3: [1.598541498184204,\n",
       "  3.527270793914795,\n",
       "  59.535499572753906,\n",
       "  1.5983389616012573],\n",
       " 0.4: [1.6216026544570923,\n",
       "  3.2097091674804688,\n",
       "  55.50996780395508,\n",
       "  1.6215879917144775],\n",
       " 0.5: [1.569057583808899,\n",
       "  3.138113021850586,\n",
       "  63.68381881713867,\n",
       "  1.5692576169967651],\n",
       " 0.6: [1.3627004623413086,\n",
       "  3.1574835777282715,\n",
       "  74.25511169433594,\n",
       "  1.362777829170227],\n",
       " 0.7: [1.1704150438308716,\n",
       "  3.3607945442199707,\n",
       "  84.16575622558594,\n",
       "  1.1703453063964844],\n",
       " 0.8: [0.8869102597236633,\n",
       "  3.9626379013061523,\n",
       "  100.3033676147461,\n",
       "  0.8868370056152344],\n",
       " 0.9: [0.5113241672515869,\n",
       "  4.614569664001465,\n",
       "  120.91699981689453,\n",
       "  0.5112897157669067]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.217405445045895"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for v in evaluate_dict_1.values():\n",
    "    s += v[0]\n",
    "\n",
    "s/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_df_1[0:48]\n",
    "submission_df_1.to_csv(\"cnn_many_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  q_0.1  q_0.2  q_0.3  q_0.4  q_0.5  q_0.6  q_0.7  q_0.8  q_0.9\n",
       "0     0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "1     0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "2     0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "3     0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "4     0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "...  ..    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
       "7771  0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "7772  0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "7773  0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "7774  0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "7775  0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = submission_df_1['id']\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df_1[submission_df_1[f'q_{q}'] < 0] = 0\n",
    "submission_df_1['id'] = _id\n",
    "submission_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_1['id'] = submission_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_1.to_csv('many_features_1d_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (dacon)",
   "language": "python",
   "name": "pycharm-549c67b6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}