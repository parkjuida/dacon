{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5ffb2a68816e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-1-5ffb2a68816e>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    1-12 best - lightgbm\u001B[0m\n\u001B[1;37m            ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1-12 best - lightgbm\n",
    "\n",
    "from src.preprocessors.add_columns import add_sin_cos_day, add_sin_cos_hour, add_ghi\n",
    "\n",
    "def feature_engineering(df):\n",
    "#     df = add_sin_cos_day(df)\n",
    "#     df = add_sin_cos_hour(df)\n",
    "    df = add_ghi(df)\n",
    "\n",
    "    df[\"TARGET_ROLLING_MEAN_3\"] = df[\"TARGET\"].rolling(3).mean()\n",
    "    df[\"TARGET_ROLLING_MEAN_5\"] = df[\"TARGET\"].rolling(5).mean()\n",
    "    df[\"TARGET_ROLLING_MEAN_11\"] = df[\"TARGET\"].rolling(11).mean()\n",
    "    df[\"TARGET_ROLLING_MEAN_23\"] = df[\"TARGET\"].rolling(23).mean()\n",
    "    df[\"TARGET_ROLLING_MEAN_47\"] = df[\"TARGET\"].rolling(47).mean()\n",
    "    \n",
    "    scaled_rh = (df[\"RH\"]) / 100\n",
    "    _mean = df[\"T\"].rolling(96).mean()\n",
    "    _std = df[\"T\"].rolling(96).std()\n",
    "    df[\"SCALED_RH\"] = scaled_rh * (df[\"T\"] - _mean) / _std\n",
    "    df[\"RH_CROSS_T\"] = df[\"RH\"] * df[\"T\"]\n",
    "    \n",
    "    df.drop([\"Day\", \"Hour\", \"Minute\", \"WS\", \"RH\", \"T\"], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "import importlib\n",
    "import src.loaders.data_loader\n",
    "importlib.reload(src.loaders.data_loader)\n",
    "\n",
    "from src.loaders.data_loader import generate_test_data, load_submission_data\n",
    "\n",
    "submission_df = load_submission_data()\n",
    "\n",
    "r = 0\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    result = []\n",
    "    param = {\n",
    "    'application': 'quantile',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 64,\n",
    "    'n_jobs': 17,\n",
    "    'seed': 42,\n",
    "    'bagging_freq': 100,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'drop_rate': 0.2,\n",
    "    'early_stopping_round': 10,\n",
    "    'alpha': q,\n",
    "    'boosting': 'dart',\n",
    "    }\n",
    "    \n",
    "    num_round = 5000\n",
    "    bst_1 = lgb.train(param, train_1_dataset, num_round, valid_sets=[valid_1_dataset])\n",
    "    bst_2 = lgb.train(param, train_2_dataset, num_round, valid_sets=[valid_2_dataset])\n",
    "    \n",
    "    y_pred_1 = bst_1.predict(test_x)\n",
    "    y_pred_2 = bst_2.predict(test_x)\n",
    "    \n",
    "    r += np.mean(np.abs(test_y_1 - y_pred_1) * q + np.abs(test_y_2 - y_pred_2) * q)\n",
    "    \n",
    "    for td in generate_test_data():\n",
    "        td = feature_engineering(td)\n",
    "        td = td.values.reshape(7, 48, -1)[(7 - x_day):, :, :].transpose(1, 0, 2).reshape(48, -1)\n",
    "        result.append(bst_1.predict(td))\n",
    "        result.append(bst_2.predict(td))\n",
    "    \n",
    "    submission_df[f\"q_{q}\"] = np.array(result).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-cnn best 1-12\n",
    "\n",
    "cutter = [\n",
    "    'DHI', \n",
    "    'DNI', \n",
    "#     'WS', \n",
    "#     'RH', \n",
    "#     'T', \n",
    "#     'Hour_sin',\n",
    "#     'Hour_cos', \n",
    "    'GHI', \n",
    "#     'TARGET_ROLLING_MEAN_3_shift_1',\n",
    "#     'TARGET_ROLLING_MEAN_5_shift_2', \n",
    "#     'TARGET_ROLLING_MEAN_11_shift_5',\n",
    "#     'TARGET_ROLLING_MEAN_23_shift_11', \n",
    "#     'TARGET_ROLLING_MEAN_47_shift_23',\n",
    "    'scaled_TARGET',\n",
    "    \"TARGET\",\n",
    "]\n",
    "train_df = train_df[cutter]\n",
    "valid_df = valid_df[cutter]\n",
    "test_df = test_df[cutter]\n",
    "\n",
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "\n",
    "days = 7\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=48 * days,\n",
    "    label_width=96,\n",
    "    shift=96,\n",
    "    sequence_stride=1,\n",
    "    label_columns=[\"TARGET\"]\n",
    "    \n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict(\"minmax\")\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * days)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various = Convolution2DVarious(days, 96, train_df.shape[-1] - 1)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various, one_days_window_label_columns, q)\n",
    "    evaluate_dict[q] = conv_various.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, days, 48, train_df.shape[-1] - 1)\n",
    "    pred_y = conv_various.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (dacon)",
   "language": "python",
   "name": "pycharm-549c67b6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}