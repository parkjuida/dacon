{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from src.trainers import compile_and_fit_with_pinball_loss\n",
    "from src.loaders.window_generator import WindowGenerator\n",
    "from src.loaders.data_loader import load_basic_preprocessed_train, load_submission_data\n",
    "from src.make_submissions.load_test_features import make_submission_df, to_submission_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 9), (10511, 9), (5257, 9)\n"
     ]
    }
   ],
   "source": [
    "from src.loaders.data_loader import load_train_data\n",
    "from src.preprocessors.preprocessors import split_train_valid_test\n",
    "\n",
    "train_df, valid_df, test_df = split_train_valid_test(load_train_data(), [0.7, 0.2, 0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target = train_df[\"TARGET\"]\n",
    "valid_df_target = valid_df[\"TARGET\"]\n",
    "test_df_target = test_df[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, test_df = load_basic_preprocessed_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[\"scaled_TARGET\"] = train_df[\"TARGET\"]\n",
    "valid_df[\"scaled_TARGET\"] = valid_df[\"TARGET\"]\n",
    "test_df[\"scaled_TARGET\"] = test_df[\"TARGET\"]\n",
    "\n",
    "train_df[\"TARGET\"] = train_df_target\n",
    "valid_df[\"TARGET\"] = valid_df_target\n",
    "test_df[\"TARGET\"] = test_df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DHI_min_max_scaled</th>\n",
       "      <th>DNI_min_max_scaled</th>\n",
       "      <th>GHI_min_max_scaled</th>\n",
       "      <th>WS_min_max_scaled</th>\n",
       "      <th>RH_min_max_scaled</th>\n",
       "      <th>T_min_max_scaled</th>\n",
       "      <th>scaled_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.652078</td>\n",
       "      <td>0.523656</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020308</td>\n",
       "      <td>1.329597</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>1.414117</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.652078</td>\n",
       "      <td>0.523656</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>-0.685276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.652078</td>\n",
       "      <td>0.522735</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020308</td>\n",
       "      <td>1.329597</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>1.414117</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.652078</td>\n",
       "      <td>0.522735</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>-0.685276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.647993</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020308</td>\n",
       "      <td>1.329597</td>\n",
       "      <td>0.365437</td>\n",
       "      <td>1.365930</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.647993</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>-0.685276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.646611</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020308</td>\n",
       "      <td>1.329597</td>\n",
       "      <td>0.365437</td>\n",
       "      <td>1.365930</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.646611</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>-0.685276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.805485</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020308</td>\n",
       "      <td>1.329597</td>\n",
       "      <td>0.706513</td>\n",
       "      <td>1.224651</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.805485</td>\n",
       "      <td>-1.983543</td>\n",
       "      <td>-0.685276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36787</th>\n",
       "      <td>-0.029736</td>\n",
       "      <td>1.862045</td>\n",
       "      <td>2.124474</td>\n",
       "      <td>-0.759309</td>\n",
       "      <td>-0.254832</td>\n",
       "      <td>37.912042</td>\n",
       "      <td>0.816634</td>\n",
       "      <td>1.070792</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>-1.000063</td>\n",
       "      <td>1.656074</td>\n",
       "      <td>-0.029736</td>\n",
       "      <td>1.862045</td>\n",
       "      <td>1.656074</td>\n",
       "      <td>2.124474</td>\n",
       "      <td>-0.759309</td>\n",
       "      <td>-0.254832</td>\n",
       "      <td>0.804417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>-0.010234</td>\n",
       "      <td>1.996416</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.834371</td>\n",
       "      <td>-0.158792</td>\n",
       "      <td>44.949675</td>\n",
       "      <td>0.816634</td>\n",
       "      <td>1.070792</td>\n",
       "      <td>0.706513</td>\n",
       "      <td>-1.224805</td>\n",
       "      <td>1.781253</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>1.996416</td>\n",
       "      <td>1.781253</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.834371</td>\n",
       "      <td>-0.158792</td>\n",
       "      <td>1.080949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>0.067773</td>\n",
       "      <td>1.944955</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.834832</td>\n",
       "      <td>-0.158792</td>\n",
       "      <td>49.078664</td>\n",
       "      <td>0.816634</td>\n",
       "      <td>1.070792</td>\n",
       "      <td>0.706513</td>\n",
       "      <td>-1.224805</td>\n",
       "      <td>1.755706</td>\n",
       "      <td>0.067773</td>\n",
       "      <td>1.944955</td>\n",
       "      <td>1.755706</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.834832</td>\n",
       "      <td>-0.158792</td>\n",
       "      <td>1.243191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>0.028769</td>\n",
       "      <td>2.127928</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.902066</td>\n",
       "      <td>-0.062753</td>\n",
       "      <td>55.083861</td>\n",
       "      <td>0.816634</td>\n",
       "      <td>1.070792</td>\n",
       "      <td>0.365437</td>\n",
       "      <td>-1.366084</td>\n",
       "      <td>1.908986</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>2.127928</td>\n",
       "      <td>1.908986</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.902066</td>\n",
       "      <td>-0.062753</td>\n",
       "      <td>1.479156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>1.793685</td>\n",
       "      <td>0.406841</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.902526</td>\n",
       "      <td>-0.062753</td>\n",
       "      <td>42.884709</td>\n",
       "      <td>0.816634</td>\n",
       "      <td>1.070792</td>\n",
       "      <td>0.365437</td>\n",
       "      <td>-1.366084</td>\n",
       "      <td>0.833472</td>\n",
       "      <td>1.793685</td>\n",
       "      <td>0.406841</td>\n",
       "      <td>0.833472</td>\n",
       "      <td>2.622830</td>\n",
       "      <td>-0.902526</td>\n",
       "      <td>-0.062753</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36792 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DHI       DNI        WS        RH         T     TARGET   Day_sin  \\\n",
       "0     -0.614791 -0.665264 -0.652078  0.523656 -1.983543   0.000000 -0.020308   \n",
       "1     -0.614791 -0.665264 -0.652078  0.522735 -1.983543   0.000000 -0.020308   \n",
       "2     -0.614791 -0.665264 -0.580885  0.647993 -1.983543   0.000000 -0.020308   \n",
       "3     -0.614791 -0.665264 -0.580885  0.646611 -1.983543   0.000000 -0.020308   \n",
       "4     -0.614791 -0.665264 -0.580885  0.805485 -1.983543   0.000000 -0.020308   \n",
       "...         ...       ...       ...       ...       ...        ...       ...   \n",
       "36787 -0.029736  1.862045  2.124474 -0.759309 -0.254832  37.912042  0.816634   \n",
       "36788 -0.010234  1.996416  2.622830 -0.834371 -0.158792  44.949675  0.816634   \n",
       "36789  0.067773  1.944955  2.622830 -0.834832 -0.158792  49.078664  0.816634   \n",
       "36790  0.028769  2.127928  2.622830 -0.902066 -0.062753  55.083861  0.816634   \n",
       "36791  1.793685  0.406841  2.622830 -0.902526 -0.062753  42.884709  0.816634   \n",
       "\n",
       "        Day_cos  Hour_sin  Hour_cos       GHI  DHI_min_max_scaled  \\\n",
       "0      1.329597 -0.000584  1.414117 -0.755529           -0.614791   \n",
       "1      1.329597 -0.000584  1.414117 -0.755529           -0.614791   \n",
       "2      1.329597  0.365437  1.365930 -0.755529           -0.614791   \n",
       "3      1.329597  0.365437  1.365930 -0.755529           -0.614791   \n",
       "4      1.329597  0.706513  1.224651 -0.755529           -0.614791   \n",
       "...         ...       ...       ...       ...                 ...   \n",
       "36787  1.070792  0.999403 -1.000063  1.656074           -0.029736   \n",
       "36788  1.070792  0.706513 -1.224805  1.781253           -0.010234   \n",
       "36789  1.070792  0.706513 -1.224805  1.755706            0.067773   \n",
       "36790  1.070792  0.365437 -1.366084  1.908986            0.028769   \n",
       "36791  1.070792  0.365437 -1.366084  0.833472            1.793685   \n",
       "\n",
       "       DNI_min_max_scaled  GHI_min_max_scaled  WS_min_max_scaled  \\\n",
       "0               -0.665264           -0.755529          -0.652078   \n",
       "1               -0.665264           -0.755529          -0.652078   \n",
       "2               -0.665264           -0.755529          -0.580885   \n",
       "3               -0.665264           -0.755529          -0.580885   \n",
       "4               -0.665264           -0.755529          -0.580885   \n",
       "...                   ...                 ...                ...   \n",
       "36787            1.862045            1.656074           2.124474   \n",
       "36788            1.996416            1.781253           2.622830   \n",
       "36789            1.944955            1.755706           2.622830   \n",
       "36790            2.127928            1.908986           2.622830   \n",
       "36791            0.406841            0.833472           2.622830   \n",
       "\n",
       "       RH_min_max_scaled  T_min_max_scaled  scaled_TARGET  \n",
       "0               0.523656         -1.983543      -0.685276  \n",
       "1               0.522735         -1.983543      -0.685276  \n",
       "2               0.647993         -1.983543      -0.685276  \n",
       "3               0.646611         -1.983543      -0.685276  \n",
       "4               0.805485         -1.983543      -0.685276  \n",
       "...                  ...               ...            ...  \n",
       "36787          -0.759309         -0.254832       0.804417  \n",
       "36788          -0.834371         -0.158792       1.080949  \n",
       "36789          -0.834832         -0.158792       1.243191  \n",
       "36790          -0.902066         -0.062753       1.479156  \n",
       "36791          -0.902526         -0.062753       0.999810  \n",
       "\n",
       "[36792 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020-12-30 최고 스코어\n",
    "\n",
    "cutter = [\n",
    "    \"DHI\", \n",
    "    \"DNI\", \n",
    "    \"GHI\", \n",
    "    \"DHI_min_max_scaled\", \n",
    "    \"DNI_min_max_scaled\", \n",
    "    \"GHI_min_max_scaled\", \n",
    "    \"scaled_TARGET\", \n",
    "    \"TARGET\",\n",
    "]\n",
    "\n",
    "from src.model.multiple_output.convolution import Convolution1D\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    conv1 = Convolution1D(ONE_DAY_STEPS, OUTPUT_STEPS, 7)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv1, one_days_window_label_columns, q)\n",
    "    conv1.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 7)\n",
    "    pred_y = conv1.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "to_submission_csv(submission_df, \"conv1d_not_scaled_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = [\n",
    "    \"DHI\",\n",
    "    \"DNI\",\n",
    "#     \"WS\",\n",
    "#     \"RH\",\n",
    "#     \"T\",\n",
    "#     \"Day_sin\",\n",
    "#     \"Day_cos\",\n",
    "#     \"Hour_sin\",\n",
    "#     \"Hour_cos\",\n",
    "    \"GHI\",\n",
    "    \"DHI_min_max_scaled\",\n",
    "    \"DNI_min_max_scaled\",\n",
    "    \"GHI_min_max_scaled\",\n",
    "#     \"WS_min_max_scaled\",\n",
    "#     \"RH_min_max_scaled\",\n",
    "#     \"T_min_max_scaled\",\n",
    "    \"scaled_TARGET\",\n",
    "    \"TARGET\",\n",
    "]\n",
    "train_df = train_df[cutter]\n",
    "valid_df = valid_df[cutter]\n",
    "test_df = test_df[cutter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DHI_min_max_scaled</th>\n",
       "      <th>DNI_min_max_scaled</th>\n",
       "      <th>GHI_min_max_scaled</th>\n",
       "      <th>scaled_TARGET</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.614791</td>\n",
       "      <td>-0.665264</td>\n",
       "      <td>-0.755529</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36787</th>\n",
       "      <td>-0.029736</td>\n",
       "      <td>1.862045</td>\n",
       "      <td>1.656074</td>\n",
       "      <td>-0.029736</td>\n",
       "      <td>1.862045</td>\n",
       "      <td>1.656074</td>\n",
       "      <td>0.804417</td>\n",
       "      <td>37.912042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>-0.010234</td>\n",
       "      <td>1.996416</td>\n",
       "      <td>1.781253</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>1.996416</td>\n",
       "      <td>1.781253</td>\n",
       "      <td>1.080949</td>\n",
       "      <td>44.949675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>0.067773</td>\n",
       "      <td>1.944955</td>\n",
       "      <td>1.755706</td>\n",
       "      <td>0.067773</td>\n",
       "      <td>1.944955</td>\n",
       "      <td>1.755706</td>\n",
       "      <td>1.243191</td>\n",
       "      <td>49.078664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>0.028769</td>\n",
       "      <td>2.127928</td>\n",
       "      <td>1.908986</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>2.127928</td>\n",
       "      <td>1.908986</td>\n",
       "      <td>1.479156</td>\n",
       "      <td>55.083861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>1.793685</td>\n",
       "      <td>0.406841</td>\n",
       "      <td>0.833472</td>\n",
       "      <td>1.793685</td>\n",
       "      <td>0.406841</td>\n",
       "      <td>0.833472</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>42.884709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36792 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DHI       DNI       GHI  DHI_min_max_scaled  DNI_min_max_scaled  \\\n",
       "0     -0.614791 -0.665264 -0.755529           -0.614791           -0.665264   \n",
       "1     -0.614791 -0.665264 -0.755529           -0.614791           -0.665264   \n",
       "2     -0.614791 -0.665264 -0.755529           -0.614791           -0.665264   \n",
       "3     -0.614791 -0.665264 -0.755529           -0.614791           -0.665264   \n",
       "4     -0.614791 -0.665264 -0.755529           -0.614791           -0.665264   \n",
       "...         ...       ...       ...                 ...                 ...   \n",
       "36787 -0.029736  1.862045  1.656074           -0.029736            1.862045   \n",
       "36788 -0.010234  1.996416  1.781253           -0.010234            1.996416   \n",
       "36789  0.067773  1.944955  1.755706            0.067773            1.944955   \n",
       "36790  0.028769  2.127928  1.908986            0.028769            2.127928   \n",
       "36791  1.793685  0.406841  0.833472            1.793685            0.406841   \n",
       "\n",
       "       GHI_min_max_scaled  scaled_TARGET     TARGET  \n",
       "0               -0.755529      -0.685276   0.000000  \n",
       "1               -0.755529      -0.685276   0.000000  \n",
       "2               -0.755529      -0.685276   0.000000  \n",
       "3               -0.755529      -0.685276   0.000000  \n",
       "4               -0.755529      -0.685276   0.000000  \n",
       "...                   ...            ...        ...  \n",
       "36787            1.656074       0.804417  37.912042  \n",
       "36788            1.781253       1.080949  44.949675  \n",
       "36789            1.755706       1.243191  49.078664  \n",
       "36790            1.908986       1.479156  55.083861  \n",
       "36791            0.833472       0.999810  42.884709  \n",
       "\n",
       "[36792 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAU = 0.5\n",
    "ONE_DAY_STEPS = 48\n",
    "OUTPUT_STEPS = ONE_DAY_STEPS * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 13s 6ms/step - loss: 1.4835 - mean_absolute_error: 12.9946 - mean_squared_error: 529.6346 - _pinball_loss: 1.4835 - val_loss: 1.7758 - val_mean_absolute_error: 14.5262 - val_mean_squared_error: 583.4628 - val__pinball_loss: 1.7758\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3941 - mean_absolute_error: 11.6825 - mean_squared_error: 433.6613 - _pinball_loss: 1.3941 - val_loss: 1.7648 - val_mean_absolute_error: 14.4343 - val_mean_squared_error: 580.5062 - val__pinball_loss: 1.7648\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3808 - mean_absolute_error: 11.5381 - mean_squared_error: 427.0672 - _pinball_loss: 1.3808 - val_loss: 1.7593 - val_mean_absolute_error: 14.4524 - val_mean_squared_error: 581.1046 - val__pinball_loss: 1.7593\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3716 - mean_absolute_error: 11.4459 - mean_squared_error: 422.1804 - _pinball_loss: 1.3716 - val_loss: 1.7513 - val_mean_absolute_error: 14.3794 - val_mean_squared_error: 584.0995 - val__pinball_loss: 1.7513\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3647 - mean_absolute_error: 11.3753 - mean_squared_error: 418.6827 - _pinball_loss: 1.3647 - val_loss: 1.7519 - val_mean_absolute_error: 13.9361 - val_mean_squared_error: 550.4869 - val__pinball_loss: 1.7519\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3578 - mean_absolute_error: 11.2973 - mean_squared_error: 415.0477 - _pinball_loss: 1.3578 - val_loss: 1.7562 - val_mean_absolute_error: 14.2261 - val_mean_squared_error: 572.1569 - val__pinball_loss: 1.7562\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3526 - mean_absolute_error: 11.2409 - mean_squared_error: 411.5334 - _pinball_loss: 1.3526 - val_loss: 1.7494 - val_mean_absolute_error: 14.2086 - val_mean_squared_error: 572.3550 - val__pinball_loss: 1.7494\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3479 - mean_absolute_error: 11.2002 - mean_squared_error: 409.9131 - _pinball_loss: 1.3479 - val_loss: 1.7519 - val_mean_absolute_error: 14.0857 - val_mean_squared_error: 560.0237 - val__pinball_loss: 1.7519\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3438 - mean_absolute_error: 11.1466 - mean_squared_error: 406.9902 - _pinball_loss: 1.3438 - val_loss: 1.7494 - val_mean_absolute_error: 13.9952 - val_mean_squared_error: 555.2826 - val__pinball_loss: 1.7494\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3390 - mean_absolute_error: 11.1230 - mean_squared_error: 406.3080 - _pinball_loss: 1.3390 - val_loss: 1.7490 - val_mean_absolute_error: 14.0493 - val_mean_squared_error: 561.3093 - val__pinball_loss: 1.7490\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3342 - mean_absolute_error: 11.0653 - mean_squared_error: 403.2349 - _pinball_loss: 1.3342 - val_loss: 1.7578 - val_mean_absolute_error: 13.7809 - val_mean_squared_error: 545.0695 - val__pinball_loss: 1.7578\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3313 - mean_absolute_error: 11.0338 - mean_squared_error: 401.5016 - _pinball_loss: 1.3313 - val_loss: 1.7524 - val_mean_absolute_error: 14.0195 - val_mean_squared_error: 560.2481 - val__pinball_loss: 1.7524\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3262 - mean_absolute_error: 11.0052 - mean_squared_error: 400.4345 - _pinball_loss: 1.3262 - val_loss: 1.7520 - val_mean_absolute_error: 13.8949 - val_mean_squared_error: 554.4397 - val__pinball_loss: 1.7520\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3227 - mean_absolute_error: 10.9798 - mean_squared_error: 399.4762 - _pinball_loss: 1.3227 - val_loss: 1.7484 - val_mean_absolute_error: 14.0053 - val_mean_squared_error: 562.9985 - val__pinball_loss: 1.7484\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3185 - mean_absolute_error: 10.9376 - mean_squared_error: 397.1864 - _pinball_loss: 1.3185 - val_loss: 1.7471 - val_mean_absolute_error: 14.0926 - val_mean_squared_error: 568.1865 - val__pinball_loss: 1.7471\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3158 - mean_absolute_error: 10.9066 - mean_squared_error: 395.1822 - _pinball_loss: 1.3158 - val_loss: 1.7595 - val_mean_absolute_error: 13.7499 - val_mean_squared_error: 543.8970 - val__pinball_loss: 1.7595\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3121 - mean_absolute_error: 10.8546 - mean_squared_error: 392.6166 - _pinball_loss: 1.3121 - val_loss: 1.7465 - val_mean_absolute_error: 14.0433 - val_mean_squared_error: 564.7562 - val__pinball_loss: 1.7465\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3088 - mean_absolute_error: 10.8596 - mean_squared_error: 393.1679 - _pinball_loss: 1.3088 - val_loss: 1.7469 - val_mean_absolute_error: 14.1418 - val_mean_squared_error: 574.4465 - val__pinball_loss: 1.7469\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3035 - mean_absolute_error: 10.8015 - mean_squared_error: 389.8612 - _pinball_loss: 1.3035 - val_loss: 1.7614 - val_mean_absolute_error: 13.5618 - val_mean_squared_error: 531.9610 - val__pinball_loss: 1.7614\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.2989 - mean_absolute_error: 10.7476 - mean_squared_error: 386.6604 - _pinball_loss: 1.2989 - val_loss: 1.7543 - val_mean_absolute_error: 13.6702 - val_mean_squared_error: 538.2889 - val__pinball_loss: 1.7543\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.2971 - mean_absolute_error: 10.7269 - mean_squared_error: 385.3413 - _pinball_loss: 1.2971 - val_loss: 1.7561 - val_mean_absolute_error: 14.0233 - val_mean_squared_error: 565.1736 - val__pinball_loss: 1.7561\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.2926 - mean_absolute_error: 10.7067 - mean_squared_error: 384.4371 - _pinball_loss: 1.2926 - val_loss: 1.7577 - val_mean_absolute_error: 13.9310 - val_mean_squared_error: 560.3847 - val__pinball_loss: 1.7577\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5077 - mean_absolute_error: 10.0448 - mean_squared_error: 325.8615 - _pinball_loss: 2.5077 - val_loss: 2.8823 - val_mean_absolute_error: 11.0559 - val_mean_squared_error: 344.4185 - val__pinball_loss: 2.8823\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 2.2597 - mean_absolute_error: 8.4907 - mean_squared_error: 232.9773 - _pinball_loss: 2.2597 - val_loss: 2.8656 - val_mean_absolute_error: 10.7483 - val_mean_squared_error: 329.6806 - val__pinball_loss: 2.8656\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 2.2350 - mean_absolute_error: 8.3673 - mean_squared_error: 228.8025 - _pinball_loss: 2.2350 - val_loss: 2.8470 - val_mean_absolute_error: 10.8513 - val_mean_squared_error: 339.1051 - val__pinball_loss: 2.8470\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 2.2170 - mean_absolute_error: 8.2809 - mean_squared_error: 226.1463 - _pinball_loss: 2.2170 - val_loss: 2.8249 - val_mean_absolute_error: 10.6795 - val_mean_squared_error: 329.6293 - val__pinball_loss: 2.8249\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 2.2055 - mean_absolute_error: 8.2086 - mean_squared_error: 223.6366 - _pinball_loss: 2.2055 - val_loss: 2.8303 - val_mean_absolute_error: 10.4518 - val_mean_squared_error: 317.8514 - val__pinball_loss: 2.8303\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1944 - mean_absolute_error: 8.1508 - mean_squared_error: 221.4425 - _pinball_loss: 2.1944 - val_loss: 2.8294 - val_mean_absolute_error: 10.6327 - val_mean_squared_error: 324.9436 - val__pinball_loss: 2.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1853 - mean_absolute_error: 8.1213 - mean_squared_error: 220.5482 - _pinball_loss: 2.1853 - val_loss: 2.8186 - val_mean_absolute_error: 10.6461 - val_mean_squared_error: 327.1314 - val__pinball_loss: 2.8186\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1786 - mean_absolute_error: 8.0854 - mean_squared_error: 219.5327 - _pinball_loss: 2.1786 - val_loss: 2.8273 - val_mean_absolute_error: 10.5970 - val_mean_squared_error: 329.8870 - val__pinball_loss: 2.8273\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1686 - mean_absolute_error: 8.0463 - mean_squared_error: 218.3473 - _pinball_loss: 2.1686 - val_loss: 2.8136 - val_mean_absolute_error: 10.5580 - val_mean_squared_error: 323.1363 - val__pinball_loss: 2.8136\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1633 - mean_absolute_error: 8.0244 - mean_squared_error: 217.7154 - _pinball_loss: 2.1633 - val_loss: 2.8164 - val_mean_absolute_error: 10.3072 - val_mean_squared_error: 313.0830 - val__pinball_loss: 2.8164\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1559 - mean_absolute_error: 7.9901 - mean_squared_error: 216.6342 - _pinball_loss: 2.1559 - val_loss: 2.8195 - val_mean_absolute_error: 10.4679 - val_mean_squared_error: 323.2464 - val__pinball_loss: 2.8195\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1514 - mean_absolute_error: 7.9751 - mean_squared_error: 216.3503 - _pinball_loss: 2.1514 - val_loss: 2.8183 - val_mean_absolute_error: 10.4640 - val_mean_squared_error: 319.9869 - val__pinball_loss: 2.8183\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1419 - mean_absolute_error: 7.9420 - mean_squared_error: 215.1330 - _pinball_loss: 2.1419 - val_loss: 2.8046 - val_mean_absolute_error: 10.5008 - val_mean_squared_error: 323.7769 - val__pinball_loss: 2.8046\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1357 - mean_absolute_error: 7.9162 - mean_squared_error: 214.4703 - _pinball_loss: 2.1357 - val_loss: 2.8028 - val_mean_absolute_error: 10.4807 - val_mean_squared_error: 322.5449 - val__pinball_loss: 2.8028\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1309 - mean_absolute_error: 7.9038 - mean_squared_error: 214.1354 - _pinball_loss: 2.1309 - val_loss: 2.8097 - val_mean_absolute_error: 10.2902 - val_mean_squared_error: 312.5414 - val__pinball_loss: 2.8097\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1214 - mean_absolute_error: 7.8783 - mean_squared_error: 213.6753 - _pinball_loss: 2.1214 - val_loss: 2.8090 - val_mean_absolute_error: 10.6738 - val_mean_squared_error: 332.5410 - val__pinball_loss: 2.8090\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1146 - mean_absolute_error: 7.8408 - mean_squared_error: 212.1755 - _pinball_loss: 2.1146 - val_loss: 2.8107 - val_mean_absolute_error: 10.3546 - val_mean_squared_error: 319.2029 - val__pinball_loss: 2.8107\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1075 - mean_absolute_error: 7.8143 - mean_squared_error: 211.1643 - _pinball_loss: 2.1075 - val_loss: 2.8072 - val_mean_absolute_error: 10.6540 - val_mean_squared_error: 331.9210 - val__pinball_loss: 2.8072\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.1013 - mean_absolute_error: 7.7892 - mean_squared_error: 209.9170 - _pinball_loss: 2.1013 - val_loss: 2.8140 - val_mean_absolute_error: 10.3206 - val_mean_squared_error: 314.2479 - val__pinball_loss: 2.8140\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 3.1451 - mean_absolute_error: 8.2589 - mean_squared_error: 227.4410 - _pinball_loss: 3.1451 - val_loss: 3.4646 - val_mean_absolute_error: 8.5974 - val_mean_squared_error: 217.4745 - val__pinball_loss: 3.4646\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7207 - mean_absolute_error: 6.6928 - mean_squared_error: 149.1556 - _pinball_loss: 2.7207 - val_loss: 3.4362 - val_mean_absolute_error: 8.5366 - val_mean_squared_error: 218.8473 - val__pinball_loss: 3.4362\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6850 - mean_absolute_error: 6.5938 - mean_squared_error: 147.5640 - _pinball_loss: 2.6850 - val_loss: 3.4441 - val_mean_absolute_error: 8.6201 - val_mean_squared_error: 222.2508 - val__pinball_loss: 3.4441\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6661 - mean_absolute_error: 6.5330 - mean_squared_error: 145.9490 - _pinball_loss: 2.6661 - val_loss: 3.4216 - val_mean_absolute_error: 8.5800 - val_mean_squared_error: 222.8764 - val__pinball_loss: 3.4216\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6522 - mean_absolute_error: 6.4953 - mean_squared_error: 145.2214 - _pinball_loss: 2.6522 - val_loss: 3.4201 - val_mean_absolute_error: 8.5754 - val_mean_squared_error: 223.2227 - val__pinball_loss: 3.4201\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6356 - mean_absolute_error: 6.4467 - mean_squared_error: 144.1453 - _pinball_loss: 2.6356 - val_loss: 3.3969 - val_mean_absolute_error: 8.4549 - val_mean_squared_error: 217.7938 - val__pinball_loss: 3.3969\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6240 - mean_absolute_error: 6.4190 - mean_squared_error: 143.6842 - _pinball_loss: 2.6240 - val_loss: 3.4090 - val_mean_absolute_error: 8.5908 - val_mean_squared_error: 221.9436 - val__pinball_loss: 3.4090\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6134 - mean_absolute_error: 6.3775 - mean_squared_error: 142.2476 - _pinball_loss: 2.6134 - val_loss: 3.3877 - val_mean_absolute_error: 8.5136 - val_mean_squared_error: 218.8060 - val__pinball_loss: 3.3877\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6048 - mean_absolute_error: 6.3508 - mean_squared_error: 141.6699 - _pinball_loss: 2.6048 - val_loss: 3.4169 - val_mean_absolute_error: 8.4548 - val_mean_squared_error: 217.3512 - val__pinball_loss: 3.4169\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5933 - mean_absolute_error: 6.3109 - mean_squared_error: 140.4324 - _pinball_loss: 2.5933 - val_loss: 3.3866 - val_mean_absolute_error: 8.3214 - val_mean_squared_error: 213.1876 - val__pinball_loss: 3.3866\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5845 - mean_absolute_error: 6.2866 - mean_squared_error: 140.1477 - _pinball_loss: 2.5845 - val_loss: 3.3642 - val_mean_absolute_error: 8.3395 - val_mean_squared_error: 213.8114 - val__pinball_loss: 3.3642\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5781 - mean_absolute_error: 6.2761 - mean_squared_error: 139.9301 - _pinball_loss: 2.5781 - val_loss: 3.3674 - val_mean_absolute_error: 8.3081 - val_mean_squared_error: 214.8383 - val__pinball_loss: 3.3674\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5715 - mean_absolute_error: 6.2609 - mean_squared_error: 139.5980 - _pinball_loss: 2.5715 - val_loss: 3.3765 - val_mean_absolute_error: 8.4789 - val_mean_squared_error: 219.0336 - val__pinball_loss: 3.3765\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5630 - mean_absolute_error: 6.2419 - mean_squared_error: 139.1170 - _pinball_loss: 2.5630 - val_loss: 3.3678 - val_mean_absolute_error: 8.3065 - val_mean_squared_error: 216.2021 - val__pinball_loss: 3.3678\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5582 - mean_absolute_error: 6.2227 - mean_squared_error: 138.5725 - _pinball_loss: 2.5582 - val_loss: 3.3639 - val_mean_absolute_error: 8.3039 - val_mean_squared_error: 215.8552 - val__pinball_loss: 3.3639\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5473 - mean_absolute_error: 6.1999 - mean_squared_error: 138.3235 - _pinball_loss: 2.5473 - val_loss: 3.3685 - val_mean_absolute_error: 8.3014 - val_mean_squared_error: 213.1568 - val__pinball_loss: 3.3685\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5409 - mean_absolute_error: 6.1789 - mean_squared_error: 137.6132 - _pinball_loss: 2.5409 - val_loss: 3.3505 - val_mean_absolute_error: 8.3153 - val_mean_squared_error: 218.9915 - val__pinball_loss: 3.3505\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5315 - mean_absolute_error: 6.1542 - mean_squared_error: 137.0791 - _pinball_loss: 2.5315 - val_loss: 3.3733 - val_mean_absolute_error: 8.5017 - val_mean_squared_error: 223.0667 - val__pinball_loss: 3.3733\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5250 - mean_absolute_error: 6.1367 - mean_squared_error: 136.3944 - _pinball_loss: 2.5250 - val_loss: 3.3687 - val_mean_absolute_error: 8.3577 - val_mean_squared_error: 218.8835 - val__pinball_loss: 3.3687\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5158 - mean_absolute_error: 6.1203 - mean_squared_error: 136.0046 - _pinball_loss: 2.5158 - val_loss: 3.3600 - val_mean_absolute_error: 8.3718 - val_mean_squared_error: 221.5096 - val__pinball_loss: 3.3600\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5105 - mean_absolute_error: 6.1035 - mean_squared_error: 135.4019 - _pinball_loss: 2.5105 - val_loss: 3.3703 - val_mean_absolute_error: 8.3042 - val_mean_squared_error: 218.6417 - val__pinball_loss: 3.3703\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5013 - mean_absolute_error: 6.0789 - mean_squared_error: 134.7907 - _pinball_loss: 2.5013 - val_loss: 3.3882 - val_mean_absolute_error: 8.2991 - val_mean_squared_error: 219.2939 - val__pinball_loss: 3.3882\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 3.5001 - mean_absolute_error: 7.4402 - mean_squared_error: 199.2571 - _pinball_loss: 3.5001 - val_loss: 3.6988 - val_mean_absolute_error: 7.4854 - val_mean_squared_error: 185.5270 - val__pinball_loss: 3.6988\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.8695 - mean_absolute_error: 5.8228 - mean_squared_error: 125.9450 - _pinball_loss: 2.8695 - val_loss: 3.6534 - val_mean_absolute_error: 7.4010 - val_mean_squared_error: 184.9499 - val__pinball_loss: 3.6534\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.8363 - mean_absolute_error: 5.7541 - mean_squared_error: 124.5769 - _pinball_loss: 2.8363 - val_loss: 3.6405 - val_mean_absolute_error: 7.4275 - val_mean_squared_error: 185.3926 - val__pinball_loss: 3.6405\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.8136 - mean_absolute_error: 5.7015 - mean_squared_error: 123.6434 - _pinball_loss: 2.8136 - val_loss: 3.6496 - val_mean_absolute_error: 7.4029 - val_mean_squared_error: 186.8201 - val__pinball_loss: 3.6496\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7996 - mean_absolute_error: 5.6707 - mean_squared_error: 122.8949 - _pinball_loss: 2.7996 - val_loss: 3.6263 - val_mean_absolute_error: 7.3509 - val_mean_squared_error: 184.7999 - val__pinball_loss: 3.6263\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7851 - mean_absolute_error: 5.6329 - mean_squared_error: 122.0532 - _pinball_loss: 2.7851 - val_loss: 3.5922 - val_mean_absolute_error: 7.3298 - val_mean_squared_error: 182.7131 - val__pinball_loss: 3.5922\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7714 - mean_absolute_error: 5.6029 - mean_squared_error: 121.3863 - _pinball_loss: 2.7714 - val_loss: 3.6003 - val_mean_absolute_error: 7.3650 - val_mean_squared_error: 182.7166 - val__pinball_loss: 3.6003\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7595 - mean_absolute_error: 5.5737 - mean_squared_error: 120.7995 - _pinball_loss: 2.7595 - val_loss: 3.6057 - val_mean_absolute_error: 7.3030 - val_mean_squared_error: 183.0684 - val__pinball_loss: 3.6057\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7489 - mean_absolute_error: 5.5441 - mean_squared_error: 120.0815 - _pinball_loss: 2.7489 - val_loss: 3.5681 - val_mean_absolute_error: 7.2686 - val_mean_squared_error: 179.9520 - val__pinball_loss: 3.5681\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7390 - mean_absolute_error: 5.5244 - mean_squared_error: 119.6068 - _pinball_loss: 2.7390 - val_loss: 3.5847 - val_mean_absolute_error: 7.2857 - val_mean_squared_error: 181.1807 - val__pinball_loss: 3.5847\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7279 - mean_absolute_error: 5.4992 - mean_squared_error: 118.9583 - _pinball_loss: 2.7279 - val_loss: 3.5880 - val_mean_absolute_error: 7.2847 - val_mean_squared_error: 181.2721 - val__pinball_loss: 3.5880\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7205 - mean_absolute_error: 5.4857 - mean_squared_error: 118.6163 - _pinball_loss: 2.7205 - val_loss: 3.5685 - val_mean_absolute_error: 7.2896 - val_mean_squared_error: 180.3939 - val__pinball_loss: 3.5685\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7114 - mean_absolute_error: 5.4665 - mean_squared_error: 118.1251 - _pinball_loss: 2.7114 - val_loss: 3.5634 - val_mean_absolute_error: 7.2332 - val_mean_squared_error: 180.5715 - val__pinball_loss: 3.5634\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7010 - mean_absolute_error: 5.4419 - mean_squared_error: 117.5343 - _pinball_loss: 2.7010 - val_loss: 3.5770 - val_mean_absolute_error: 7.2672 - val_mean_squared_error: 181.1403 - val__pinball_loss: 3.5770\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6923 - mean_absolute_error: 5.4246 - mean_squared_error: 117.1691 - _pinball_loss: 2.6923 - val_loss: 3.5738 - val_mean_absolute_error: 7.1799 - val_mean_squared_error: 181.6593 - val__pinball_loss: 3.5738\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6859 - mean_absolute_error: 5.4057 - mean_squared_error: 116.6776 - _pinball_loss: 2.6859 - val_loss: 3.5542 - val_mean_absolute_error: 7.1459 - val_mean_squared_error: 180.9932 - val__pinball_loss: 3.5542\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6779 - mean_absolute_error: 5.3913 - mean_squared_error: 116.2975 - _pinball_loss: 2.6779 - val_loss: 3.5433 - val_mean_absolute_error: 7.1704 - val_mean_squared_error: 179.9232 - val__pinball_loss: 3.5433\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6698 - mean_absolute_error: 5.3747 - mean_squared_error: 115.9945 - _pinball_loss: 2.6698 - val_loss: 3.5760 - val_mean_absolute_error: 7.1885 - val_mean_squared_error: 181.2061 - val__pinball_loss: 3.5760\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6636 - mean_absolute_error: 5.3610 - mean_squared_error: 115.4882 - _pinball_loss: 2.6636 - val_loss: 3.5599 - val_mean_absolute_error: 7.2401 - val_mean_squared_error: 182.3013 - val__pinball_loss: 3.5599\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6563 - mean_absolute_error: 5.3473 - mean_squared_error: 115.1855 - _pinball_loss: 2.6563 - val_loss: 3.5476 - val_mean_absolute_error: 7.1893 - val_mean_squared_error: 180.3778 - val__pinball_loss: 3.5476\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6477 - mean_absolute_error: 5.3331 - mean_squared_error: 114.7753 - _pinball_loss: 2.6477 - val_loss: 3.5676 - val_mean_absolute_error: 7.0949 - val_mean_squared_error: 183.1418 - val__pinball_loss: 3.5676\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6385 - mean_absolute_error: 5.3099 - mean_squared_error: 114.1739 - _pinball_loss: 2.6385 - val_loss: 3.5653 - val_mean_absolute_error: 7.3280 - val_mean_squared_error: 182.5455 - val__pinball_loss: 3.5653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 3.6073 - mean_absolute_error: 7.2146 - mean_squared_error: 198.5323 - _pinball_loss: 3.6073 - val_loss: 3.5783 - val_mean_absolute_error: 7.1565 - val_mean_squared_error: 194.8312 - val__pinball_loss: 3.5783\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7950 - mean_absolute_error: 5.5900 - mean_squared_error: 134.5321 - _pinball_loss: 2.7950 - val_loss: 3.5734 - val_mean_absolute_error: 7.1469 - val_mean_squared_error: 185.7621 - val__pinball_loss: 3.5734\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7590 - mean_absolute_error: 5.5179 - mean_squared_error: 132.6568 - _pinball_loss: 2.7590 - val_loss: 3.5706 - val_mean_absolute_error: 7.1412 - val_mean_squared_error: 184.5065 - val__pinball_loss: 3.5706\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7412 - mean_absolute_error: 5.4823 - mean_squared_error: 131.5734 - _pinball_loss: 2.7412 - val_loss: 3.5087 - val_mean_absolute_error: 7.0174 - val_mean_squared_error: 194.9110 - val__pinball_loss: 3.5087\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7193 - mean_absolute_error: 5.4386 - mean_squared_error: 130.9762 - _pinball_loss: 2.7193 - val_loss: 3.5268 - val_mean_absolute_error: 7.0537 - val_mean_squared_error: 188.4882 - val__pinball_loss: 3.5268\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.7075 - mean_absolute_error: 5.4151 - mean_squared_error: 130.1570 - _pinball_loss: 2.7075 - val_loss: 3.5029 - val_mean_absolute_error: 7.0057 - val_mean_squared_error: 189.0226 - val__pinball_loss: 3.5029\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6931 - mean_absolute_error: 5.3863 - mean_squared_error: 129.5684 - _pinball_loss: 2.6931 - val_loss: 3.4913 - val_mean_absolute_error: 6.9826 - val_mean_squared_error: 184.9332 - val__pinball_loss: 3.4913\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6798 - mean_absolute_error: 5.3595 - mean_squared_error: 129.0942 - _pinball_loss: 2.6798 - val_loss: 3.4977 - val_mean_absolute_error: 6.9954 - val_mean_squared_error: 190.8779 - val__pinball_loss: 3.4977\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6682 - mean_absolute_error: 5.3364 - mean_squared_error: 128.7742 - _pinball_loss: 2.6682 - val_loss: 3.4527 - val_mean_absolute_error: 6.9054 - val_mean_squared_error: 186.4797 - val__pinball_loss: 3.4527\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6566 - mean_absolute_error: 5.3132 - mean_squared_error: 128.3200 - _pinball_loss: 2.6566 - val_loss: 3.4841 - val_mean_absolute_error: 6.9681 - val_mean_squared_error: 191.7609 - val__pinball_loss: 3.4841\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6437 - mean_absolute_error: 5.2875 - mean_squared_error: 127.9443 - _pinball_loss: 2.6437 - val_loss: 3.4774 - val_mean_absolute_error: 6.9548 - val_mean_squared_error: 189.0212 - val__pinball_loss: 3.4774\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6333 - mean_absolute_error: 5.2667 - mean_squared_error: 127.4403 - _pinball_loss: 2.6333 - val_loss: 3.4656 - val_mean_absolute_error: 6.9313 - val_mean_squared_error: 192.0483 - val__pinball_loss: 3.4656\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6288 - mean_absolute_error: 5.2576 - mean_squared_error: 127.1992 - _pinball_loss: 2.6288 - val_loss: 3.4403 - val_mean_absolute_error: 6.8805 - val_mean_squared_error: 186.6482 - val__pinball_loss: 3.4403\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6147 - mean_absolute_error: 5.2294 - mean_squared_error: 126.7536 - _pinball_loss: 2.6147 - val_loss: 3.4313 - val_mean_absolute_error: 6.8626 - val_mean_squared_error: 186.7024 - val__pinball_loss: 3.4313\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.6077 - mean_absolute_error: 5.2155 - mean_squared_error: 126.0519 - _pinball_loss: 2.6077 - val_loss: 3.4432 - val_mean_absolute_error: 6.8864 - val_mean_squared_error: 186.0415 - val__pinball_loss: 3.4432\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5962 - mean_absolute_error: 5.1924 - mean_squared_error: 125.4929 - _pinball_loss: 2.5962 - val_loss: 3.4620 - val_mean_absolute_error: 6.9240 - val_mean_squared_error: 186.5829 - val__pinball_loss: 3.4620\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5905 - mean_absolute_error: 5.1810 - mean_squared_error: 125.2395 - _pinball_loss: 2.5905 - val_loss: 3.4539 - val_mean_absolute_error: 6.9079 - val_mean_squared_error: 183.7765 - val__pinball_loss: 3.4539\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5845 - mean_absolute_error: 5.1690 - mean_squared_error: 124.8288 - _pinball_loss: 2.5845 - val_loss: 3.4444 - val_mean_absolute_error: 6.8887 - val_mean_squared_error: 184.9579 - val__pinball_loss: 3.4444\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5761 - mean_absolute_error: 5.1521 - mean_squared_error: 124.4443 - _pinball_loss: 2.5761 - val_loss: 3.4377 - val_mean_absolute_error: 6.8754 - val_mean_squared_error: 187.0363 - val__pinball_loss: 3.4377\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CDD4B5A4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 3.5225 - mean_absolute_error: 7.4504 - mean_squared_error: 215.3665 - _pinball_loss: 3.5225 - val_loss: 3.1992 - val_mean_absolute_error: 7.3056 - val_mean_squared_error: 233.6563 - val__pinball_loss: 3.1992\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.5127 - mean_absolute_error: 5.7071 - mean_squared_error: 155.9197 - _pinball_loss: 2.5127 - val_loss: 3.1892 - val_mean_absolute_error: 7.3942 - val_mean_squared_error: 245.2135 - val__pinball_loss: 3.1892\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.4722 - mean_absolute_error: 5.6291 - mean_squared_error: 154.3574 - _pinball_loss: 2.4722 - val_loss: 3.1575 - val_mean_absolute_error: 7.1113 - val_mean_squared_error: 219.5815 - val__pinball_loss: 3.1575\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.4491 - mean_absolute_error: 5.5852 - mean_squared_error: 153.2639 - _pinball_loss: 2.4491 - val_loss: 3.1402 - val_mean_absolute_error: 7.2272 - val_mean_squared_error: 231.8455 - val__pinball_loss: 3.1402\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.4313 - mean_absolute_error: 5.5501 - mean_squared_error: 152.4236 - _pinball_loss: 2.4313 - val_loss: 3.0875 - val_mean_absolute_error: 7.0721 - val_mean_squared_error: 222.1916 - val__pinball_loss: 3.0875\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.4155 - mean_absolute_error: 5.5213 - mean_squared_error: 151.9707 - _pinball_loss: 2.4155 - val_loss: 3.0907 - val_mean_absolute_error: 7.1090 - val_mean_squared_error: 230.6545 - val__pinball_loss: 3.0907\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.4001 - mean_absolute_error: 5.4950 - mean_squared_error: 151.8030 - _pinball_loss: 2.4001 - val_loss: 3.1053 - val_mean_absolute_error: 7.1761 - val_mean_squared_error: 231.0065 - val__pinball_loss: 3.1053\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3851 - mean_absolute_error: 5.4660 - mean_squared_error: 151.2200 - _pinball_loss: 2.3851 - val_loss: 3.0739 - val_mean_absolute_error: 7.0929 - val_mean_squared_error: 230.5540 - val__pinball_loss: 3.0739\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3716 - mean_absolute_error: 5.4399 - mean_squared_error: 150.7613 - _pinball_loss: 2.3717 - val_loss: 3.0872 - val_mean_absolute_error: 7.0434 - val_mean_squared_error: 224.3616 - val__pinball_loss: 3.0872\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3575 - mean_absolute_error: 5.4131 - mean_squared_error: 150.4212 - _pinball_loss: 2.3575 - val_loss: 3.0794 - val_mean_absolute_error: 7.0839 - val_mean_squared_error: 227.5945 - val__pinball_loss: 3.0794\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3511 - mean_absolute_error: 5.4053 - mean_squared_error: 150.6314 - _pinball_loss: 2.3511 - val_loss: 3.0760 - val_mean_absolute_error: 7.0603 - val_mean_squared_error: 226.9332 - val__pinball_loss: 3.0760\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3380 - mean_absolute_error: 5.3789 - mean_squared_error: 150.1693 - _pinball_loss: 2.3380 - val_loss: 3.0589 - val_mean_absolute_error: 7.0051 - val_mean_squared_error: 225.4266 - val__pinball_loss: 3.0589\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3299 - mean_absolute_error: 5.3597 - mean_squared_error: 149.4319 - _pinball_loss: 2.3299 - val_loss: 3.0480 - val_mean_absolute_error: 7.0596 - val_mean_squared_error: 230.7028 - val__pinball_loss: 3.0480\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3237 - mean_absolute_error: 5.3483 - mean_squared_error: 149.2785 - _pinball_loss: 2.3237 - val_loss: 3.0308 - val_mean_absolute_error: 7.0013 - val_mean_squared_error: 228.2438 - val__pinball_loss: 3.0308\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3179 - mean_absolute_error: 5.3371 - mean_squared_error: 149.0462 - _pinball_loss: 2.3179 - val_loss: 3.0313 - val_mean_absolute_error: 6.9978 - val_mean_squared_error: 226.6049 - val__pinball_loss: 3.0313\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3094 - mean_absolute_error: 5.3221 - mean_squared_error: 148.9238 - _pinball_loss: 2.3094 - val_loss: 3.0606 - val_mean_absolute_error: 7.0316 - val_mean_squared_error: 225.6651 - val__pinball_loss: 3.0606\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3029 - mean_absolute_error: 5.3050 - mean_squared_error: 148.3412 - _pinball_loss: 2.3029 - val_loss: 3.0651 - val_mean_absolute_error: 7.0172 - val_mean_squared_error: 223.8119 - val__pinball_loss: 3.0651\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.2997 - mean_absolute_error: 5.2994 - mean_squared_error: 148.1865 - _pinball_loss: 2.2997 - val_loss: 3.0438 - val_mean_absolute_error: 7.0237 - val_mean_squared_error: 228.3602 - val__pinball_loss: 3.0438\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.2985 - mean_absolute_error: 5.2937 - mean_squared_error: 147.6919 - _pinball_loss: 2.2985 - val_loss: 3.0435 - val_mean_absolute_error: 7.0465 - val_mean_squared_error: 229.7359 - val__pinball_loss: 3.0435\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CDFF31C318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 3.2776 - mean_absolute_error: 8.0998 - mean_squared_error: 243.4014 - _pinball_loss: 3.2776 - val_loss: 2.6942 - val_mean_absolute_error: 7.6955 - val_mean_squared_error: 263.8210 - val__pinball_loss: 2.6942\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.0888 - mean_absolute_error: 6.0990 - mean_squared_error: 182.4794 - _pinball_loss: 2.0888 - val_loss: 2.6069 - val_mean_absolute_error: 7.7971 - val_mean_squared_error: 273.5926 - val__pinball_loss: 2.6069\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.0481 - mean_absolute_error: 6.0194 - mean_squared_error: 181.6020 - _pinball_loss: 2.0481 - val_loss: 2.6079 - val_mean_absolute_error: 7.7454 - val_mean_squared_error: 275.2198 - val__pinball_loss: 2.6079\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.0131 - mean_absolute_error: 5.9479 - mean_squared_error: 180.6456 - _pinball_loss: 2.0131 - val_loss: 2.5713 - val_mean_absolute_error: 7.3779 - val_mean_squared_error: 250.4840 - val__pinball_loss: 2.5713\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.0001 - mean_absolute_error: 5.9241 - mean_squared_error: 180.2629 - _pinball_loss: 2.0001 - val_loss: 2.5376 - val_mean_absolute_error: 7.6322 - val_mean_squared_error: 273.6952 - val__pinball_loss: 2.5376\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9814 - mean_absolute_error: 5.8831 - mean_squared_error: 179.5542 - _pinball_loss: 1.9814 - val_loss: 2.5478 - val_mean_absolute_error: 7.4472 - val_mean_squared_error: 259.6769 - val__pinball_loss: 2.5478\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9655 - mean_absolute_error: 5.8487 - mean_squared_error: 179.2287 - _pinball_loss: 1.9655 - val_loss: 2.5285 - val_mean_absolute_error: 7.4840 - val_mean_squared_error: 265.3527 - val__pinball_loss: 2.5285\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9551 - mean_absolute_error: 5.8271 - mean_squared_error: 178.8270 - _pinball_loss: 1.9551 - val_loss: 2.5132 - val_mean_absolute_error: 7.6473 - val_mean_squared_error: 275.4578 - val__pinball_loss: 2.5132\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9408 - mean_absolute_error: 5.8027 - mean_squared_error: 179.2223 - _pinball_loss: 1.9408 - val_loss: 2.5234 - val_mean_absolute_error: 7.4448 - val_mean_squared_error: 260.2183 - val__pinball_loss: 2.5234\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9304 - mean_absolute_error: 5.7718 - mean_squared_error: 178.1175 - _pinball_loss: 1.9304 - val_loss: 2.4921 - val_mean_absolute_error: 7.3762 - val_mean_squared_error: 260.7480 - val__pinball_loss: 2.4921\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9219 - mean_absolute_error: 5.7577 - mean_squared_error: 178.1635 - _pinball_loss: 1.9219 - val_loss: 2.4671 - val_mean_absolute_error: 7.5066 - val_mean_squared_error: 272.8663 - val__pinball_loss: 2.4671\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9133 - mean_absolute_error: 5.7389 - mean_squared_error: 178.0561 - _pinball_loss: 1.9133 - val_loss: 2.5060 - val_mean_absolute_error: 7.5570 - val_mean_squared_error: 269.7611 - val__pinball_loss: 2.5060\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9057 - mean_absolute_error: 5.7187 - mean_squared_error: 177.4071 - _pinball_loss: 1.9057 - val_loss: 2.4634 - val_mean_absolute_error: 7.3710 - val_mean_squared_error: 264.8250 - val__pinball_loss: 2.4634\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.9057 - mean_absolute_error: 5.7232 - mean_squared_error: 177.8517 - _pinball_loss: 1.9057 - val_loss: 2.4912 - val_mean_absolute_error: 7.4314 - val_mean_squared_error: 264.8226 - val__pinball_loss: 2.4912\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.8964 - mean_absolute_error: 5.6981 - mean_squared_error: 176.9997 - _pinball_loss: 1.8964 - val_loss: 2.4945 - val_mean_absolute_error: 7.4648 - val_mean_squared_error: 264.6307 - val__pinball_loss: 2.4945\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.8906 - mean_absolute_error: 5.6853 - mean_squared_error: 177.0274 - _pinball_loss: 1.8906 - val_loss: 2.4748 - val_mean_absolute_error: 7.4264 - val_mean_squared_error: 267.4809 - val__pinball_loss: 2.4748\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.8845 - mean_absolute_error: 5.6681 - mean_squared_error: 176.3569 - _pinball_loss: 1.8845 - val_loss: 2.4955 - val_mean_absolute_error: 7.3459 - val_mean_squared_error: 258.9364 - val__pinball_loss: 2.4955\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.8818 - mean_absolute_error: 5.6625 - mean_squared_error: 176.3497 - _pinball_loss: 1.8818 - val_loss: 2.4791 - val_mean_absolute_error: 7.4351 - val_mean_squared_error: 263.7254 - val__pinball_loss: 2.4791\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CDDABE9F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.9790 - mean_absolute_error: 9.5085 - mean_squared_error: 301.1835 - _pinball_loss: 2.9790 - val_loss: 1.9857 - val_mean_absolute_error: 8.6620 - val_mean_squared_error: 315.0389 - val__pinball_loss: 1.9857\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.5329 - mean_absolute_error: 6.7139 - mean_squared_error: 210.7708 - _pinball_loss: 1.5329 - val_loss: 1.9111 - val_mean_absolute_error: 8.4306 - val_mean_squared_error: 312.6372 - val__pinball_loss: 1.9111\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.4817 - mean_absolute_error: 6.5571 - mean_squared_error: 208.3929 - _pinball_loss: 1.4817 - val_loss: 1.8642 - val_mean_absolute_error: 7.8489 - val_mean_squared_error: 280.9389 - val__pinball_loss: 1.8642\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.4581 - mean_absolute_error: 6.4805 - mean_squared_error: 207.1465 - _pinball_loss: 1.4581 - val_loss: 1.8404 - val_mean_absolute_error: 8.1955 - val_mean_squared_error: 302.5157 - val__pinball_loss: 1.8404\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.4346 - mean_absolute_error: 6.4077 - mean_squared_error: 206.0333 - _pinball_loss: 1.4346 - val_loss: 1.8255 - val_mean_absolute_error: 8.0527 - val_mean_squared_error: 301.6937 - val__pinball_loss: 1.8255\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.4203 - mean_absolute_error: 6.3722 - mean_squared_error: 206.3018 - _pinball_loss: 1.4203 - val_loss: 1.8423 - val_mean_absolute_error: 8.1802 - val_mean_squared_error: 307.8791 - val__pinball_loss: 1.8423\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.4122 - mean_absolute_error: 6.3487 - mean_squared_error: 205.9792 - _pinball_loss: 1.4122 - val_loss: 1.8050 - val_mean_absolute_error: 7.8915 - val_mean_squared_error: 293.9051 - val__pinball_loss: 1.8050\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.4019 - mean_absolute_error: 6.3158 - mean_squared_error: 205.4460 - _pinball_loss: 1.4019 - val_loss: 1.8040 - val_mean_absolute_error: 7.8848 - val_mean_squared_error: 292.8141 - val__pinball_loss: 1.8040\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3970 - mean_absolute_error: 6.3011 - mean_squared_error: 205.5417 - _pinball_loss: 1.3970 - val_loss: 1.7949 - val_mean_absolute_error: 7.6921 - val_mean_squared_error: 283.9721 - val__pinball_loss: 1.7949\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3823 - mean_absolute_error: 6.2455 - mean_squared_error: 204.4052 - _pinball_loss: 1.3823 - val_loss: 1.8080 - val_mean_absolute_error: 8.2777 - val_mean_squared_error: 312.5715 - val__pinball_loss: 1.8080\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3758 - mean_absolute_error: 6.2292 - mean_squared_error: 204.3489 - _pinball_loss: 1.3758 - val_loss: 1.7704 - val_mean_absolute_error: 7.8914 - val_mean_squared_error: 293.9791 - val__pinball_loss: 1.7704\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3687 - mean_absolute_error: 6.2059 - mean_squared_error: 203.8620 - _pinball_loss: 1.3687 - val_loss: 1.7751 - val_mean_absolute_error: 7.7933 - val_mean_squared_error: 290.2381 - val__pinball_loss: 1.7751\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3669 - mean_absolute_error: 6.1989 - mean_squared_error: 203.7171 - _pinball_loss: 1.3669 - val_loss: 1.7554 - val_mean_absolute_error: 7.8871 - val_mean_squared_error: 294.7812 - val__pinball_loss: 1.7554\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3620 - mean_absolute_error: 6.1801 - mean_squared_error: 203.2754 - _pinball_loss: 1.3620 - val_loss: 1.7605 - val_mean_absolute_error: 7.7255 - val_mean_squared_error: 288.3122 - val__pinball_loss: 1.7605\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3564 - mean_absolute_error: 6.1593 - mean_squared_error: 203.0232 - _pinball_loss: 1.3564 - val_loss: 1.7646 - val_mean_absolute_error: 7.8330 - val_mean_squared_error: 292.2398 - val__pinball_loss: 1.7646\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3541 - mean_absolute_error: 6.1576 - mean_squared_error: 203.3154 - _pinball_loss: 1.3541 - val_loss: 1.7438 - val_mean_absolute_error: 7.7685 - val_mean_squared_error: 292.7120 - val__pinball_loss: 1.7438\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3442 - mean_absolute_error: 6.1184 - mean_squared_error: 202.3536 - _pinball_loss: 1.3442 - val_loss: 1.7614 - val_mean_absolute_error: 7.8140 - val_mean_squared_error: 291.5929 - val__pinball_loss: 1.7614\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3421 - mean_absolute_error: 6.1131 - mean_squared_error: 202.2620 - _pinball_loss: 1.3421 - val_loss: 1.7580 - val_mean_absolute_error: 7.8586 - val_mean_squared_error: 296.0527 - val__pinball_loss: 1.7580\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3376 - mean_absolute_error: 6.1002 - mean_squared_error: 202.0856 - _pinball_loss: 1.3376 - val_loss: 1.7666 - val_mean_absolute_error: 7.6595 - val_mean_squared_error: 287.3293 - val__pinball_loss: 1.7666\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3398 - mean_absolute_error: 6.1024 - mean_squared_error: 201.9058 - _pinball_loss: 1.3398 - val_loss: 1.7512 - val_mean_absolute_error: 7.9397 - val_mean_squared_error: 297.7883 - val__pinball_loss: 1.7512\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3333 - mean_absolute_error: 6.0840 - mean_squared_error: 201.3222 - _pinball_loss: 1.3333 - val_loss: 1.7423 - val_mean_absolute_error: 7.9522 - val_mean_squared_error: 301.8570 - val__pinball_loss: 1.7423\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3285 - mean_absolute_error: 6.0643 - mean_squared_error: 201.0080 - _pinball_loss: 1.3285 - val_loss: 1.7416 - val_mean_absolute_error: 7.8207 - val_mean_squared_error: 295.6658 - val__pinball_loss: 1.7416\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3252 - mean_absolute_error: 6.0481 - mean_squared_error: 200.5663 - _pinball_loss: 1.3252 - val_loss: 1.7390 - val_mean_absolute_error: 7.8449 - val_mean_squared_error: 298.5801 - val__pinball_loss: 1.7390\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3247 - mean_absolute_error: 6.0518 - mean_squared_error: 200.6709 - _pinball_loss: 1.3247 - val_loss: 1.7553 - val_mean_absolute_error: 7.7282 - val_mean_squared_error: 288.6918 - val__pinball_loss: 1.7553\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.3218 - mean_absolute_error: 6.0315 - mean_squared_error: 199.8844 - _pinball_loss: 1.3218 - val_loss: 1.7596 - val_mean_absolute_error: 7.8178 - val_mean_squared_error: 293.0010 - val__pinball_loss: 1.7596\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3208 - mean_absolute_error: 6.0316 - mean_squared_error: 199.6789 - _pinball_loss: 1.3208 - val_loss: 1.7649 - val_mean_absolute_error: 7.6316 - val_mean_squared_error: 281.1338 - val__pinball_loss: 1.7649\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3169 - mean_absolute_error: 6.0122 - mean_squared_error: 199.1469 - _pinball_loss: 1.3169 - val_loss: 1.7384 - val_mean_absolute_error: 7.5530 - val_mean_squared_error: 282.2962 - val__pinball_loss: 1.7384\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3126 - mean_absolute_error: 5.9977 - mean_squared_error: 198.7103 - _pinball_loss: 1.3126 - val_loss: 1.7417 - val_mean_absolute_error: 7.7246 - val_mean_squared_error: 292.5261 - val__pinball_loss: 1.7417\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3097 - mean_absolute_error: 5.9866 - mean_squared_error: 198.4444 - _pinball_loss: 1.3097 - val_loss: 1.7582 - val_mean_absolute_error: 7.9325 - val_mean_squared_error: 300.3784 - val__pinball_loss: 1.7582\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3083 - mean_absolute_error: 5.9796 - mean_squared_error: 198.0240 - _pinball_loss: 1.3083 - val_loss: 1.7378 - val_mean_absolute_error: 7.6935 - val_mean_squared_error: 288.5685 - val__pinball_loss: 1.7378\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3069 - mean_absolute_error: 5.9719 - mean_squared_error: 197.7309 - _pinball_loss: 1.3069 - val_loss: 1.7419 - val_mean_absolute_error: 7.8136 - val_mean_squared_error: 294.8633 - val__pinball_loss: 1.7419\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3025 - mean_absolute_error: 5.9560 - mean_squared_error: 197.2837 - _pinball_loss: 1.3025 - val_loss: 1.7420 - val_mean_absolute_error: 7.6859 - val_mean_squared_error: 291.1906 - val__pinball_loss: 1.7420\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 1.3018 - mean_absolute_error: 5.9508 - mean_squared_error: 196.9754 - _pinball_loss: 1.3018 - val_loss: 1.7390 - val_mean_absolute_error: 7.7221 - val_mean_squared_error: 292.5186 - val__pinball_loss: 1.7390\n",
      "Epoch 34/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.2981 - mean_absolute_error: 5.9391 - mean_squared_error: 196.6173 - _pinball_loss: 1.2981 - val_loss: 1.7586 - val_mean_absolute_error: 7.7572 - val_mean_squared_error: 292.8648 - val__pinball_loss: 1.7586\n",
      "Epoch 35/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 1.2995 - mean_absolute_error: 5.9425 - mean_squared_error: 196.8156 - _pinball_loss: 1.2995 - val_loss: 1.7392 - val_mean_absolute_error: 7.7670 - val_mean_squared_error: 293.7465 - val__pinball_loss: 1.7392\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CDDA247168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 2.3351 - mean_absolute_error: 12.0379 - mean_squared_error: 407.9558 - _pinball_loss: 2.3351 - val_loss: 1.1110 - val_mean_absolute_error: 9.6085 - val_mean_squared_error: 353.0593 - val__pinball_loss: 1.1110\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.8961 - mean_absolute_error: 7.9603 - mean_squared_error: 254.3779 - _pinball_loss: 0.8961 - val_loss: 1.0734 - val_mean_absolute_error: 9.8850 - val_mean_squared_error: 369.7262 - val__pinball_loss: 1.0734\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.8532 - mean_absolute_error: 7.6579 - mean_squared_error: 246.8814 - _pinball_loss: 0.8532 - val_loss: 1.0508 - val_mean_absolute_error: 9.5033 - val_mean_squared_error: 354.9137 - val__pinball_loss: 1.0508\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.8277 - mean_absolute_error: 7.4856 - mean_squared_error: 243.3003 - _pinball_loss: 0.8277 - val_loss: 1.0086 - val_mean_absolute_error: 9.2572 - val_mean_squared_error: 345.6582 - val__pinball_loss: 1.0086\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.8183 - mean_absolute_error: 7.4212 - mean_squared_error: 241.6727 - _pinball_loss: 0.8183 - val_loss: 1.0122 - val_mean_absolute_error: 8.9914 - val_mean_squared_error: 337.2622 - val__pinball_loss: 1.0122\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.8050 - mean_absolute_error: 7.3180 - mean_squared_error: 239.2119 - _pinball_loss: 0.8050 - val_loss: 1.0155 - val_mean_absolute_error: 9.3545 - val_mean_squared_error: 354.2917 - val__pinball_loss: 1.0155\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7947 - mean_absolute_error: 7.2495 - mean_squared_error: 238.3551 - _pinball_loss: 0.7947 - val_loss: 0.9930 - val_mean_absolute_error: 8.7614 - val_mean_squared_error: 326.2463 - val__pinball_loss: 0.9930\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7916 - mean_absolute_error: 7.2282 - mean_squared_error: 238.0644 - _pinball_loss: 0.7916 - val_loss: 0.9900 - val_mean_absolute_error: 9.1454 - val_mean_squared_error: 346.5686 - val__pinball_loss: 0.9900\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7826 - mean_absolute_error: 7.1606 - mean_squared_error: 236.9707 - _pinball_loss: 0.7826 - val_loss: 0.9678 - val_mean_absolute_error: 8.9698 - val_mean_squared_error: 338.2378 - val__pinball_loss: 0.9678\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7772 - mean_absolute_error: 7.1263 - mean_squared_error: 236.2049 - _pinball_loss: 0.7772 - val_loss: 0.9780 - val_mean_absolute_error: 9.0465 - val_mean_squared_error: 339.5926 - val__pinball_loss: 0.9780\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7697 - mean_absolute_error: 7.0689 - mean_squared_error: 234.6367 - _pinball_loss: 0.7697 - val_loss: 0.9790 - val_mean_absolute_error: 8.8080 - val_mean_squared_error: 334.5102 - val__pinball_loss: 0.9790\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7660 - mean_absolute_error: 7.0426 - mean_squared_error: 234.7984 - _pinball_loss: 0.7660 - val_loss: 0.9842 - val_mean_absolute_error: 8.9396 - val_mean_squared_error: 340.3042 - val__pinball_loss: 0.9842\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7579 - mean_absolute_error: 6.9857 - mean_squared_error: 233.5007 - _pinball_loss: 0.7579 - val_loss: 0.9674 - val_mean_absolute_error: 8.8564 - val_mean_squared_error: 338.6767 - val__pinball_loss: 0.9674\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7573 - mean_absolute_error: 6.9840 - mean_squared_error: 233.8164 - _pinball_loss: 0.7573 - val_loss: 0.9557 - val_mean_absolute_error: 8.7305 - val_mean_squared_error: 332.9134 - val__pinball_loss: 0.9557\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7515 - mean_absolute_error: 6.9400 - mean_squared_error: 232.9355 - _pinball_loss: 0.7515 - val_loss: 0.9563 - val_mean_absolute_error: 8.4725 - val_mean_squared_error: 322.9408 - val__pinball_loss: 0.9563\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7469 - mean_absolute_error: 6.9028 - mean_squared_error: 232.0845 - _pinball_loss: 0.7469 - val_loss: 0.9488 - val_mean_absolute_error: 8.4594 - val_mean_squared_error: 322.8417 - val__pinball_loss: 0.9488\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7427 - mean_absolute_error: 6.8700 - mean_squared_error: 231.5356 - _pinball_loss: 0.7427 - val_loss: 0.9604 - val_mean_absolute_error: 8.5180 - val_mean_squared_error: 321.3779 - val__pinball_loss: 0.9604\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7427 - mean_absolute_error: 6.8740 - mean_squared_error: 231.8863 - _pinball_loss: 0.7427 - val_loss: 0.9536 - val_mean_absolute_error: 8.9009 - val_mean_squared_error: 345.5746 - val__pinball_loss: 0.9536\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7387 - mean_absolute_error: 6.8453 - mean_squared_error: 231.2024 - _pinball_loss: 0.7387 - val_loss: 0.9472 - val_mean_absolute_error: 8.5738 - val_mean_squared_error: 329.9042 - val__pinball_loss: 0.9472\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7369 - mean_absolute_error: 6.8348 - mean_squared_error: 230.7872 - _pinball_loss: 0.7369 - val_loss: 0.9464 - val_mean_absolute_error: 8.7668 - val_mean_squared_error: 339.2756 - val__pinball_loss: 0.9464\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7358 - mean_absolute_error: 6.8316 - mean_squared_error: 231.2884 - _pinball_loss: 0.7358 - val_loss: 0.9369 - val_mean_absolute_error: 8.6799 - val_mean_squared_error: 333.2880 - val__pinball_loss: 0.9369\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7344 - mean_absolute_error: 6.8146 - mean_squared_error: 230.4988 - _pinball_loss: 0.7344 - val_loss: 0.9333 - val_mean_absolute_error: 8.4382 - val_mean_squared_error: 326.1280 - val__pinball_loss: 0.9333\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7318 - mean_absolute_error: 6.7982 - mean_squared_error: 230.4739 - _pinball_loss: 0.7318 - val_loss: 0.9360 - val_mean_absolute_error: 8.7432 - val_mean_squared_error: 339.5363 - val__pinball_loss: 0.9360\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7296 - mean_absolute_error: 6.7793 - mean_squared_error: 230.0166 - _pinball_loss: 0.7296 - val_loss: 0.9439 - val_mean_absolute_error: 8.4283 - val_mean_squared_error: 320.3847 - val__pinball_loss: 0.9439\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7286 - mean_absolute_error: 6.7706 - mean_squared_error: 229.8407 - _pinball_loss: 0.7286 - val_loss: 0.9329 - val_mean_absolute_error: 8.4653 - val_mean_squared_error: 323.9822 - val__pinball_loss: 0.9329\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.7268 - mean_absolute_error: 6.7540 - mean_squared_error: 229.2933 - _pinball_loss: 0.7268 - val_loss: 0.9406 - val_mean_absolute_error: 8.5843 - val_mean_squared_error: 328.8391 - val__pinball_loss: 0.9406\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7259 - mean_absolute_error: 6.7511 - mean_squared_error: 229.3259 - _pinball_loss: 0.7259 - val_loss: 0.9342 - val_mean_absolute_error: 8.4985 - val_mean_squared_error: 329.3830 - val__pinball_loss: 0.9342\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7242 - mean_absolute_error: 6.7363 - mean_squared_error: 229.0856 - _pinball_loss: 0.7242 - val_loss: 0.9301 - val_mean_absolute_error: 8.5645 - val_mean_squared_error: 331.4416 - val__pinball_loss: 0.9301\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7226 - mean_absolute_error: 6.7256 - mean_squared_error: 228.8651 - _pinball_loss: 0.7226 - val_loss: 0.9210 - val_mean_absolute_error: 8.4609 - val_mean_squared_error: 329.2483 - val__pinball_loss: 0.9210\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7228 - mean_absolute_error: 6.7301 - mean_squared_error: 228.8266 - _pinball_loss: 0.7228 - val_loss: 0.9360 - val_mean_absolute_error: 8.2147 - val_mean_squared_error: 316.1570 - val__pinball_loss: 0.9360\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7216 - mean_absolute_error: 6.7156 - mean_squared_error: 228.3921 - _pinball_loss: 0.7216 - val_loss: 0.9291 - val_mean_absolute_error: 8.3665 - val_mean_squared_error: 323.0316 - val__pinball_loss: 0.9291\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7175 - mean_absolute_error: 6.6879 - mean_squared_error: 227.8019 - _pinball_loss: 0.7175 - val_loss: 0.9211 - val_mean_absolute_error: 8.3912 - val_mean_squared_error: 324.6702 - val__pinball_loss: 0.9211\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7177 - mean_absolute_error: 6.6873 - mean_squared_error: 227.9141 - _pinball_loss: 0.7177 - val_loss: 0.9314 - val_mean_absolute_error: 8.6006 - val_mean_squared_error: 332.0376 - val__pinball_loss: 0.9314\n",
      "Epoch 34/1000\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.7154 - mean_absolute_error: 6.6748 - mean_squared_error: 227.6223 - _pinball_loss: 0.7154 - val_loss: 0.9223 - val_mean_absolute_error: 8.5851 - val_mean_squared_error: 333.8893 - val__pinball_loss: 0.9223\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CBAA8F9CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from src.model.multiple_output.convolution import Convolution1D\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    conv1 = Convolution1D(ONE_DAY_STEPS, OUTPUT_STEPS, 17)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv1, one_days_window_label_columns, q)\n",
    "    conv1.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 17)\n",
    "    pred_y = conv1.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "to_submission_csv(submission_df, \"conv1d_all_feature_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"data/submission/conv1d_all_feature_target.csv_2020-12-30 12_03_55.958013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.526921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.746142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.086555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.272306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.108723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  q_0.1  q_0.2  q_0.3  q_0.4  q_0.5  q_0.6  q_0.7  \\\n",
       "0       0.csv_Day7_0h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.csv_Day7_0h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.csv_Day7_1h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.csv_Day7_1h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.csv_Day7_2h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...                  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7771  80.csv_Day8_21h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7772  80.csv_Day8_22h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7773  80.csv_Day8_22h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7774  80.csv_Day8_23h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7775  80.csv_Day8_23h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      q_0.8     q_0.9  \n",
       "0       0.0  0.000000  \n",
       "1       0.0  0.000000  \n",
       "2       0.0  0.000000  \n",
       "3       0.0  0.000000  \n",
       "4       0.0  0.000000  \n",
       "...     ...       ...  \n",
       "7771    0.0  2.526921  \n",
       "7772    0.0  2.746142  \n",
       "7773    0.0  2.086555  \n",
       "7774    0.0  2.272306  \n",
       "7775    0.0  1.108723  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df_1 = pd.read_csv('raw_target_predict_using_solar_values.csv')\n",
    "submission_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.825519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>1.126346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147563</td>\n",
       "      <td>1.861683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     q_0.1  q_0.2     q_0.3     q_0.4  q_0.5  q_0.6  \\\n",
       "0       0.csv_Day7_0h00m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "1       0.csv_Day7_0h30m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "2       0.csv_Day7_1h00m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "3       0.csv_Day7_1h30m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "4       0.csv_Day7_2h00m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "...                  ...       ...    ...       ...       ...    ...    ...   \n",
       "7771  80.csv_Day8_21h30m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "7772  80.csv_Day8_22h00m  0.000000    0.0  0.000000  0.000000    0.0    0.0   \n",
       "7773  80.csv_Day8_22h30m  0.000000    0.0  0.000000  1.825519    0.0    0.0   \n",
       "7774  80.csv_Day8_23h00m  0.000000    0.0  0.000000  1.325230    0.0    0.0   \n",
       "7775  80.csv_Day8_23h30m  1.126346    0.0  1.147563  1.861683    0.0    0.0   \n",
       "\n",
       "      q_0.7  q_0.8  q_0.9  \n",
       "0       0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0  \n",
       "...     ...    ...    ...  \n",
       "7771    0.0    0.0    0.0  \n",
       "7772    0.0    0.0    0.0  \n",
       "7773    0.0    0.0    0.0  \n",
       "7774    0.0    0.0    0.0  \n",
       "7775    0.0    0.0    0.0  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 1] = 0\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0996207571759258"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(submission_df_1[\"q_0.1\"] - submission_df[\"q_0.1\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.470885324095422"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    s += (submission_df[f\"q_{q}\"] - submission_df_1[f\"q_{q}\"]).mean() * q\n",
    "\n",
    "s/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"raw_target_predict_using_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9281770e-01,  4.9281770e-01,  4.9281770e-01,  4.9281770e-01,\n",
       "         4.9281770e-01,  4.9281770e-01,  4.9281770e-01],\n",
       "       [ 7.6189011e-02,  7.6189011e-02,  7.6189011e-02,  7.6189011e-02,\n",
       "         7.6189011e-02,  7.6189011e-02,  7.6189011e-02],\n",
       "       [-5.2533066e-01, -5.2533066e-01, -5.2533066e-01, -5.2533066e-01,\n",
       "        -5.2533066e-01, -5.2533066e-01, -5.2533066e-01],\n",
       "       [-8.5956240e-01, -8.5956240e-01, -8.5956240e-01, -8.5956240e-01,\n",
       "        -8.5956240e-01, -8.5956240e-01, -8.5956240e-01],\n",
       "       [-7.0838153e-02, -7.0838153e-02, -7.0838153e-02, -7.0838153e-02,\n",
       "        -7.0838153e-02, -7.0838153e-02, -7.0838153e-02],\n",
       "       [-4.2691615e-01, -4.2691615e-01, -4.2691615e-01, -4.2691615e-01,\n",
       "        -4.2691615e-01, -4.2691615e-01, -4.2691615e-01],\n",
       "       [-7.6162839e-01, -7.6162839e-01, -7.6162839e-01, -7.6162839e-01,\n",
       "        -7.6162839e-01, -7.6162839e-01, -7.6162839e-01],\n",
       "       [-6.0606575e-01, -6.0606575e-01, -6.0606575e-01, -6.0606575e-01,\n",
       "        -6.0606575e-01, -6.0606575e-01, -6.0606575e-01],\n",
       "       [ 2.8140405e-01,  2.8140405e-01,  2.8140405e-01,  2.8140405e-01,\n",
       "         2.8140405e-01,  2.8140405e-01,  2.8140405e-01],\n",
       "       [ 2.5969309e-01,  2.5969309e-01,  2.5969309e-01,  2.5969309e-01,\n",
       "         2.5969309e-01,  2.5969309e-01,  2.5969309e-01],\n",
       "       [ 3.8228810e-02,  3.8228810e-02,  3.8228810e-02,  3.8228810e-02,\n",
       "         3.8228810e-02,  3.8228810e-02,  3.8228810e-02],\n",
       "       [ 5.4171640e-01,  5.4171640e-01,  5.4171640e-01,  5.4171640e-01,\n",
       "         5.4171640e-01,  5.4171640e-01,  5.4171640e-01],\n",
       "       [ 1.2614195e+00,  1.2614195e+00,  1.2614195e+00,  1.2614195e+00,\n",
       "         1.2614195e+00,  1.2614195e+00,  1.2614195e+00],\n",
       "       [ 2.6131525e+00,  2.6131525e+00,  2.6131525e+00,  2.6131525e+00,\n",
       "         2.6131525e+00,  2.6131525e+00,  2.6131525e+00],\n",
       "       [ 4.9087162e+00,  4.9087162e+00,  4.9087162e+00,  4.9087162e+00,\n",
       "         4.9087162e+00,  4.9087162e+00,  4.9087162e+00],\n",
       "       [ 7.4180384e+00,  7.4180384e+00,  7.4180384e+00,  7.4180384e+00,\n",
       "         7.4180384e+00,  7.4180384e+00,  7.4180384e+00],\n",
       "       [ 1.2278154e+01,  1.2278154e+01,  1.2278154e+01,  1.2278154e+01,\n",
       "         1.2278154e+01,  1.2278154e+01,  1.2278154e+01],\n",
       "       [ 1.8623621e+01,  1.8623621e+01,  1.8623621e+01,  1.8623621e+01,\n",
       "         1.8623621e+01,  1.8623621e+01,  1.8623621e+01],\n",
       "       [ 2.5590744e+01,  2.5590744e+01,  2.5590744e+01,  2.5590744e+01,\n",
       "         2.5590744e+01,  2.5590744e+01,  2.5590744e+01],\n",
       "       [ 3.2531567e+01,  3.2531567e+01,  3.2531567e+01,  3.2531567e+01,\n",
       "         3.2531567e+01,  3.2531567e+01,  3.2531567e+01],\n",
       "       [ 3.9965771e+01,  3.9965771e+01,  3.9965771e+01,  3.9965771e+01,\n",
       "         3.9965771e+01,  3.9965771e+01,  3.9965771e+01],\n",
       "       [ 4.5424225e+01,  4.5424225e+01,  4.5424225e+01,  4.5424225e+01,\n",
       "         4.5424225e+01,  4.5424225e+01,  4.5424225e+01],\n",
       "       [ 4.9282612e+01,  4.9282612e+01,  4.9282612e+01,  4.9282612e+01,\n",
       "         4.9282612e+01,  4.9282612e+01,  4.9282612e+01],\n",
       "       [ 5.2939121e+01,  5.2939121e+01,  5.2939121e+01,  5.2939121e+01,\n",
       "         5.2939121e+01,  5.2939121e+01,  5.2939121e+01],\n",
       "       [ 5.4889248e+01,  5.4889248e+01,  5.4889248e+01,  5.4889248e+01,\n",
       "         5.4889248e+01,  5.4889248e+01,  5.4889248e+01],\n",
       "       [ 5.5160473e+01,  5.5160473e+01,  5.5160473e+01,  5.5160473e+01,\n",
       "         5.5160473e+01,  5.5160473e+01,  5.5160473e+01],\n",
       "       [ 5.2208942e+01,  5.2208942e+01,  5.2208942e+01,  5.2208942e+01,\n",
       "         5.2208942e+01,  5.2208942e+01,  5.2208942e+01],\n",
       "       [ 4.9798412e+01,  4.9798412e+01,  4.9798412e+01,  4.9798412e+01,\n",
       "         4.9798412e+01,  4.9798412e+01,  4.9798412e+01],\n",
       "       [ 4.6183434e+01,  4.6183434e+01,  4.6183434e+01,  4.6183434e+01,\n",
       "         4.6183434e+01,  4.6183434e+01,  4.6183434e+01],\n",
       "       [ 4.3362156e+01,  4.3362156e+01,  4.3362156e+01,  4.3362156e+01,\n",
       "         4.3362156e+01,  4.3362156e+01,  4.3362156e+01],\n",
       "       [ 3.6816452e+01,  3.6816452e+01,  3.6816452e+01,  3.6816452e+01,\n",
       "         3.6816452e+01,  3.6816452e+01,  3.6816452e+01],\n",
       "       [ 2.9486492e+01,  2.9486492e+01,  2.9486492e+01,  2.9486492e+01,\n",
       "         2.9486492e+01,  2.9486492e+01,  2.9486492e+01],\n",
       "       [ 2.3033268e+01,  2.3033268e+01,  2.3033268e+01,  2.3033268e+01,\n",
       "         2.3033268e+01,  2.3033268e+01,  2.3033268e+01],\n",
       "       [ 1.8039446e+01,  1.8039446e+01,  1.8039446e+01,  1.8039446e+01,\n",
       "         1.8039446e+01,  1.8039446e+01,  1.8039446e+01],\n",
       "       [ 1.2428722e+01,  1.2428722e+01,  1.2428722e+01,  1.2428722e+01,\n",
       "         1.2428722e+01,  1.2428722e+01,  1.2428722e+01],\n",
       "       [ 9.4800768e+00,  9.4800768e+00,  9.4800768e+00,  9.4800768e+00,\n",
       "         9.4800768e+00,  9.4800768e+00,  9.4800768e+00],\n",
       "       [ 5.9829731e+00,  5.9829731e+00,  5.9829731e+00,  5.9829731e+00,\n",
       "         5.9829731e+00,  5.9829731e+00,  5.9829731e+00],\n",
       "       [ 3.2627540e+00,  3.2627540e+00,  3.2627540e+00,  3.2627540e+00,\n",
       "         3.2627540e+00,  3.2627540e+00,  3.2627540e+00],\n",
       "       [ 2.3578553e+00,  2.3578553e+00,  2.3578553e+00,  2.3578553e+00,\n",
       "         2.3578553e+00,  2.3578553e+00,  2.3578553e+00],\n",
       "       [ 1.5449107e+00,  1.5449107e+00,  1.5449107e+00,  1.5449107e+00,\n",
       "         1.5449107e+00,  1.5449107e+00,  1.5449107e+00],\n",
       "       [ 7.7471209e-01,  7.7471209e-01,  7.7471209e-01,  7.7471209e-01,\n",
       "         7.7471209e-01,  7.7471209e-01,  7.7471209e-01],\n",
       "       [ 3.8064587e-01,  3.8064587e-01,  3.8064587e-01,  3.8064587e-01,\n",
       "         3.8064587e-01,  3.8064587e-01,  3.8064587e-01],\n",
       "       [ 1.2212619e+00,  1.2212619e+00,  1.2212619e+00,  1.2212619e+00,\n",
       "         1.2212619e+00,  1.2212619e+00,  1.2212619e+00],\n",
       "       [ 1.7939050e+00,  1.7939050e+00,  1.7939050e+00,  1.7939050e+00,\n",
       "         1.7939050e+00,  1.7939050e+00,  1.7939050e+00],\n",
       "       [ 1.3495703e+00,  1.3495703e+00,  1.3495703e+00,  1.3495703e+00,\n",
       "         1.3495703e+00,  1.3495703e+00,  1.3495703e+00],\n",
       "       [ 3.3438960e-01,  3.3438960e-01,  3.3438960e-01,  3.3438960e-01,\n",
       "         3.3438960e-01,  3.3438960e-01,  3.3438960e-01],\n",
       "       [ 6.0848355e-01,  6.0848355e-01,  6.0848355e-01,  6.0848355e-01,\n",
       "         6.0848355e-01,  6.0848355e-01,  6.0848355e-01],\n",
       "       [ 8.2565796e-01,  8.2565796e-01,  8.2565796e-01,  8.2565796e-01,\n",
       "         8.2565796e-01,  8.2565796e-01,  8.2565796e-01],\n",
       "       [ 4.7622725e-01,  4.7622725e-01,  4.7622725e-01,  4.7622725e-01,\n",
       "         4.7622725e-01,  4.7622725e-01,  4.7622725e-01],\n",
       "       [ 2.8254497e-01,  2.8254497e-01,  2.8254497e-01,  2.8254497e-01,\n",
       "         2.8254497e-01,  2.8254497e-01,  2.8254497e-01],\n",
       "       [ 4.3543971e-01,  4.3543971e-01,  4.3543971e-01,  4.3543971e-01,\n",
       "         4.3543971e-01,  4.3543971e-01,  4.3543971e-01],\n",
       "       [-8.1986070e-01, -8.1986070e-01, -8.1986070e-01, -8.1986070e-01,\n",
       "        -8.1986070e-01, -8.1986070e-01, -8.1986070e-01],\n",
       "       [-7.0480704e-01, -7.0480704e-01, -7.0480704e-01, -7.0480704e-01,\n",
       "        -7.0480704e-01, -7.0480704e-01, -7.0480704e-01],\n",
       "       [-1.3284183e-01, -1.3284183e-01, -1.3284183e-01, -1.3284183e-01,\n",
       "        -1.3284183e-01, -1.3284183e-01, -1.3284183e-01],\n",
       "       [ 4.3159378e-01,  4.3159378e-01,  4.3159378e-01,  4.3159378e-01,\n",
       "         4.3159378e-01,  4.3159378e-01,  4.3159378e-01],\n",
       "       [ 6.3425529e-01,  6.3425529e-01,  6.3425529e-01,  6.3425529e-01,\n",
       "         6.3425529e-01,  6.3425529e-01,  6.3425529e-01],\n",
       "       [ 2.3257357e-01,  2.3257357e-01,  2.3257357e-01,  2.3257357e-01,\n",
       "         2.3257357e-01,  2.3257357e-01,  2.3257357e-01],\n",
       "       [ 1.9705933e-01,  1.9705933e-01,  1.9705933e-01,  1.9705933e-01,\n",
       "         1.9705933e-01,  1.9705933e-01,  1.9705933e-01],\n",
       "       [ 3.8276541e-01,  3.8276541e-01,  3.8276541e-01,  3.8276541e-01,\n",
       "         3.8276541e-01,  3.8276541e-01,  3.8276541e-01],\n",
       "       [-2.2800273e-01, -2.2800273e-01, -2.2800273e-01, -2.2800273e-01,\n",
       "        -2.2800273e-01, -2.2800273e-01, -2.2800273e-01],\n",
       "       [ 1.4117640e+00,  1.4117640e+00,  1.4117640e+00,  1.4117640e+00,\n",
       "         1.4117640e+00,  1.4117640e+00,  1.4117640e+00],\n",
       "       [ 2.0871119e+00,  2.0871119e+00,  2.0871119e+00,  2.0871119e+00,\n",
       "         2.0871119e+00,  2.0871119e+00,  2.0871119e+00],\n",
       "       [ 4.1166306e+00,  4.1166306e+00,  4.1166306e+00,  4.1166306e+00,\n",
       "         4.1166306e+00,  4.1166306e+00,  4.1166306e+00],\n",
       "       [ 7.6698995e+00,  7.6698995e+00,  7.6698995e+00,  7.6698995e+00,\n",
       "         7.6698995e+00,  7.6698995e+00,  7.6698995e+00],\n",
       "       [ 1.2455369e+01,  1.2455369e+01,  1.2455369e+01,  1.2455369e+01,\n",
       "         1.2455369e+01,  1.2455369e+01,  1.2455369e+01],\n",
       "       [ 1.8628593e+01,  1.8628593e+01,  1.8628593e+01,  1.8628593e+01,\n",
       "         1.8628593e+01,  1.8628593e+01,  1.8628593e+01],\n",
       "       [ 2.4502068e+01,  2.4502068e+01,  2.4502068e+01,  2.4502068e+01,\n",
       "         2.4502068e+01,  2.4502068e+01,  2.4502068e+01],\n",
       "       [ 3.1712379e+01,  3.1712379e+01,  3.1712379e+01,  3.1712379e+01,\n",
       "         3.1712379e+01,  3.1712379e+01,  3.1712379e+01],\n",
       "       [ 4.0238007e+01,  4.0238007e+01,  4.0238007e+01,  4.0238007e+01,\n",
       "         4.0238007e+01,  4.0238007e+01,  4.0238007e+01],\n",
       "       [ 4.5509941e+01,  4.5509941e+01,  4.5509941e+01,  4.5509941e+01,\n",
       "         4.5509941e+01,  4.5509941e+01,  4.5509941e+01],\n",
       "       [ 4.8219704e+01,  4.8219704e+01,  4.8219704e+01,  4.8219704e+01,\n",
       "         4.8219704e+01,  4.8219704e+01,  4.8219704e+01],\n",
       "       [ 5.1585175e+01,  5.1585175e+01,  5.1585175e+01,  5.1585175e+01,\n",
       "         5.1585175e+01,  5.1585175e+01,  5.1585175e+01],\n",
       "       [ 5.4929470e+01,  5.4929470e+01,  5.4929470e+01,  5.4929470e+01,\n",
       "         5.4929470e+01,  5.4929470e+01,  5.4929470e+01],\n",
       "       [ 5.5253567e+01,  5.5253567e+01,  5.5253567e+01,  5.5253567e+01,\n",
       "         5.5253567e+01,  5.5253567e+01,  5.5253567e+01],\n",
       "       [ 5.3083363e+01,  5.3083363e+01,  5.3083363e+01,  5.3083363e+01,\n",
       "         5.3083363e+01,  5.3083363e+01,  5.3083363e+01],\n",
       "       [ 4.9365734e+01,  4.9365734e+01,  4.9365734e+01,  4.9365734e+01,\n",
       "         4.9365734e+01,  4.9365734e+01,  4.9365734e+01],\n",
       "       [ 4.7016117e+01,  4.7016117e+01,  4.7016117e+01,  4.7016117e+01,\n",
       "         4.7016117e+01,  4.7016117e+01,  4.7016117e+01],\n",
       "       [ 4.2744957e+01,  4.2744957e+01,  4.2744957e+01,  4.2744957e+01,\n",
       "         4.2744957e+01,  4.2744957e+01,  4.2744957e+01],\n",
       "       [ 3.6563442e+01,  3.6563442e+01,  3.6563442e+01,  3.6563442e+01,\n",
       "         3.6563442e+01,  3.6563442e+01,  3.6563442e+01],\n",
       "       [ 2.9605099e+01,  2.9605099e+01,  2.9605099e+01,  2.9605099e+01,\n",
       "         2.9605099e+01,  2.9605099e+01,  2.9605099e+01],\n",
       "       [ 2.4072500e+01,  2.4072500e+01,  2.4072500e+01,  2.4072500e+01,\n",
       "         2.4072500e+01,  2.4072500e+01,  2.4072500e+01],\n",
       "       [ 1.7287071e+01,  1.7287071e+01,  1.7287071e+01,  1.7287071e+01,\n",
       "         1.7287071e+01,  1.7287071e+01,  1.7287071e+01],\n",
       "       [ 1.2125258e+01,  1.2125258e+01,  1.2125258e+01,  1.2125258e+01,\n",
       "         1.2125258e+01,  1.2125258e+01,  1.2125258e+01],\n",
       "       [ 9.7718716e+00,  9.7718716e+00,  9.7718716e+00,  9.7718716e+00,\n",
       "         9.7718716e+00,  9.7718716e+00,  9.7718716e+00],\n",
       "       [ 6.5378466e+00,  6.5378466e+00,  6.5378466e+00,  6.5378466e+00,\n",
       "         6.5378466e+00,  6.5378466e+00,  6.5378466e+00],\n",
       "       [ 4.7629232e+00,  4.7629232e+00,  4.7629232e+00,  4.7629232e+00,\n",
       "         4.7629232e+00,  4.7629232e+00,  4.7629232e+00],\n",
       "       [ 2.2888527e+00,  2.2888527e+00,  2.2888527e+00,  2.2888527e+00,\n",
       "         2.2888527e+00,  2.2888527e+00,  2.2888527e+00],\n",
       "       [ 1.0746835e+00,  1.0746835e+00,  1.0746835e+00,  1.0746835e+00,\n",
       "         1.0746835e+00,  1.0746835e+00,  1.0746835e+00],\n",
       "       [ 1.3394253e+00,  1.3394253e+00,  1.3394253e+00,  1.3394253e+00,\n",
       "         1.3394253e+00,  1.3394253e+00,  1.3394253e+00],\n",
       "       [ 2.0272307e+00,  2.0272307e+00,  2.0272307e+00,  2.0272307e+00,\n",
       "         2.0272307e+00,  2.0272307e+00,  2.0272307e+00],\n",
       "       [ 8.3062887e-01,  8.3062887e-01,  8.3062887e-01,  8.3062887e-01,\n",
       "         8.3062887e-01,  8.3062887e-01,  8.3062887e-01],\n",
       "       [ 1.2925785e+00,  1.2925785e+00,  1.2925785e+00,  1.2925785e+00,\n",
       "         1.2925785e+00,  1.2925785e+00,  1.2925785e+00],\n",
       "       [ 8.1282496e-01,  8.1282496e-01,  8.1282496e-01,  8.1282496e-01,\n",
       "         8.1282496e-01,  8.1282496e-01,  8.1282496e-01],\n",
       "       [ 9.0512377e-01,  9.0512377e-01,  9.0512377e-01,  9.0512377e-01,\n",
       "         9.0512377e-01,  9.0512377e-01,  9.0512377e-01],\n",
       "       [ 9.0743154e-01,  9.0743154e-01,  9.0743154e-01,  9.0743154e-01,\n",
       "         9.0743154e-01,  9.0743154e-01,  9.0743154e-01],\n",
       "       [ 1.5365784e+00,  1.5365784e+00,  1.5365784e+00,  1.5365784e+00,\n",
       "         1.5365784e+00,  1.5365784e+00,  1.5365784e+00]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.predict(predict_np)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n",
      "0.1\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4926 - mean_absolute_error: 13.0646 - mean_squared_error: 527.6806 - _pinball_loss: 1.4926 - val_loss: 1.7958 - val_mean_absolute_error: 15.5729 - val_mean_squared_error: 670.6212 - val__pinball_loss: 1.7958\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4189 - mean_absolute_error: 12.0127 - mean_squared_error: 453.3780 - _pinball_loss: 1.4189 - val_loss: 1.7774 - val_mean_absolute_error: 15.3909 - val_mean_squared_error: 663.2848 - val__pinball_loss: 1.7774\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4045 - mean_absolute_error: 11.8375 - mean_squared_error: 446.4313 - _pinball_loss: 1.4045 - val_loss: 1.7720 - val_mean_absolute_error: 15.2155 - val_mean_squared_error: 646.0442 - val__pinball_loss: 1.7720\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 6ms/step - loss: 1.3965 - mean_absolute_error: 11.7667 - mean_squared_error: 444.2633 - _pinball_loss: 1.3965 - val_loss: 1.7768 - val_mean_absolute_error: 15.0920 - val_mean_squared_error: 646.2262 - val__pinball_loss: 1.7768\n",
      "Epoch 5/1000\n",
      "1084/1146 [===========================>..] - ETA: 0s - loss: 1.3912 - mean_absolute_error: 11.6773 - mean_squared_error: 440.0760 - _pinball_loss: 1.3912"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8f30e0afcfe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mconv1d2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution1D2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_STEPS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mcompile_and_fit_with_pinball_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1d2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_days_window_label_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mconv1d2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_days_window_label_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mpredict_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\dacon\\235680\\src\\trainers.py\u001b[0m in \u001b[0;36mcompile_and_fit_with_pinball_loss\u001b[1;34m(model, window, tau, patience)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     history = model.fit(\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "from src.model.multiple_output.convolution import Convolution1D2\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv1d2 = Convolution1D2(48, OUTPUT_STEPS, 7)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv1d2, one_days_window_label_columns, q)\n",
    "    conv1d2.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 7)\n",
    "    pred_y = conv1d2.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "to_submission_csv(submission_df, \"conv1d2_not_scaled_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "from src.model.multiple_output.convolution import Convolution2D3\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS * 1,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * 1)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv2d3 = Convolution2D3(1, OUTPUT_STEPS, 17)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv2d3, one_days_window_label_columns, q)\n",
    "    conv2d3.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 17)\n",
    "    pred_y = conv2d3.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "to_submission_csv(submission_df, \"conv2d3_all_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.400381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>1.772600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>2.818873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>4.652788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>6.097359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>8.452878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>9.241078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>10.465257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>10.956903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>11.866484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>11.761783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>10.006454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>9.584481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>8.860756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>7.852172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>6.575282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>4.710351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>3.074631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>1.549875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.507971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>-0.273685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>-0.857344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>-1.109380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>-1.784322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>-1.297921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>-0.664760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>-0.386692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>-0.261884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>-0.019052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.270847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>-0.140175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>-0.010557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.csv_Day8_0h00m</td>\n",
       "      <td>0.061457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.csv_Day8_0h30m</td>\n",
       "      <td>-0.117943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1  q_0.2  q_0.3  q_0.4  q_0.5  q_0.6  q_0.7  \\\n",
       "15   0.csv_Day7_7h30m   0.400381    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "16   0.csv_Day7_8h00m   1.772600    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "17   0.csv_Day7_8h30m   2.818873    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "18   0.csv_Day7_9h00m   4.652788    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "19   0.csv_Day7_9h30m   6.097359    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "20  0.csv_Day7_10h00m   8.452878    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "21  0.csv_Day7_10h30m   9.241078    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "22  0.csv_Day7_11h00m  10.465257    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "23  0.csv_Day7_11h30m  10.956903    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24  0.csv_Day7_12h00m  11.866484    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "25  0.csv_Day7_12h30m  11.761783    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "26  0.csv_Day7_13h00m  10.006454    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "27  0.csv_Day7_13h30m   9.584481    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "28  0.csv_Day7_14h00m   8.860756    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "29  0.csv_Day7_14h30m   7.852172    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "30  0.csv_Day7_15h00m   6.575282    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "31  0.csv_Day7_15h30m   4.710351    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "32  0.csv_Day7_16h00m   3.074631    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "33  0.csv_Day7_16h30m   1.549875    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "34  0.csv_Day7_17h00m   0.507971    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "35  0.csv_Day7_17h30m  -0.273685    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "36  0.csv_Day7_18h00m  -0.857344    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "37  0.csv_Day7_18h30m  -1.109380    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "38  0.csv_Day7_19h00m  -1.784322    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "39  0.csv_Day7_19h30m  -1.297921    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "40  0.csv_Day7_20h00m  -0.664760    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "41  0.csv_Day7_20h30m  -0.386692    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "42  0.csv_Day7_21h00m  -0.261884    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "43  0.csv_Day7_21h30m  -0.019052    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "44  0.csv_Day7_22h00m   0.270847    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "45  0.csv_Day7_22h30m  -0.140175    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "46  0.csv_Day7_23h00m  -0.010557    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "47  0.csv_Day7_23h30m   0.072768    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "48   0.csv_Day8_0h00m   0.061457    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49   0.csv_Day8_0h30m  -0.117943    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "    q_0.8  q_0.9  \n",
       "15    0.0    0.0  \n",
       "16    0.0    0.0  \n",
       "17    0.0    0.0  \n",
       "18    0.0    0.0  \n",
       "19    0.0    0.0  \n",
       "20    0.0    0.0  \n",
       "21    0.0    0.0  \n",
       "22    0.0    0.0  \n",
       "23    0.0    0.0  \n",
       "24    0.0    0.0  \n",
       "25    0.0    0.0  \n",
       "26    0.0    0.0  \n",
       "27    0.0    0.0  \n",
       "28    0.0    0.0  \n",
       "29    0.0    0.0  \n",
       "30    0.0    0.0  \n",
       "31    0.0    0.0  \n",
       "32    0.0    0.0  \n",
       "33    0.0    0.0  \n",
       "34    0.0    0.0  \n",
       "35    0.0    0.0  \n",
       "36    0.0    0.0  \n",
       "37    0.0    0.0  \n",
       "38    0.0    0.0  \n",
       "39    0.0    0.0  \n",
       "40    0.0    0.0  \n",
       "41    0.0    0.0  \n",
       "42    0.0    0.0  \n",
       "43    0.0    0.0  \n",
       "44    0.0    0.0  \n",
       "45    0.0    0.0  \n",
       "46    0.0    0.0  \n",
       "47    0.0    0.0  \n",
       "48    0.0    0.0  \n",
       "49    0.0    0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[15:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_basic_preprocessed_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9f95802de175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_basic_preprocessed_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"scaled_TARGET\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TARGET\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcutter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TARGET\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_basic_preprocessed_predict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_df, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"ORIGIN_TARGET\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 0] = 0\n",
    "submission_df.to_csv(\"conv1_using_target_zero.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7600bc4d632e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_days_window_label_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'conv1' is not defined"
     ]
    }
   ],
   "source": [
    "one_days_window_label_columns.plot(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 6ms/step - loss: 0.1519 - mean_absolute_error: 0.3038 - mean_squared_error: 0.2822 - _pinball_loss: 0.1519 - val_loss: 0.1501 - val_mean_absolute_error: 0.3001 - val_mean_squared_error: 0.2983 - val__pinball_loss: 0.1501\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 6s 6ms/step - loss: 0.1164 - mean_absolute_error: 0.2327 - mean_squared_error: 0.2101 - _pinball_loss: 0.1164 - val_loss: 0.1439 - val_mean_absolute_error: 0.2878 - val_mean_squared_error: 0.2879 - val__pinball_loss: 0.1439\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 6s 6ms/step - loss: 0.1129 - mean_absolute_error: 0.2258 - mean_squared_error: 0.2065 - _pinball_loss: 0.1129 - val_loss: 0.1421 - val_mean_absolute_error: 0.2843 - val_mean_squared_error: 0.2962 - val__pinball_loss: 0.1421\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 6s 6ms/step - loss: 0.1108 - mean_absolute_error: 0.2217 - mean_squared_error: 0.2051 - _pinball_loss: 0.1108 - val_loss: 0.1428 - val_mean_absolute_error: 0.2857 - val_mean_squared_error: 0.2987 - val__pinball_loss: 0.1428\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 6s 6ms/step - loss: 0.1092 - mean_absolute_error: 0.2184 - mean_squared_error: 0.2032 - _pinball_loss: 0.1092 - val_loss: 0.1393 - val_mean_absolute_error: 0.2786 - val_mean_squared_error: 0.2994 - val__pinball_loss: 0.1393\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.1077 - mean_absolute_error: 0.2154 - mean_squared_error: 0.2021 - _pinball_loss: 0.1077 - val_loss: 0.1429 - val_mean_absolute_error: 0.2858 - val_mean_squared_error: 0.3008 - val__pinball_loss: 0.1429\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 6s 6ms/step - loss: 0.1072 - mean_absolute_error: 0.2143 - mean_squared_error: 0.2018 - _pinball_loss: 0.1072 - val_loss: 0.1428 - val_mean_absolute_error: 0.2856 - val_mean_squared_error: 0.3035 - val__pinball_loss: 0.1428\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.1061 - mean_absolute_error: 0.2123 - mean_squared_error: 0.2007 - _pinball_loss: 0.1061 - val_loss: 0.1420 - val_mean_absolute_error: 0.2840 - val_mean_squared_error: 0.3007 - val__pinball_loss: 0.1420\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.1051 - mean_absolute_error: 0.2103 - mean_squared_error: 0.1988 - _pinball_loss: 0.1051 - val_loss: 0.1405 - val_mean_absolute_error: 0.2811 - val_mean_squared_error: 0.2984 - val__pinball_loss: 0.1405\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.1048 - mean_absolute_error: 0.2097 - mean_squared_error: 0.1980 - _pinball_loss: 0.1048 - val_loss: 0.1416 - val_mean_absolute_error: 0.2832 - val_mean_squared_error: 0.3058 - val__pinball_loss: 0.1416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.model.multiple_output.convolution import Convolution2D3\n",
    "\n",
    "conv2D3 = Convolution2D3(1, OUTPUT_STEPS, len(train_df.columns))\n",
    "compile_and_fit_with_pinball_loss(conv2D3, one_days_window_label_columns, TAU)\n",
    "conv2D3.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "one_days_window_label_columns.plot(conv2D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07364267855882645,\n",
       " 0.1472853720188141,\n",
       " 0.11808878928422928,\n",
       " 0.07364268600940704]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2D3.evaluate(one_days_window_label_columns.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DHI', 'DNI', 'GHI', 'DHI_min_max_scaled', 'DNI_min_max_scaled',\n",
       "       'GHI_min_max_scaled', 'scaled_TARGET', 'TARGET'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n",
      "0.1\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 26s 13ms/step - loss: 1.6322 - mean_absolute_error: 15.5961 - mean_squared_error: 779.4335 - _pinball_loss: 1.6322 - val_loss: 1.8716 - val_mean_absolute_error: 16.7137 - val_mean_squared_error: 802.8913 - val__pinball_loss: 1.8716\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4710 - mean_absolute_error: 13.0737 - mean_squared_error: 561.8469 - _pinball_loss: 1.4710 - val_loss: 1.8243 - val_mean_absolute_error: 16.0334 - val_mean_squared_error: 736.4716 - val__pinball_loss: 1.8243\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4330 - mean_absolute_error: 12.4821 - mean_squared_error: 511.8997 - _pinball_loss: 1.4330 - val_loss: 1.7924 - val_mean_absolute_error: 15.4632 - val_mean_squared_error: 683.8065 - val__pinball_loss: 1.7924\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4060 - mean_absolute_error: 12.0677 - mean_squared_error: 477.4243 - _pinball_loss: 1.4060 - val_loss: 1.7716 - val_mean_absolute_error: 15.0503 - val_mean_squared_error: 649.4899 - val__pinball_loss: 1.7716\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3865 - mean_absolute_error: 11.7711 - mean_squared_error: 454.4911 - _pinball_loss: 1.3865 - val_loss: 1.7561 - val_mean_absolute_error: 14.6857 - val_mean_squared_error: 622.8954 - val__pinball_loss: 1.7561\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3743 - mean_absolute_error: 11.5935 - mean_squared_error: 441.8236 - _pinball_loss: 1.3743 - val_loss: 1.7498 - val_mean_absolute_error: 14.7597 - val_mean_squared_error: 623.3687 - val__pinball_loss: 1.7498\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3663 - mean_absolute_error: 11.4925 - mean_squared_error: 435.3612 - _pinball_loss: 1.3663 - val_loss: 1.7422 - val_mean_absolute_error: 14.6234 - val_mean_squared_error: 616.4623 - val__pinball_loss: 1.7422\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3607 - mean_absolute_error: 11.4270 - mean_squared_error: 431.8013 - _pinball_loss: 1.3607 - val_loss: 1.7371 - val_mean_absolute_error: 14.5373 - val_mean_squared_error: 611.2298 - val__pinball_loss: 1.7371\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3565 - mean_absolute_error: 11.3809 - mean_squared_error: 429.6113 - _pinball_loss: 1.3565 - val_loss: 1.7344 - val_mean_absolute_error: 14.4465 - val_mean_squared_error: 608.2216 - val__pinball_loss: 1.7344\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3525 - mean_absolute_error: 11.3273 - mean_squared_error: 426.8959 - _pinball_loss: 1.3525 - val_loss: 1.7358 - val_mean_absolute_error: 14.4008 - val_mean_squared_error: 607.1226 - val__pinball_loss: 1.7358\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.3498 - mean_absolute_error: 11.2958 - mean_squared_error: 425.5965 - _pinball_loss: 1.3498 - val_loss: 1.7326 - val_mean_absolute_error: 14.3433 - val_mean_squared_error: 600.7681 - val__pinball_loss: 1.7326\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3481 - mean_absolute_error: 11.2854 - mean_squared_error: 425.3100 - _pinball_loss: 1.3481 - val_loss: 1.7301 - val_mean_absolute_error: 14.3242 - val_mean_squared_error: 599.4118 - val__pinball_loss: 1.7301\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.3455 - mean_absolute_error: 11.2545 - mean_squared_error: 423.8948 - _pinball_loss: 1.3455 - val_loss: 1.7293 - val_mean_absolute_error: 14.3759 - val_mean_squared_error: 605.0574 - val__pinball_loss: 1.7293\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.3450 - mean_absolute_error: 11.2423 - mean_squared_error: 423.1972 - _pinball_loss: 1.3450 - val_loss: 1.7280 - val_mean_absolute_error: 14.3701 - val_mean_squared_error: 605.2431 - val__pinball_loss: 1.7280\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.3416 - mean_absolute_error: 11.2164 - mean_squared_error: 422.1063 - _pinball_loss: 1.3416 - val_loss: 1.7267 - val_mean_absolute_error: 14.2850 - val_mean_squared_error: 601.1357 - val__pinball_loss: 1.7267\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 1.3415 - mean_absolute_error: 11.2066 - mean_squared_error: 421.6673 - _pinball_loss: 1.3415 - val_loss: 1.7279 - val_mean_absolute_error: 14.3310 - val_mean_squared_error: 602.9988 - val__pinball_loss: 1.7279\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3391 - mean_absolute_error: 11.1762 - mean_squared_error: 420.2029 - _pinball_loss: 1.3391 - val_loss: 1.7260 - val_mean_absolute_error: 14.3495 - val_mean_squared_error: 605.4083 - val__pinball_loss: 1.7260\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3383 - mean_absolute_error: 11.1652 - mean_squared_error: 419.6616 - _pinball_loss: 1.3383 - val_loss: 1.7282 - val_mean_absolute_error: 14.4530 - val_mean_squared_error: 613.9224 - val__pinball_loss: 1.7282\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3362 - mean_absolute_error: 11.1537 - mean_squared_error: 419.1526 - _pinball_loss: 1.3362 - val_loss: 1.7281 - val_mean_absolute_error: 14.3766 - val_mean_squared_error: 605.6443 - val__pinball_loss: 1.7281\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3345 - mean_absolute_error: 11.1320 - mean_squared_error: 417.9842 - _pinball_loss: 1.3345 - val_loss: 1.7262 - val_mean_absolute_error: 14.2063 - val_mean_squared_error: 596.1050 - val__pinball_loss: 1.7262\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3342 - mean_absolute_error: 11.1163 - mean_squared_error: 417.2251 - _pinball_loss: 1.3342 - val_loss: 1.7269 - val_mean_absolute_error: 14.2837 - val_mean_squared_error: 601.8242 - val__pinball_loss: 1.7269\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.3327 - mean_absolute_error: 11.1072 - mean_squared_error: 416.7603 - _pinball_loss: 1.3327 - val_loss: 1.7276 - val_mean_absolute_error: 14.1855 - val_mean_squared_error: 594.1395 - val__pinball_loss: 1.7276\n",
      "0.2\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.9036 - mean_absolute_error: 13.0576 - mean_squared_error: 574.4932 - _pinball_loss: 2.9036 - val_loss: 2.9169 - val_mean_absolute_error: 11.0731 - val_mean_squared_error: 350.9101 - val__pinball_loss: 2.9169\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.2842 - mean_absolute_error: 8.6688 - mean_squared_error: 247.6829 - _pinball_loss: 2.2842 - val_loss: 2.8576 - val_mean_absolute_error: 10.7927 - val_mean_squared_error: 346.0504 - val__pinball_loss: 2.8576\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2367 - mean_absolute_error: 8.4170 - mean_squared_error: 240.5817 - _pinball_loss: 2.2367 - val_loss: 2.8299 - val_mean_absolute_error: 10.6851 - val_mean_squared_error: 346.0710 - val__pinball_loss: 2.8299\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2166 - mean_absolute_error: 8.3045 - mean_squared_error: 237.5546 - _pinball_loss: 2.2166 - val_loss: 2.8191 - val_mean_absolute_error: 10.7646 - val_mean_squared_error: 350.1292 - val__pinball_loss: 2.8191\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2036 - mean_absolute_error: 8.2439 - mean_squared_error: 236.0019 - _pinball_loss: 2.2036 - val_loss: 2.8056 - val_mean_absolute_error: 10.5703 - val_mean_squared_error: 342.2120 - val__pinball_loss: 2.8056\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1956 - mean_absolute_error: 8.2066 - mean_squared_error: 234.7409 - _pinball_loss: 2.1956 - val_loss: 2.8047 - val_mean_absolute_error: 10.6502 - val_mean_squared_error: 346.1917 - val__pinball_loss: 2.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1904 - mean_absolute_error: 8.1892 - mean_squared_error: 234.4913 - _pinball_loss: 2.1904 - val_loss: 2.7979 - val_mean_absolute_error: 10.5810 - val_mean_squared_error: 342.4866 - val__pinball_loss: 2.7979\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1836 - mean_absolute_error: 8.1320 - mean_squared_error: 232.0613 - _pinball_loss: 2.1836 - val_loss: 2.7941 - val_mean_absolute_error: 10.5046 - val_mean_squared_error: 339.7582 - val__pinball_loss: 2.7941\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1788 - mean_absolute_error: 8.1162 - mean_squared_error: 231.4786 - _pinball_loss: 2.1788 - val_loss: 2.7964 - val_mean_absolute_error: 10.5546 - val_mean_squared_error: 341.1242 - val__pinball_loss: 2.7964\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1754 - mean_absolute_error: 8.1061 - mean_squared_error: 231.3948 - _pinball_loss: 2.1754 - val_loss: 2.7858 - val_mean_absolute_error: 10.4283 - val_mean_squared_error: 336.1071 - val__pinball_loss: 2.7858\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 2.1695 - mean_absolute_error: 8.0830 - mean_squared_error: 230.6764 - _pinball_loss: 2.1695 - val_loss: 2.7889 - val_mean_absolute_error: 10.4791 - val_mean_squared_error: 340.2798 - val__pinball_loss: 2.7889\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1678 - mean_absolute_error: 8.0657 - mean_squared_error: 229.9922 - _pinball_loss: 2.1678 - val_loss: 2.7837 - val_mean_absolute_error: 10.4000 - val_mean_squared_error: 337.8243 - val__pinball_loss: 2.7837\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1648 - mean_absolute_error: 8.0390 - mean_squared_error: 228.8801 - _pinball_loss: 2.1648 - val_loss: 2.7826 - val_mean_absolute_error: 10.4302 - val_mean_squared_error: 336.9183 - val__pinball_loss: 2.7826\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1599 - mean_absolute_error: 8.0210 - mean_squared_error: 228.4061 - _pinball_loss: 2.1599 - val_loss: 2.7844 - val_mean_absolute_error: 10.4541 - val_mean_squared_error: 338.0891 - val__pinball_loss: 2.7844\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1577 - mean_absolute_error: 8.0211 - mean_squared_error: 228.4760 - _pinball_loss: 2.1577 - val_loss: 2.7802 - val_mean_absolute_error: 10.3470 - val_mean_squared_error: 333.7068 - val__pinball_loss: 2.7802\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1548 - mean_absolute_error: 8.0110 - mean_squared_error: 228.2967 - _pinball_loss: 2.1548 - val_loss: 2.7791 - val_mean_absolute_error: 10.3114 - val_mean_squared_error: 331.1755 - val__pinball_loss: 2.7791\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1543 - mean_absolute_error: 8.0144 - mean_squared_error: 228.3392 - _pinball_loss: 2.1543 - val_loss: 2.7825 - val_mean_absolute_error: 10.4416 - val_mean_squared_error: 338.7883 - val__pinball_loss: 2.7825\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1500 - mean_absolute_error: 7.9865 - mean_squared_error: 227.3188 - _pinball_loss: 2.1500 - val_loss: 2.7803 - val_mean_absolute_error: 10.4756 - val_mean_squared_error: 340.5486 - val__pinball_loss: 2.7803\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1473 - mean_absolute_error: 7.9857 - mean_squared_error: 227.3571 - _pinball_loss: 2.1473 - val_loss: 2.7763 - val_mean_absolute_error: 10.2706 - val_mean_squared_error: 330.2433 - val__pinball_loss: 2.7763\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1442 - mean_absolute_error: 7.9625 - mean_squared_error: 226.4683 - _pinball_loss: 2.1442 - val_loss: 2.7786 - val_mean_absolute_error: 10.3645 - val_mean_squared_error: 335.5160 - val__pinball_loss: 2.7786\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1418 - mean_absolute_error: 7.9516 - mean_squared_error: 226.1510 - _pinball_loss: 2.1418 - val_loss: 2.7798 - val_mean_absolute_error: 10.2744 - val_mean_squared_error: 332.1246 - val__pinball_loss: 2.7798\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1397 - mean_absolute_error: 7.9332 - mean_squared_error: 225.3644 - _pinball_loss: 2.1397 - val_loss: 2.7755 - val_mean_absolute_error: 10.2136 - val_mean_squared_error: 327.5234 - val__pinball_loss: 2.7755\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1375 - mean_absolute_error: 7.9310 - mean_squared_error: 225.3570 - _pinball_loss: 2.1375 - val_loss: 2.7765 - val_mean_absolute_error: 10.2513 - val_mean_squared_error: 329.2346 - val__pinball_loss: 2.7765\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1349 - mean_absolute_error: 7.9315 - mean_squared_error: 225.4535 - _pinball_loss: 2.1349 - val_loss: 2.7775 - val_mean_absolute_error: 10.3452 - val_mean_squared_error: 335.6170 - val__pinball_loss: 2.7775\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1320 - mean_absolute_error: 7.9006 - mean_squared_error: 224.2004 - _pinball_loss: 2.1320 - val_loss: 2.7818 - val_mean_absolute_error: 10.2859 - val_mean_squared_error: 331.8181 - val__pinball_loss: 2.7818\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1304 - mean_absolute_error: 7.9055 - mean_squared_error: 224.4070 - _pinball_loss: 2.1304 - val_loss: 2.7843 - val_mean_absolute_error: 10.2111 - val_mean_squared_error: 328.2446 - val__pinball_loss: 2.7843\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1264 - mean_absolute_error: 7.8896 - mean_squared_error: 223.7060 - _pinball_loss: 2.1264 - val_loss: 2.7849 - val_mean_absolute_error: 10.3936 - val_mean_squared_error: 336.6964 - val__pinball_loss: 2.7849\n",
      "0.3\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 3.9869 - mean_absolute_error: 11.9742 - mean_squared_error: 509.9710 - _pinball_loss: 3.9869 - val_loss: 3.5503 - val_mean_absolute_error: 8.9688 - val_mean_squared_error: 243.7790 - val__pinball_loss: 3.5503\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7779 - mean_absolute_error: 6.9583 - mean_squared_error: 167.3619 - _pinball_loss: 2.7779 - val_loss: 3.4654 - val_mean_absolute_error: 8.6677 - val_mean_squared_error: 236.1904 - val__pinball_loss: 3.4654\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7124 - mean_absolute_error: 6.7444 - mean_squared_error: 161.4330 - _pinball_loss: 2.7124 - val_loss: 3.4348 - val_mean_absolute_error: 8.5572 - val_mean_squared_error: 234.0304 - val__pinball_loss: 3.4348\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6842 - mean_absolute_error: 6.6443 - mean_squared_error: 158.8002 - _pinball_loss: 2.6842 - val_loss: 3.4079 - val_mean_absolute_error: 8.4865 - val_mean_squared_error: 232.9664 - val__pinball_loss: 3.4079\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6664 - mean_absolute_error: 6.5814 - mean_squared_error: 156.8470 - _pinball_loss: 2.6664 - val_loss: 3.4029 - val_mean_absolute_error: 8.3460 - val_mean_squared_error: 228.8723 - val__pinball_loss: 3.4029\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6511 - mean_absolute_error: 6.5268 - mean_squared_error: 155.4007 - _pinball_loss: 2.6511 - val_loss: 3.3864 - val_mean_absolute_error: 8.2891 - val_mean_squared_error: 226.1324 - val__pinball_loss: 3.3864\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6374 - mean_absolute_error: 6.4830 - mean_squared_error: 153.9393 - _pinball_loss: 2.6374 - val_loss: 3.3769 - val_mean_absolute_error: 8.4014 - val_mean_squared_error: 229.2510 - val__pinball_loss: 3.3769\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6279 - mean_absolute_error: 6.4508 - mean_squared_error: 152.8243 - _pinball_loss: 2.6279 - val_loss: 3.3802 - val_mean_absolute_error: 8.3529 - val_mean_squared_error: 228.6375 - val__pinball_loss: 3.3802\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6202 - mean_absolute_error: 6.4199 - mean_squared_error: 152.0252 - _pinball_loss: 2.6202 - val_loss: 3.3768 - val_mean_absolute_error: 8.3400 - val_mean_squared_error: 228.2737 - val__pinball_loss: 3.3768\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6139 - mean_absolute_error: 6.4044 - mean_squared_error: 151.5302 - _pinball_loss: 2.6139 - val_loss: 3.3725 - val_mean_absolute_error: 8.4064 - val_mean_squared_error: 229.0435 - val__pinball_loss: 3.3725\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6112 - mean_absolute_error: 6.3940 - mean_squared_error: 151.0877 - _pinball_loss: 2.6112 - val_loss: 3.3639 - val_mean_absolute_error: 8.3181 - val_mean_squared_error: 227.4290 - val__pinball_loss: 3.3639\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6024 - mean_absolute_error: 6.3639 - mean_squared_error: 150.2335 - _pinball_loss: 2.6024 - val_loss: 3.3696 - val_mean_absolute_error: 8.2093 - val_mean_squared_error: 222.6277 - val__pinball_loss: 3.3696\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6015 - mean_absolute_error: 6.3582 - mean_squared_error: 150.0203 - _pinball_loss: 2.6015 - val_loss: 3.3630 - val_mean_absolute_error: 8.3233 - val_mean_squared_error: 227.0863 - val__pinball_loss: 3.3630\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5967 - mean_absolute_error: 6.3471 - mean_squared_error: 149.8103 - _pinball_loss: 2.5967 - val_loss: 3.3554 - val_mean_absolute_error: 8.2995 - val_mean_squared_error: 226.8803 - val__pinball_loss: 3.3554\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5925 - mean_absolute_error: 6.3354 - mean_squared_error: 149.6054 - _pinball_loss: 2.5925 - val_loss: 3.3595 - val_mean_absolute_error: 8.3348 - val_mean_squared_error: 227.5610 - val__pinball_loss: 3.3595\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5898 - mean_absolute_error: 6.3271 - mean_squared_error: 149.1767 - _pinball_loss: 2.5898 - val_loss: 3.3531 - val_mean_absolute_error: 8.2990 - val_mean_squared_error: 225.5562 - val__pinball_loss: 3.3531\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5865 - mean_absolute_error: 6.3133 - mean_squared_error: 148.9087 - _pinball_loss: 2.5865 - val_loss: 3.3607 - val_mean_absolute_error: 8.2599 - val_mean_squared_error: 225.7488 - val__pinball_loss: 3.3607\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5842 - mean_absolute_error: 6.3041 - mean_squared_error: 148.5751 - _pinball_loss: 2.5842 - val_loss: 3.3583 - val_mean_absolute_error: 8.2151 - val_mean_squared_error: 224.6420 - val__pinball_loss: 3.3583\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5794 - mean_absolute_error: 6.2830 - mean_squared_error: 147.9753 - _pinball_loss: 2.5794 - val_loss: 3.3546 - val_mean_absolute_error: 8.3013 - val_mean_squared_error: 225.9054 - val__pinball_loss: 3.3546\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5776 - mean_absolute_error: 6.2807 - mean_squared_error: 147.6958 - _pinball_loss: 2.5776 - val_loss: 3.3519 - val_mean_absolute_error: 8.2800 - val_mean_squared_error: 225.8723 - val__pinball_loss: 3.3519\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5766 - mean_absolute_error: 6.2799 - mean_squared_error: 147.8169 - _pinball_loss: 2.5766 - val_loss: 3.3604 - val_mean_absolute_error: 8.2853 - val_mean_squared_error: 224.7760 - val__pinball_loss: 3.3604\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5719 - mean_absolute_error: 6.2656 - mean_squared_error: 147.1696 - _pinball_loss: 2.5719 - val_loss: 3.3584 - val_mean_absolute_error: 8.2025 - val_mean_squared_error: 223.8696 - val__pinball_loss: 3.3584\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5699 - mean_absolute_error: 6.2557 - mean_squared_error: 147.0149 - _pinball_loss: 2.5699 - val_loss: 3.3595 - val_mean_absolute_error: 8.2759 - val_mean_squared_error: 225.8539 - val__pinball_loss: 3.3595\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5661 - mean_absolute_error: 6.2491 - mean_squared_error: 146.9191 - _pinball_loss: 2.5661 - val_loss: 3.3506 - val_mean_absolute_error: 8.2526 - val_mean_squared_error: 225.6075 - val__pinball_loss: 3.3506\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5642 - mean_absolute_error: 6.2423 - mean_squared_error: 146.5631 - _pinball_loss: 2.5642 - val_loss: 3.3529 - val_mean_absolute_error: 8.2747 - val_mean_squared_error: 225.8339 - val__pinball_loss: 3.3529\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5650 - mean_absolute_error: 6.2483 - mean_squared_error: 146.8412 - _pinball_loss: 2.5650 - val_loss: 3.3550 - val_mean_absolute_error: 8.2677 - val_mean_squared_error: 225.1054 - val__pinball_loss: 3.3550\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5610 - mean_absolute_error: 6.2310 - mean_squared_error: 146.3881 - _pinball_loss: 2.5610 - val_loss: 3.3623 - val_mean_absolute_error: 8.1780 - val_mean_squared_error: 222.8747 - val__pinball_loss: 3.3623\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5595 - mean_absolute_error: 6.2238 - mean_squared_error: 146.1653 - _pinball_loss: 2.5595 - val_loss: 3.3496 - val_mean_absolute_error: 8.1766 - val_mean_squared_error: 222.1544 - val__pinball_loss: 3.3496\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5547 - mean_absolute_error: 6.2174 - mean_squared_error: 146.0054 - _pinball_loss: 2.5547 - val_loss: 3.3646 - val_mean_absolute_error: 8.2623 - val_mean_squared_error: 225.7187 - val__pinball_loss: 3.3646\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5590 - mean_absolute_error: 6.2348 - mean_squared_error: 146.5293 - _pinball_loss: 2.5590 - val_loss: 3.3528 - val_mean_absolute_error: 8.1341 - val_mean_squared_error: 221.7986 - val__pinball_loss: 3.3528\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5497 - mean_absolute_error: 6.1982 - mean_squared_error: 145.3831 - _pinball_loss: 2.5497 - val_loss: 3.3613 - val_mean_absolute_error: 8.2092 - val_mean_squared_error: 223.0119 - val__pinball_loss: 3.3613\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5489 - mean_absolute_error: 6.2031 - mean_squared_error: 145.3900 - _pinball_loss: 2.5489 - val_loss: 3.3665 - val_mean_absolute_error: 8.2460 - val_mean_squared_error: 225.5485 - val__pinball_loss: 3.3665\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5483 - mean_absolute_error: 6.1956 - mean_squared_error: 145.2568 - _pinball_loss: 2.5483 - val_loss: 3.3535 - val_mean_absolute_error: 8.2568 - val_mean_squared_error: 226.4186 - val__pinball_loss: 3.3535\n",
      "0.4\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 4.3660 - mean_absolute_error: 9.8939 - mean_squared_error: 354.7289 - _pinball_loss: 4.3660 - val_loss: 3.7835 - val_mean_absolute_error: 7.7608 - val_mean_squared_error: 204.2648 - val__pinball_loss: 3.7835\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.9833 - mean_absolute_error: 6.1371 - mean_squared_error: 142.2210 - _pinball_loss: 2.9833 - val_loss: 3.7042 - val_mean_absolute_error: 7.4783 - val_mean_squared_error: 199.0355 - val__pinball_loss: 3.7042\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.9010 - mean_absolute_error: 5.9324 - mean_squared_error: 136.4477 - _pinball_loss: 2.9010 - val_loss: 3.6488 - val_mean_absolute_error: 7.4762 - val_mean_squared_error: 194.9290 - val__pinball_loss: 3.6488\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.8539 - mean_absolute_error: 5.8207 - mean_squared_error: 133.5850 - _pinball_loss: 2.8539 - val_loss: 3.6313 - val_mean_absolute_error: 7.4456 - val_mean_squared_error: 193.8660 - val__pinball_loss: 3.6313\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.8309 - mean_absolute_error: 5.7654 - mean_squared_error: 132.2597 - _pinball_loss: 2.8309 - val_loss: 3.6120 - val_mean_absolute_error: 7.3925 - val_mean_squared_error: 192.4305 - val__pinball_loss: 3.6120\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.8123 - mean_absolute_error: 5.7169 - mean_squared_error: 131.0493 - _pinball_loss: 2.8123 - val_loss: 3.5975 - val_mean_absolute_error: 7.3393 - val_mean_squared_error: 193.0411 - val__pinball_loss: 3.5975\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7961 - mean_absolute_error: 5.6789 - mean_squared_error: 130.2518 - _pinball_loss: 2.7961 - val_loss: 3.5910 - val_mean_absolute_error: 7.3348 - val_mean_squared_error: 192.3975 - val__pinball_loss: 3.5910\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7831 - mean_absolute_error: 5.6494 - mean_squared_error: 129.4921 - _pinball_loss: 2.7831 - val_loss: 3.5837 - val_mean_absolute_error: 7.2543 - val_mean_squared_error: 191.6000 - val__pinball_loss: 3.5837\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7737 - mean_absolute_error: 5.6242 - mean_squared_error: 128.7897 - _pinball_loss: 2.7737 - val_loss: 3.5919 - val_mean_absolute_error: 7.2674 - val_mean_squared_error: 192.7766 - val__pinball_loss: 3.5919\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7674 - mean_absolute_error: 5.6074 - mean_squared_error: 128.6573 - _pinball_loss: 2.7674 - val_loss: 3.5757 - val_mean_absolute_error: 7.2878 - val_mean_squared_error: 190.5246 - val__pinball_loss: 3.5757\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7592 - mean_absolute_error: 5.5906 - mean_squared_error: 127.9702 - _pinball_loss: 2.7592 - val_loss: 3.5862 - val_mean_absolute_error: 7.2914 - val_mean_squared_error: 191.6438 - val__pinball_loss: 3.5862\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7547 - mean_absolute_error: 5.5802 - mean_squared_error: 127.7528 - _pinball_loss: 2.7547 - val_loss: 3.5816 - val_mean_absolute_error: 7.2586 - val_mean_squared_error: 192.6321 - val__pinball_loss: 3.5816\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7517 - mean_absolute_error: 5.5714 - mean_squared_error: 127.6810 - _pinball_loss: 2.7517 - val_loss: 3.5678 - val_mean_absolute_error: 7.1835 - val_mean_squared_error: 191.1750 - val__pinball_loss: 3.5678\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7403 - mean_absolute_error: 5.5410 - mean_squared_error: 127.0216 - _pinball_loss: 2.7403 - val_loss: 3.5663 - val_mean_absolute_error: 7.2649 - val_mean_squared_error: 191.1558 - val__pinball_loss: 3.5663\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7390 - mean_absolute_error: 5.5426 - mean_squared_error: 127.0678 - _pinball_loss: 2.7390 - val_loss: 3.5726 - val_mean_absolute_error: 7.2306 - val_mean_squared_error: 192.0611 - val__pinball_loss: 3.5726\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7365 - mean_absolute_error: 5.5357 - mean_squared_error: 126.7600 - _pinball_loss: 2.7365 - val_loss: 3.5677 - val_mean_absolute_error: 7.1612 - val_mean_squared_error: 191.9482 - val__pinball_loss: 3.5677\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7285 - mean_absolute_error: 5.5117 - mean_squared_error: 126.3961 - _pinball_loss: 2.7285 - val_loss: 3.5638 - val_mean_absolute_error: 7.1937 - val_mean_squared_error: 191.7891 - val__pinball_loss: 3.5638\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7266 - mean_absolute_error: 5.5127 - mean_squared_error: 126.3367 - _pinball_loss: 2.7266 - val_loss: 3.5651 - val_mean_absolute_error: 7.1932 - val_mean_squared_error: 191.2816 - val__pinball_loss: 3.5651\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7225 - mean_absolute_error: 5.5041 - mean_squared_error: 126.2562 - _pinball_loss: 2.7225 - val_loss: 3.5562 - val_mean_absolute_error: 7.1890 - val_mean_squared_error: 190.7115 - val__pinball_loss: 3.5562\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7198 - mean_absolute_error: 5.4959 - mean_squared_error: 126.0651 - _pinball_loss: 2.7198 - val_loss: 3.5594 - val_mean_absolute_error: 7.2223 - val_mean_squared_error: 191.5664 - val__pinball_loss: 3.5594\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7152 - mean_absolute_error: 5.4845 - mean_squared_error: 125.8126 - _pinball_loss: 2.7152 - val_loss: 3.5614 - val_mean_absolute_error: 7.2494 - val_mean_squared_error: 192.0558 - val__pinball_loss: 3.5614\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7127 - mean_absolute_error: 5.4827 - mean_squared_error: 125.6145 - _pinball_loss: 2.7127 - val_loss: 3.5591 - val_mean_absolute_error: 7.1859 - val_mean_squared_error: 191.6445 - val__pinball_loss: 3.5591\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7087 - mean_absolute_error: 5.4705 - mean_squared_error: 125.4366 - _pinball_loss: 2.7087 - val_loss: 3.5533 - val_mean_absolute_error: 7.1712 - val_mean_squared_error: 191.9623 - val__pinball_loss: 3.5533\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7064 - mean_absolute_error: 5.4675 - mean_squared_error: 125.2914 - _pinball_loss: 2.7064 - val_loss: 3.5634 - val_mean_absolute_error: 7.1427 - val_mean_squared_error: 192.4136 - val__pinball_loss: 3.5634\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7035 - mean_absolute_error: 5.4580 - mean_squared_error: 125.0777 - _pinball_loss: 2.7035 - val_loss: 3.5714 - val_mean_absolute_error: 7.1658 - val_mean_squared_error: 192.7033 - val__pinball_loss: 3.5714\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6992 - mean_absolute_error: 5.4492 - mean_squared_error: 124.7930 - _pinball_loss: 2.6992 - val_loss: 3.5628 - val_mean_absolute_error: 7.1774 - val_mean_squared_error: 193.2524 - val__pinball_loss: 3.5628\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7000 - mean_absolute_error: 5.4510 - mean_squared_error: 124.8715 - _pinball_loss: 2.7000 - val_loss: 3.5501 - val_mean_absolute_error: 7.2236 - val_mean_squared_error: 191.3696 - val__pinball_loss: 3.5501\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6947 - mean_absolute_error: 5.4427 - mean_squared_error: 124.5109 - _pinball_loss: 2.6947 - val_loss: 3.5588 - val_mean_absolute_error: 7.2002 - val_mean_squared_error: 192.4526 - val__pinball_loss: 3.5588\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6915 - mean_absolute_error: 5.4300 - mean_squared_error: 124.3612 - _pinball_loss: 2.6915 - val_loss: 3.5579 - val_mean_absolute_error: 7.2040 - val_mean_squared_error: 191.6977 - val__pinball_loss: 3.5579\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6897 - mean_absolute_error: 5.4282 - mean_squared_error: 124.2832 - _pinball_loss: 2.6897 - val_loss: 3.5656 - val_mean_absolute_error: 7.1812 - val_mean_squared_error: 193.0775 - val__pinball_loss: 3.5656\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6847 - mean_absolute_error: 5.4189 - mean_squared_error: 123.8452 - _pinball_loss: 2.6847 - val_loss: 3.5537 - val_mean_absolute_error: 7.2152 - val_mean_squared_error: 191.7488 - val__pinball_loss: 3.5537\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6810 - mean_absolute_error: 5.4124 - mean_squared_error: 123.7259 - _pinball_loss: 2.6810 - val_loss: 3.5571 - val_mean_absolute_error: 7.1631 - val_mean_squared_error: 192.1286 - val__pinball_loss: 3.5571\n",
      "0.5\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 4.7346 - mean_absolute_error: 9.4692 - mean_squared_error: 310.3320 - _pinball_loss: 4.7346 - val_loss: 3.7592 - val_mean_absolute_error: 7.5184 - val_mean_squared_error: 210.7276 - val__pinball_loss: 3.7592\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.9659 - mean_absolute_error: 5.9318 - mean_squared_error: 145.8437 - _pinball_loss: 2.9659 - val_loss: 3.6528 - val_mean_absolute_error: 7.3057 - val_mean_squared_error: 203.2002 - val__pinball_loss: 3.6528\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.8570 - mean_absolute_error: 5.7140 - mean_squared_error: 140.9110 - _pinball_loss: 2.8570 - val_loss: 3.5888 - val_mean_absolute_error: 7.1776 - val_mean_squared_error: 204.6103 - val__pinball_loss: 3.5888\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.8066 - mean_absolute_error: 5.6131 - mean_squared_error: 138.8490 - _pinball_loss: 2.8066 - val_loss: 3.5619 - val_mean_absolute_error: 7.1238 - val_mean_squared_error: 200.5043 - val__pinball_loss: 3.5619\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7758 - mean_absolute_error: 5.5517 - mean_squared_error: 137.6773 - _pinball_loss: 2.7758 - val_loss: 3.5445 - val_mean_absolute_error: 7.0890 - val_mean_squared_error: 200.9843 - val__pinball_loss: 3.5445\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7545 - mean_absolute_error: 5.5090 - mean_squared_error: 136.3988 - _pinball_loss: 2.7545 - val_loss: 3.5381 - val_mean_absolute_error: 7.0762 - val_mean_squared_error: 197.0781 - val__pinball_loss: 3.5381\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7393 - mean_absolute_error: 5.4786 - mean_squared_error: 135.9265 - _pinball_loss: 2.7393 - val_loss: 3.5328 - val_mean_absolute_error: 7.0657 - val_mean_squared_error: 198.4186 - val__pinball_loss: 3.5328\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7237 - mean_absolute_error: 5.4474 - mean_squared_error: 135.2885 - _pinball_loss: 2.7237 - val_loss: 3.5246 - val_mean_absolute_error: 7.0491 - val_mean_squared_error: 202.0228 - val__pinball_loss: 3.5246\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7125 - mean_absolute_error: 5.4250 - mean_squared_error: 134.9286 - _pinball_loss: 2.7125 - val_loss: 3.4981 - val_mean_absolute_error: 6.9963 - val_mean_squared_error: 201.5201 - val__pinball_loss: 3.4981\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7027 - mean_absolute_error: 5.4054 - mean_squared_error: 134.7478 - _pinball_loss: 2.7027 - val_loss: 3.5037 - val_mean_absolute_error: 7.0074 - val_mean_squared_error: 196.5747 - val__pinball_loss: 3.5037\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6942 - mean_absolute_error: 5.3884 - mean_squared_error: 134.1743 - _pinball_loss: 2.6942 - val_loss: 3.4979 - val_mean_absolute_error: 6.9958 - val_mean_squared_error: 197.4254 - val__pinball_loss: 3.4979\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6864 - mean_absolute_error: 5.3727 - mean_squared_error: 133.9115 - _pinball_loss: 2.6864 - val_loss: 3.4875 - val_mean_absolute_error: 6.9749 - val_mean_squared_error: 194.3262 - val__pinball_loss: 3.4875\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6775 - mean_absolute_error: 5.3551 - mean_squared_error: 133.3385 - _pinball_loss: 2.6775 - val_loss: 3.4779 - val_mean_absolute_error: 6.9558 - val_mean_squared_error: 198.4989 - val__pinball_loss: 3.4779\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6693 - mean_absolute_error: 5.3386 - mean_squared_error: 133.2258 - _pinball_loss: 2.6693 - val_loss: 3.4811 - val_mean_absolute_error: 6.9622 - val_mean_squared_error: 199.9159 - val__pinball_loss: 3.4811\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6666 - mean_absolute_error: 5.3332 - mean_squared_error: 133.0815 - _pinball_loss: 2.6666 - val_loss: 3.4765 - val_mean_absolute_error: 6.9531 - val_mean_squared_error: 194.8644 - val__pinball_loss: 3.4765\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6571 - mean_absolute_error: 5.3141 - mean_squared_error: 132.7991 - _pinball_loss: 2.6571 - val_loss: 3.4778 - val_mean_absolute_error: 6.9557 - val_mean_squared_error: 201.5800 - val__pinball_loss: 3.4778\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6495 - mean_absolute_error: 5.2990 - mean_squared_error: 132.5056 - _pinball_loss: 2.6495 - val_loss: 3.4839 - val_mean_absolute_error: 6.9678 - val_mean_squared_error: 200.4353 - val__pinball_loss: 3.4839\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6452 - mean_absolute_error: 5.2903 - mean_squared_error: 132.4346 - _pinball_loss: 2.6452 - val_loss: 3.4654 - val_mean_absolute_error: 6.9308 - val_mean_squared_error: 196.5018 - val__pinball_loss: 3.4654\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6404 - mean_absolute_error: 5.2809 - mean_squared_error: 132.1374 - _pinball_loss: 2.6404 - val_loss: 3.4577 - val_mean_absolute_error: 6.9153 - val_mean_squared_error: 195.6633 - val__pinball_loss: 3.4577\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6321 - mean_absolute_error: 5.2641 - mean_squared_error: 131.7624 - _pinball_loss: 2.6321 - val_loss: 3.4610 - val_mean_absolute_error: 6.9220 - val_mean_squared_error: 198.5671 - val__pinball_loss: 3.4610\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6314 - mean_absolute_error: 5.2628 - mean_squared_error: 131.7535 - _pinball_loss: 2.6314 - val_loss: 3.4483 - val_mean_absolute_error: 6.8966 - val_mean_squared_error: 197.9192 - val__pinball_loss: 3.4483\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6285 - mean_absolute_error: 5.2570 - mean_squared_error: 131.6964 - _pinball_loss: 2.6285 - val_loss: 3.4588 - val_mean_absolute_error: 6.9176 - val_mean_squared_error: 198.6456 - val__pinball_loss: 3.4588\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6204 - mean_absolute_error: 5.2408 - mean_squared_error: 131.2142 - _pinball_loss: 2.6204 - val_loss: 3.4502 - val_mean_absolute_error: 6.9004 - val_mean_squared_error: 199.7214 - val__pinball_loss: 3.4502\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6177 - mean_absolute_error: 5.2355 - mean_squared_error: 131.3628 - _pinball_loss: 2.6177 - val_loss: 3.4431 - val_mean_absolute_error: 6.8862 - val_mean_squared_error: 196.7432 - val__pinball_loss: 3.4431\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6148 - mean_absolute_error: 5.2296 - mean_squared_error: 130.9125 - _pinball_loss: 2.6148 - val_loss: 3.4491 - val_mean_absolute_error: 6.8981 - val_mean_squared_error: 199.1313 - val__pinball_loss: 3.4491\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6126 - mean_absolute_error: 5.2253 - mean_squared_error: 130.7926 - _pinball_loss: 2.6126 - val_loss: 3.4540 - val_mean_absolute_error: 6.9081 - val_mean_squared_error: 198.8870 - val__pinball_loss: 3.4540\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6082 - mean_absolute_error: 5.2163 - mean_squared_error: 130.3330 - _pinball_loss: 2.6082 - val_loss: 3.4297 - val_mean_absolute_error: 6.8594 - val_mean_squared_error: 196.5342 - val__pinball_loss: 3.4297\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6029 - mean_absolute_error: 5.2059 - mean_squared_error: 130.3486 - _pinball_loss: 2.6029 - val_loss: 3.4448 - val_mean_absolute_error: 6.8897 - val_mean_squared_error: 196.6383 - val__pinball_loss: 3.4448\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.6033 - mean_absolute_error: 5.2065 - mean_squared_error: 130.3442 - _pinball_loss: 2.6033 - val_loss: 3.4619 - val_mean_absolute_error: 6.9238 - val_mean_squared_error: 197.6494 - val__pinball_loss: 3.4619\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5997 - mean_absolute_error: 5.1994 - mean_squared_error: 130.0762 - _pinball_loss: 2.5997 - val_loss: 3.4434 - val_mean_absolute_error: 6.8868 - val_mean_squared_error: 197.7883 - val__pinball_loss: 3.4434\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5972 - mean_absolute_error: 5.1945 - mean_squared_error: 129.9568 - _pinball_loss: 2.5972 - val_loss: 3.4562 - val_mean_absolute_error: 6.9125 - val_mean_squared_error: 203.6543 - val__pinball_loss: 3.4562\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5928 - mean_absolute_error: 5.1856 - mean_squared_error: 129.8727 - _pinball_loss: 2.5928 - val_loss: 3.4358 - val_mean_absolute_error: 6.8717 - val_mean_squared_error: 196.9977 - val__pinball_loss: 3.4358\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000176788A1CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.6\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 4.9556 - mean_absolute_error: 9.7769 - mean_squared_error: 314.1217 - _pinball_loss: 4.9556 - val_loss: 3.5012 - val_mean_absolute_error: 7.6589 - val_mean_squared_error: 228.5135 - val__pinball_loss: 3.5012\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.7305 - mean_absolute_error: 6.0374 - mean_squared_error: 159.2764 - _pinball_loss: 2.7305 - val_loss: 3.3421 - val_mean_absolute_error: 7.3172 - val_mean_squared_error: 216.3496 - val__pinball_loss: 3.3421\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5998 - mean_absolute_error: 5.8000 - mean_squared_error: 155.3367 - _pinball_loss: 2.5998 - val_loss: 3.2677 - val_mean_absolute_error: 7.1562 - val_mean_squared_error: 213.3563 - val__pinball_loss: 3.2677\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.5372 - mean_absolute_error: 5.6846 - mean_squared_error: 153.6780 - _pinball_loss: 2.5372 - val_loss: 3.2391 - val_mean_absolute_error: 7.2212 - val_mean_squared_error: 222.5378 - val__pinball_loss: 3.2391\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4997 - mean_absolute_error: 5.6203 - mean_squared_error: 153.2236 - _pinball_loss: 2.4997 - val_loss: 3.1958 - val_mean_absolute_error: 7.1062 - val_mean_squared_error: 217.4032 - val__pinball_loss: 3.1958\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4674 - mean_absolute_error: 5.5611 - mean_squared_error: 152.6947 - _pinball_loss: 2.4674 - val_loss: 3.1854 - val_mean_absolute_error: 7.0323 - val_mean_squared_error: 213.5836 - val__pinball_loss: 3.1854\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4468 - mean_absolute_error: 5.5230 - mean_squared_error: 152.1913 - _pinball_loss: 2.4468 - val_loss: 3.1659 - val_mean_absolute_error: 6.9967 - val_mean_squared_error: 212.6598 - val__pinball_loss: 3.1659\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4361 - mean_absolute_error: 5.5030 - mean_squared_error: 151.7534 - _pinball_loss: 2.4361 - val_loss: 3.1393 - val_mean_absolute_error: 7.0289 - val_mean_squared_error: 218.4844 - val__pinball_loss: 3.1393\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4190 - mean_absolute_error: 5.4744 - mean_squared_error: 151.8059 - _pinball_loss: 2.4190 - val_loss: 3.1646 - val_mean_absolute_error: 7.0941 - val_mean_squared_error: 222.0410 - val__pinball_loss: 3.1646\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4109 - mean_absolute_error: 5.4601 - mean_squared_error: 151.5499 - _pinball_loss: 2.4109 - val_loss: 3.1252 - val_mean_absolute_error: 6.9679 - val_mean_squared_error: 216.4153 - val__pinball_loss: 3.1252\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.4015 - mean_absolute_error: 5.4414 - mean_squared_error: 151.3376 - _pinball_loss: 2.4015 - val_loss: 3.1309 - val_mean_absolute_error: 6.9592 - val_mean_squared_error: 214.3103 - val__pinball_loss: 3.1309\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3955 - mean_absolute_error: 5.4291 - mean_squared_error: 150.9264 - _pinball_loss: 2.3955 - val_loss: 3.1334 - val_mean_absolute_error: 6.9837 - val_mean_squared_error: 216.7422 - val__pinball_loss: 3.1334\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3897 - mean_absolute_error: 5.4240 - mean_squared_error: 151.6144 - _pinball_loss: 2.3897 - val_loss: 3.1091 - val_mean_absolute_error: 6.9837 - val_mean_squared_error: 219.8799 - val__pinball_loss: 3.1091\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3827 - mean_absolute_error: 5.4072 - mean_squared_error: 150.9894 - _pinball_loss: 2.3827 - val_loss: 3.1247 - val_mean_absolute_error: 6.9672 - val_mean_squared_error: 216.8551 - val__pinball_loss: 3.1247\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3764 - mean_absolute_error: 5.3957 - mean_squared_error: 150.8833 - _pinball_loss: 2.3764 - val_loss: 3.1054 - val_mean_absolute_error: 6.9775 - val_mean_squared_error: 220.4120 - val__pinball_loss: 3.1054\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3683 - mean_absolute_error: 5.3816 - mean_squared_error: 150.7396 - _pinball_loss: 2.3683 - val_loss: 3.1176 - val_mean_absolute_error: 6.9642 - val_mean_squared_error: 217.1267 - val__pinball_loss: 3.1176\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3669 - mean_absolute_error: 5.3793 - mean_squared_error: 150.6618 - _pinball_loss: 2.3669 - val_loss: 3.1219 - val_mean_absolute_error: 6.9810 - val_mean_squared_error: 217.9350 - val__pinball_loss: 3.1219\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3639 - mean_absolute_error: 5.3728 - mean_squared_error: 150.4685 - _pinball_loss: 2.3639 - val_loss: 3.1127 - val_mean_absolute_error: 6.9625 - val_mean_squared_error: 218.6452 - val__pinball_loss: 3.1127\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3566 - mean_absolute_error: 5.3586 - mean_squared_error: 150.3160 - _pinball_loss: 2.3566 - val_loss: 3.1125 - val_mean_absolute_error: 6.9421 - val_mean_squared_error: 215.8633 - val__pinball_loss: 3.1125\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3534 - mean_absolute_error: 5.3536 - mean_squared_error: 150.2444 - _pinball_loss: 2.3534 - val_loss: 3.1139 - val_mean_absolute_error: 6.9356 - val_mean_squared_error: 215.5175 - val__pinball_loss: 3.1139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001769EA9B9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.7\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 4.8412 - mean_absolute_error: 10.5556 - mean_squared_error: 334.6999 - _pinball_loss: 4.8412 - val_loss: 3.0047 - val_mean_absolute_error: 8.2094 - val_mean_squared_error: 268.0436 - val__pinball_loss: 3.0047\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.3772 - mean_absolute_error: 6.5466 - mean_squared_error: 184.7111 - _pinball_loss: 2.3772 - val_loss: 2.8572 - val_mean_absolute_error: 8.0138 - val_mean_squared_error: 266.7434 - val__pinball_loss: 2.8572\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.2281 - mean_absolute_error: 6.2509 - mean_squared_error: 180.4306 - _pinball_loss: 2.2281 - val_loss: 2.7630 - val_mean_absolute_error: 7.7264 - val_mean_squared_error: 262.1989 - val__pinball_loss: 2.7630\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1532 - mean_absolute_error: 6.0944 - mean_squared_error: 178.8539 - _pinball_loss: 2.1532 - val_loss: 2.7144 - val_mean_absolute_error: 7.7476 - val_mean_squared_error: 260.0684 - val__pinball_loss: 2.7144\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.1070 - mean_absolute_error: 6.0082 - mean_squared_error: 178.4313 - _pinball_loss: 2.1070 - val_loss: 2.6523 - val_mean_absolute_error: 7.4425 - val_mean_squared_error: 254.5732 - val__pinball_loss: 2.6523\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.0742 - mean_absolute_error: 5.9346 - mean_squared_error: 177.5142 - _pinball_loss: 2.0742 - val_loss: 2.6460 - val_mean_absolute_error: 7.6107 - val_mean_squared_error: 262.4997 - val__pinball_loss: 2.6460\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.0512 - mean_absolute_error: 5.8910 - mean_squared_error: 177.2423 - _pinball_loss: 2.0512 - val_loss: 2.6287 - val_mean_absolute_error: 7.4290 - val_mean_squared_error: 254.5258 - val__pinball_loss: 2.6287\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.0353 - mean_absolute_error: 5.8554 - mean_squared_error: 176.6210 - _pinball_loss: 2.0353 - val_loss: 2.6094 - val_mean_absolute_error: 7.3868 - val_mean_squared_error: 254.9768 - val__pinball_loss: 2.6094\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.0216 - mean_absolute_error: 5.8280 - mean_squared_error: 176.6475 - _pinball_loss: 2.0216 - val_loss: 2.5967 - val_mean_absolute_error: 7.3935 - val_mean_squared_error: 256.6933 - val__pinball_loss: 2.5967\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 2.0064 - mean_absolute_error: 5.7970 - mean_squared_error: 176.2035 - _pinball_loss: 2.0064 - val_loss: 2.5891 - val_mean_absolute_error: 7.4400 - val_mean_squared_error: 261.6063 - val__pinball_loss: 2.5891\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9955 - mean_absolute_error: 5.7770 - mean_squared_error: 176.3836 - _pinball_loss: 1.9955 - val_loss: 2.5759 - val_mean_absolute_error: 7.3840 - val_mean_squared_error: 258.2064 - val__pinball_loss: 2.5759\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9875 - mean_absolute_error: 5.7632 - mean_squared_error: 176.3846 - _pinball_loss: 1.9875 - val_loss: 2.5721 - val_mean_absolute_error: 7.3016 - val_mean_squared_error: 254.5875 - val__pinball_loss: 2.5721\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9838 - mean_absolute_error: 5.7474 - mean_squared_error: 175.7063 - _pinball_loss: 1.9838 - val_loss: 2.5640 - val_mean_absolute_error: 7.3870 - val_mean_squared_error: 261.0110 - val__pinball_loss: 2.5640\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9727 - mean_absolute_error: 5.7273 - mean_squared_error: 175.6477 - _pinball_loss: 1.9727 - val_loss: 2.5808 - val_mean_absolute_error: 7.4268 - val_mean_squared_error: 261.1379 - val__pinball_loss: 2.5808\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9671 - mean_absolute_error: 5.7172 - mean_squared_error: 175.5059 - _pinball_loss: 1.9671 - val_loss: 2.5536 - val_mean_absolute_error: 7.2951 - val_mean_squared_error: 257.0222 - val__pinball_loss: 2.5536\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9648 - mean_absolute_error: 5.7110 - mean_squared_error: 175.3895 - _pinball_loss: 1.9648 - val_loss: 2.5464 - val_mean_absolute_error: 7.2345 - val_mean_squared_error: 253.6661 - val__pinball_loss: 2.5464\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9546 - mean_absolute_error: 5.6849 - mean_squared_error: 174.7371 - _pinball_loss: 1.9546 - val_loss: 2.5483 - val_mean_absolute_error: 7.3816 - val_mean_squared_error: 262.0979 - val__pinball_loss: 2.5483\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9511 - mean_absolute_error: 5.6831 - mean_squared_error: 175.1680 - _pinball_loss: 1.9511 - val_loss: 2.5521 - val_mean_absolute_error: 7.3124 - val_mean_squared_error: 257.0731 - val__pinball_loss: 2.5521\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9462 - mean_absolute_error: 5.6756 - mean_squared_error: 175.2892 - _pinball_loss: 1.9462 - val_loss: 2.5613 - val_mean_absolute_error: 7.3983 - val_mean_squared_error: 262.1974 - val__pinball_loss: 2.5613\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9419 - mean_absolute_error: 5.6681 - mean_squared_error: 175.0383 - _pinball_loss: 1.9419 - val_loss: 2.5473 - val_mean_absolute_error: 7.2801 - val_mean_squared_error: 255.7038 - val__pinball_loss: 2.5473\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.9376 - mean_absolute_error: 5.6539 - mean_squared_error: 174.5424 - _pinball_loss: 1.9376 - val_loss: 2.5532 - val_mean_absolute_error: 7.3034 - val_mean_squared_error: 255.9265 - val__pinball_loss: 2.5532\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000178F83563A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.8\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 4.7014 - mean_absolute_error: 12.6387 - mean_squared_error: 419.2414 - _pinball_loss: 4.7014 - val_loss: 2.3246 - val_mean_absolute_error: 9.0311 - val_mean_squared_error: 302.7073 - val__pinball_loss: 2.3246\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.8653 - mean_absolute_error: 7.4615 - mean_squared_error: 220.1729 - _pinball_loss: 1.8653 - val_loss: 2.1719 - val_mean_absolute_error: 8.7269 - val_mean_squared_error: 298.5925 - val__pinball_loss: 2.1719\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.7338 - mean_absolute_error: 7.0906 - mean_squared_error: 213.6032 - _pinball_loss: 1.7338 - val_loss: 2.0958 - val_mean_absolute_error: 8.3877 - val_mean_squared_error: 288.5701 - val__pinball_loss: 2.0958\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.6730 - mean_absolute_error: 6.9149 - mean_squared_error: 211.4012 - _pinball_loss: 1.6730 - val_loss: 2.0585 - val_mean_absolute_error: 8.2574 - val_mean_squared_error: 284.4286 - val__pinball_loss: 2.0585\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.6280 - mean_absolute_error: 6.7753 - mean_squared_error: 209.7523 - _pinball_loss: 1.6280 - val_loss: 2.0077 - val_mean_absolute_error: 8.1613 - val_mean_squared_error: 289.8417 - val__pinball_loss: 2.0077\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5988 - mean_absolute_error: 6.6920 - mean_squared_error: 209.1261 - _pinball_loss: 1.5988 - val_loss: 1.9951 - val_mean_absolute_error: 8.0148 - val_mean_squared_error: 282.0603 - val__pinball_loss: 1.9951\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5777 - mean_absolute_error: 6.6289 - mean_squared_error: 208.4943 - _pinball_loss: 1.5777 - val_loss: 1.9799 - val_mean_absolute_error: 7.9918 - val_mean_squared_error: 282.1537 - val__pinball_loss: 1.9799\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5601 - mean_absolute_error: 6.5749 - mean_squared_error: 207.9730 - _pinball_loss: 1.5601 - val_loss: 1.9865 - val_mean_absolute_error: 8.3303 - val_mean_squared_error: 295.6978 - val__pinball_loss: 1.9865\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5501 - mean_absolute_error: 6.5488 - mean_squared_error: 207.4210 - _pinball_loss: 1.5501 - val_loss: 1.9607 - val_mean_absolute_error: 8.0496 - val_mean_squared_error: 287.9537 - val__pinball_loss: 1.9607\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5358 - mean_absolute_error: 6.5130 - mean_squared_error: 207.6028 - _pinball_loss: 1.5358 - val_loss: 1.9525 - val_mean_absolute_error: 8.1176 - val_mean_squared_error: 290.6925 - val__pinball_loss: 1.9525\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5300 - mean_absolute_error: 6.4980 - mean_squared_error: 207.4208 - _pinball_loss: 1.5300 - val_loss: 1.9521 - val_mean_absolute_error: 7.8885 - val_mean_squared_error: 280.7235 - val__pinball_loss: 1.9521\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5211 - mean_absolute_error: 6.4712 - mean_squared_error: 207.0526 - _pinball_loss: 1.5211 - val_loss: 1.9431 - val_mean_absolute_error: 7.8509 - val_mean_squared_error: 281.7712 - val__pinball_loss: 1.9431\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5110 - mean_absolute_error: 6.4383 - mean_squared_error: 206.5868 - _pinball_loss: 1.5110 - val_loss: 1.9276 - val_mean_absolute_error: 7.9233 - val_mean_squared_error: 284.7997 - val__pinball_loss: 1.9276\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5066 - mean_absolute_error: 6.4328 - mean_squared_error: 206.9326 - _pinball_loss: 1.5066 - val_loss: 1.9302 - val_mean_absolute_error: 7.8319 - val_mean_squared_error: 282.7638 - val__pinball_loss: 1.9302\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.5006 - mean_absolute_error: 6.4168 - mean_squared_error: 206.4840 - _pinball_loss: 1.5006 - val_loss: 1.9160 - val_mean_absolute_error: 8.0651 - val_mean_squared_error: 291.9218 - val__pinball_loss: 1.9160\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4947 - mean_absolute_error: 6.3979 - mean_squared_error: 206.1110 - _pinball_loss: 1.4947 - val_loss: 1.9339 - val_mean_absolute_error: 8.0351 - val_mean_squared_error: 292.6538 - val__pinball_loss: 1.9339\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4877 - mean_absolute_error: 6.3778 - mean_squared_error: 205.9414 - _pinball_loss: 1.4877 - val_loss: 1.9186 - val_mean_absolute_error: 7.8415 - val_mean_squared_error: 283.2023 - val__pinball_loss: 1.9186\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4851 - mean_absolute_error: 6.3669 - mean_squared_error: 205.8828 - _pinball_loss: 1.4851 - val_loss: 1.8928 - val_mean_absolute_error: 7.9246 - val_mean_squared_error: 291.7448 - val__pinball_loss: 1.8928\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4780 - mean_absolute_error: 6.3504 - mean_squared_error: 205.7771 - _pinball_loss: 1.4780 - val_loss: 1.9006 - val_mean_absolute_error: 7.9671 - val_mean_squared_error: 290.7296 - val__pinball_loss: 1.9006\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4734 - mean_absolute_error: 6.3408 - mean_squared_error: 205.6409 - _pinball_loss: 1.4734 - val_loss: 1.9019 - val_mean_absolute_error: 7.9898 - val_mean_squared_error: 290.3567 - val__pinball_loss: 1.9019\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4695 - mean_absolute_error: 6.3285 - mean_squared_error: 205.4044 - _pinball_loss: 1.4695 - val_loss: 1.9096 - val_mean_absolute_error: 7.9329 - val_mean_squared_error: 285.7039 - val__pinball_loss: 1.9096\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4644 - mean_absolute_error: 6.3121 - mean_squared_error: 205.4480 - _pinball_loss: 1.4644 - val_loss: 1.8741 - val_mean_absolute_error: 7.8383 - val_mean_squared_error: 287.5131 - val__pinball_loss: 1.8741\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4593 - mean_absolute_error: 6.2976 - mean_squared_error: 205.2074 - _pinball_loss: 1.4593 - val_loss: 1.8866 - val_mean_absolute_error: 7.9510 - val_mean_squared_error: 292.1176 - val__pinball_loss: 1.8866\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4554 - mean_absolute_error: 6.2924 - mean_squared_error: 205.1826 - _pinball_loss: 1.4554 - val_loss: 1.8853 - val_mean_absolute_error: 7.8573 - val_mean_squared_error: 287.3118 - val__pinball_loss: 1.8853\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4529 - mean_absolute_error: 6.2791 - mean_squared_error: 204.4954 - _pinball_loss: 1.4529 - val_loss: 1.8849 - val_mean_absolute_error: 7.7993 - val_mean_squared_error: 285.8171 - val__pinball_loss: 1.8849\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4490 - mean_absolute_error: 6.2720 - mean_squared_error: 204.9812 - _pinball_loss: 1.4490 - val_loss: 1.8823 - val_mean_absolute_error: 7.6853 - val_mean_squared_error: 280.2198 - val__pinball_loss: 1.8823\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.4448 - mean_absolute_error: 6.2555 - mean_squared_error: 204.2792 - _pinball_loss: 1.4448 - val_loss: 1.8963 - val_mean_absolute_error: 7.9146 - val_mean_squared_error: 290.1167 - val__pinball_loss: 1.8963\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017905DDB828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.9\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 11s 9ms/step - loss: 4.0768 - mean_absolute_error: 17.6203 - mean_squared_error: 664.8881 - _pinball_loss: 4.0768 - val_loss: 1.4485 - val_mean_absolute_error: 10.9731 - val_mean_squared_error: 377.1199 - val__pinball_loss: 1.4485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.1808 - mean_absolute_error: 9.4962 - mean_squared_error: 285.3818 - _pinball_loss: 1.1808 - val_loss: 1.3142 - val_mean_absolute_error: 10.2556 - val_mean_squared_error: 355.7460 - val__pinball_loss: 1.3142\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.0672 - mean_absolute_error: 8.7805 - mean_squared_error: 267.0790 - _pinball_loss: 1.0672 - val_loss: 1.2526 - val_mean_absolute_error: 9.8826 - val_mean_squared_error: 347.0743 - val__pinball_loss: 1.2526\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 1.0146 - mean_absolute_error: 8.4483 - mean_squared_error: 260.4474 - _pinball_loss: 1.0146 - val_loss: 1.2153 - val_mean_absolute_error: 9.5875 - val_mean_squared_error: 339.3181 - val__pinball_loss: 1.2153\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.9823 - mean_absolute_error: 8.2307 - mean_squared_error: 255.8366 - _pinball_loss: 0.9823 - val_loss: 1.1888 - val_mean_absolute_error: 9.3750 - val_mean_squared_error: 335.8696 - val__pinball_loss: 1.1888\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.9544 - mean_absolute_error: 8.0386 - mean_squared_error: 252.3055 - _pinball_loss: 0.9544 - val_loss: 1.1892 - val_mean_absolute_error: 9.6579 - val_mean_squared_error: 341.0187 - val__pinball_loss: 1.1892\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.9403 - mean_absolute_error: 7.9579 - mean_squared_error: 251.4683 - _pinball_loss: 0.9403 - val_loss: 1.1600 - val_mean_absolute_error: 9.2131 - val_mean_squared_error: 331.8658 - val__pinball_loss: 1.1600\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.9226 - mean_absolute_error: 7.8319 - mean_squared_error: 248.3941 - _pinball_loss: 0.9226 - val_loss: 1.1556 - val_mean_absolute_error: 9.5887 - val_mean_squared_error: 352.2954 - val__pinball_loss: 1.1556\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.9133 - mean_absolute_error: 7.7827 - mean_squared_error: 248.1302 - _pinball_loss: 0.9133 - val_loss: 1.1416 - val_mean_absolute_error: 9.4772 - val_mean_squared_error: 342.6332 - val__pinball_loss: 1.1416\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.9045 - mean_absolute_error: 7.7305 - mean_squared_error: 247.0122 - _pinball_loss: 0.9045 - val_loss: 1.1429 - val_mean_absolute_error: 9.1883 - val_mean_squared_error: 336.6595 - val__pinball_loss: 1.1429\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8955 - mean_absolute_error: 7.6688 - mean_squared_error: 246.0251 - _pinball_loss: 0.8955 - val_loss: 1.1328 - val_mean_absolute_error: 9.1341 - val_mean_squared_error: 331.1928 - val__pinball_loss: 1.1328\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8882 - mean_absolute_error: 7.6191 - mean_squared_error: 244.7474 - _pinball_loss: 0.8882 - val_loss: 1.1291 - val_mean_absolute_error: 9.2631 - val_mean_squared_error: 341.4123 - val__pinball_loss: 1.1291\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8802 - mean_absolute_error: 7.5675 - mean_squared_error: 244.3872 - _pinball_loss: 0.8802 - val_loss: 1.1206 - val_mean_absolute_error: 9.2136 - val_mean_squared_error: 341.3442 - val__pinball_loss: 1.1206\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8741 - mean_absolute_error: 7.5154 - mean_squared_error: 242.9177 - _pinball_loss: 0.8741 - val_loss: 1.1078 - val_mean_absolute_error: 9.0435 - val_mean_squared_error: 331.3675 - val__pinball_loss: 1.1078\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8696 - mean_absolute_error: 7.4921 - mean_squared_error: 242.5721 - _pinball_loss: 0.8696 - val_loss: 1.0980 - val_mean_absolute_error: 8.8755 - val_mean_squared_error: 328.5473 - val__pinball_loss: 1.0980\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8665 - mean_absolute_error: 7.4692 - mean_squared_error: 242.3912 - _pinball_loss: 0.8665 - val_loss: 1.1078 - val_mean_absolute_error: 9.0184 - val_mean_squared_error: 331.3114 - val__pinball_loss: 1.1078\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8598 - mean_absolute_error: 7.4265 - mean_squared_error: 241.5795 - _pinball_loss: 0.8598 - val_loss: 1.0991 - val_mean_absolute_error: 8.9380 - val_mean_squared_error: 333.4411 - val__pinball_loss: 1.0991\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8554 - mean_absolute_error: 7.3856 - mean_squared_error: 240.2867 - _pinball_loss: 0.8554 - val_loss: 1.1060 - val_mean_absolute_error: 8.9200 - val_mean_squared_error: 331.3330 - val__pinball_loss: 1.1060\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8518 - mean_absolute_error: 7.3741 - mean_squared_error: 240.5087 - _pinball_loss: 0.8518 - val_loss: 1.0887 - val_mean_absolute_error: 8.9703 - val_mean_squared_error: 334.3612 - val__pinball_loss: 1.0887\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8474 - mean_absolute_error: 7.3495 - mean_squared_error: 240.2089 - _pinball_loss: 0.8474 - val_loss: 1.0850 - val_mean_absolute_error: 9.0452 - val_mean_squared_error: 336.5927 - val__pinball_loss: 1.0850\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8429 - mean_absolute_error: 7.3280 - mean_squared_error: 239.9447 - _pinball_loss: 0.8429 - val_loss: 1.1117 - val_mean_absolute_error: 8.8253 - val_mean_squared_error: 325.5681 - val__pinball_loss: 1.1117\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8410 - mean_absolute_error: 7.3023 - mean_squared_error: 238.9505 - _pinball_loss: 0.8410 - val_loss: 1.0820 - val_mean_absolute_error: 9.0956 - val_mean_squared_error: 337.8156 - val__pinball_loss: 1.0820\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8389 - mean_absolute_error: 7.2995 - mean_squared_error: 239.4326 - _pinball_loss: 0.8389 - val_loss: 1.0852 - val_mean_absolute_error: 9.0873 - val_mean_squared_error: 337.8184 - val__pinball_loss: 1.0852\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8360 - mean_absolute_error: 7.2819 - mean_squared_error: 238.8984 - _pinball_loss: 0.8360 - val_loss: 1.0765 - val_mean_absolute_error: 9.0413 - val_mean_squared_error: 340.3001 - val__pinball_loss: 1.0765\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8325 - mean_absolute_error: 7.2572 - mean_squared_error: 238.6649 - _pinball_loss: 0.8325 - val_loss: 1.0910 - val_mean_absolute_error: 8.6635 - val_mean_squared_error: 325.9036 - val__pinball_loss: 1.0910\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8302 - mean_absolute_error: 7.2391 - mean_squared_error: 237.9287 - _pinball_loss: 0.8302 - val_loss: 1.0767 - val_mean_absolute_error: 8.7193 - val_mean_squared_error: 326.3729 - val__pinball_loss: 1.0767\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8294 - mean_absolute_error: 7.2429 - mean_squared_error: 238.3844 - _pinball_loss: 0.8294 - val_loss: 1.0768 - val_mean_absolute_error: 8.7363 - val_mean_squared_error: 325.9493 - val__pinball_loss: 1.0768\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8245 - mean_absolute_error: 7.2063 - mean_squared_error: 237.3308 - _pinball_loss: 0.8245 - val_loss: 1.0908 - val_mean_absolute_error: 8.9402 - val_mean_squared_error: 333.3008 - val__pinball_loss: 1.0908\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 10s 9ms/step - loss: 0.8243 - mean_absolute_error: 7.2057 - mean_squared_error: 237.3063 - _pinball_loss: 0.8243 - val_loss: 1.0903 - val_mean_absolute_error: 8.6425 - val_mean_squared_error: 322.0850 - val__pinball_loss: 1.0903\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017692015438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "from src.model.multiple_output.convolution import ConvolutionVarious\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS * 1,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * 1)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various = ConvolutionVarious(48)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various, one_days_window_label_columns, q)\n",
    "    evaluate_dict[q] = conv_various.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 7)\n",
    "    pred_y = conv_various.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "to_submission_csv(submission_df, \"conv_various_dhi_dni_ghi_standard_scaled_n_minmaxed_zero_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2740258693695068"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "r = 0.1\n",
    "for index, value in evaluate_dict.items():\n",
    "    s += value[0]\n",
    "    r += .1\n",
    "s / 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.036854</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>-0.038514</td>\n",
       "      <td>-0.031595</td>\n",
       "      <td>0.052430</td>\n",
       "      <td>-0.042618</td>\n",
       "      <td>-0.043031</td>\n",
       "      <td>0.099883</td>\n",
       "      <td>0.089826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>-0.025153</td>\n",
       "      <td>-0.013342</td>\n",
       "      <td>0.015868</td>\n",
       "      <td>-0.031941</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>-0.004643</td>\n",
       "      <td>0.124043</td>\n",
       "      <td>-0.010582</td>\n",
       "      <td>0.101584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.038245</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>0.024491</td>\n",
       "      <td>0.111412</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.044517</td>\n",
       "      <td>-0.024220</td>\n",
       "      <td>0.362732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.028149</td>\n",
       "      <td>-0.021281</td>\n",
       "      <td>-0.010313</td>\n",
       "      <td>-0.034961</td>\n",
       "      <td>0.065999</td>\n",
       "      <td>-0.017749</td>\n",
       "      <td>0.174484</td>\n",
       "      <td>0.092974</td>\n",
       "      <td>0.628838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>-0.035426</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>-0.041857</td>\n",
       "      <td>-0.025774</td>\n",
       "      <td>0.129988</td>\n",
       "      <td>0.064149</td>\n",
       "      <td>0.131346</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.799641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>-0.228636</td>\n",
       "      <td>-0.087524</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.135374</td>\n",
       "      <td>-0.090930</td>\n",
       "      <td>-0.115872</td>\n",
       "      <td>0.293979</td>\n",
       "      <td>-0.157742</td>\n",
       "      <td>-0.340676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>-0.030693</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.092182</td>\n",
       "      <td>-0.230004</td>\n",
       "      <td>0.097128</td>\n",
       "      <td>-0.103232</td>\n",
       "      <td>0.122087</td>\n",
       "      <td>0.269507</td>\n",
       "      <td>0.411329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>-0.053651</td>\n",
       "      <td>-0.089856</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>-0.140243</td>\n",
       "      <td>0.276680</td>\n",
       "      <td>-0.260293</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.189809</td>\n",
       "      <td>-0.144519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>-0.071637</td>\n",
       "      <td>-0.046387</td>\n",
       "      <td>-0.048091</td>\n",
       "      <td>-0.134190</td>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.084310</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.112328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>-0.090756</td>\n",
       "      <td>-0.034882</td>\n",
       "      <td>-0.034859</td>\n",
       "      <td>-0.044475</td>\n",
       "      <td>0.159490</td>\n",
       "      <td>-0.169261</td>\n",
       "      <td>-0.058044</td>\n",
       "      <td>0.275128</td>\n",
       "      <td>0.032835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     q_0.1     q_0.2     q_0.3     q_0.4     q_0.5  \\\n",
       "0       0.csv_Day7_0h00m -0.036854  0.010802 -0.038514 -0.031595  0.052430   \n",
       "1       0.csv_Day7_0h30m -0.025153 -0.013342  0.015868 -0.031941  0.082701   \n",
       "2       0.csv_Day7_1h00m -0.038245 -0.006583 -0.018621  0.024491  0.111412   \n",
       "3       0.csv_Day7_1h30m -0.028149 -0.021281 -0.010313 -0.034961  0.065999   \n",
       "4       0.csv_Day7_2h00m -0.035426 -0.004872 -0.041857 -0.025774  0.129988   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "7771  80.csv_Day8_21h30m -0.228636 -0.087524  0.001333 -0.135374 -0.090930   \n",
       "7772  80.csv_Day8_22h00m -0.030693 -0.049850 -0.092182 -0.230004  0.097128   \n",
       "7773  80.csv_Day8_22h30m -0.053651 -0.089856  0.032349 -0.140243  0.276680   \n",
       "7774  80.csv_Day8_23h00m -0.071637 -0.046387 -0.048091 -0.134190  0.341226   \n",
       "7775  80.csv_Day8_23h30m -0.090756 -0.034882 -0.034859 -0.044475  0.159490   \n",
       "\n",
       "         q_0.6     q_0.7     q_0.8     q_0.9  \n",
       "0    -0.042618 -0.043031  0.099883  0.089826  \n",
       "1    -0.004643  0.124043 -0.010582  0.101584  \n",
       "2     0.073612  0.044517 -0.024220  0.362732  \n",
       "3    -0.017749  0.174484  0.092974  0.628838  \n",
       "4     0.064149  0.131346  0.044643  0.799641  \n",
       "...        ...       ...       ...       ...  \n",
       "7771 -0.115872  0.293979 -0.157742 -0.340676  \n",
       "7772 -0.103232  0.122087  0.269507  0.411329  \n",
       "7773 -0.260293  0.007408  0.189809 -0.144519  \n",
       "7774  0.084310 -0.003148  0.214436  0.112328  \n",
       "7775 -0.169261 -0.058044  0.275128  0.032835  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "submission_df.to_csv('conv_various_using_dhi_dni_ghi_standard_scaled_n_minmaxed.csv', index=False)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 0] = 0\n",
    "submission_df\n",
    "submission_df.to_csv('conv_various_using_dhi_dni_ghi_standard_scaled_n_minmaxed_zero.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 1] = 0\n",
    "submission_df\n",
    "submission_df.to_csv('conv_various_using_dhi_dni_ghi_standard_scaled_n_minmaxed_less_than_one_zero.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7858011722564697, 3.5716018676757812, 78.81475067138672, 1.7854149341583252]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_various.evaluate(one_days_window_label_columns.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7903892993927002, 3.580777645111084, 79.85618591308594, 1.7906612157821655]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_various.evaluate(one_days_window_label_columns.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.884\n",
    "\n",
    "class ConvolutionVarious(tf.keras.Model):\n",
    "    name = \"Convolution_various\"\n",
    "\n",
    "    def __init__(self, conv_width):\n",
    "        super().__init__()\n",
    "        self.conv1_input = tf.keras.layers.Lambda(lambda x: x[:, -conv_width:, :])\n",
    "        self.conv2_input = tf.keras.layers.Lambda(lambda x: x[:, -conv_width // 2:, :])\n",
    "        self.conv3_input = tf.keras.layers.Lambda(lambda x: x[:, -conv_width // 3:, :])\n",
    "        self.conv4_input = tf.keras.layers.Lambda(lambda x: x[:, -conv_width // 4:, :])\n",
    "        self.conv5_input = tf.keras.layers.Lambda(lambda x: x[:, -conv_width // 6:, :])\n",
    "        self.conv6_input = tf.keras.layers.Lambda(lambda x: x[:, -conv_width // 48:, :])\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(32, kernel_size=conv_width, activation=\"relu\")\n",
    "        self.conv2 = tf.keras.layers.Conv1D(64, kernel_size=conv_width // 2, activation=\"relu\")\n",
    "        self.conv3 = tf.keras.layers.Conv1D(128, kernel_size=conv_width // 3, activation=\"relu\")\n",
    "        self.conv4 = tf.keras.layers.Conv1D(256, kernel_size=conv_width // 4, activation=\"relu\")\n",
    "        self.conv5 = tf.keras.layers.Conv1D(512, kernel_size=conv_width // 6, activation=\"relu\")\n",
    "        self.conv6 = tf.keras.layers.Conv1D(1024, kernel_size=conv_width // 48, activation=\"relu\")\n",
    "\n",
    "        self.conv1_1 = tf.keras.layers.Conv1D(8, kernel_size=1, activation=\"relu\")\n",
    "        self.conv2_1 = tf.keras.layers.Conv1D(8, kernel_size=1, activation=\"relu\")\n",
    "        self.conv3_1 = tf.keras.layers.Conv1D(16, kernel_size=1, activation=\"relu\")\n",
    "        self.conv4_1 = tf.keras.layers.Conv1D(16, kernel_size=1, activation=\"relu\")\n",
    "        self.conv5_1 = tf.keras.layers.Conv1D(32, kernel_size=1, activation=\"relu\")\n",
    "        self.conv6_1 = tf.keras.layers.Conv1D(32, kernel_size=1, activation=\"relu\")\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation=\"relu\")\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation=\"relu\")\n",
    "        self.dense3 = tf.keras.layers.Dense(96)\n",
    "        self.output_layer = tf.keras.layers.Reshape([96, 1])\n",
    "\n",
    "    def get_config(self):\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        conv1_model = self.conv1_1(self.conv1(self.conv1_input(inputs)))\n",
    "        conv2_model = self.conv2_1(self.conv2(self.conv2_input(inputs)))\n",
    "        conv3_model = self.conv3_1(self.conv3(self.conv3_input(inputs)))\n",
    "        conv4_model = self.conv4_1(self.conv4(self.conv4_input(inputs)))\n",
    "        conv5_model = self.conv5_1(self.conv5(self.conv5_input(inputs)))\n",
    "        conv6_model = self.conv6_1(self.conv6(self.conv6_input(inputs)))\n",
    "\n",
    "        net = tf.concat(axis=2, values=[conv1_model, conv2_model, conv3_model, conv4_model, conv5_model, conv6_model])\n",
    "        # net = self.dense1(net)\n",
    "        # net = self.dense2(net)\n",
    "        net = self.dense3(net)\n",
    "        return self.output_layer(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n",
      "0.1\n",
      "Epoch 1/1000\n",
      " 882/1146 [======================>.......] - ETA: 11s - loss: 1.5332 - mean_absolute_error: 13.9818 - mean_squared_error: 627.9276 - _pinball_loss: 1.5332"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-21612e674834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mconv_various2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolutionVarious2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mcompile_and_fit_with_pinball_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_various2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_days_window_label_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mevaluate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_various2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_days_window_label_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mpredict_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\dacon\\235680\\src\\trainers.py\u001b[0m in \u001b[0;36mcompile_and_fit_with_pinball_loss\u001b[1;34m(model, window, tau, patience)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     history = model.fit(\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "from src.model.multiple_output.convolution import ConvolutionVarious2\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "ONE_DAY_STEPS=48\n",
    "OUTPUT_STEPS=96\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS * 1,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * 1)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various2 = ConvolutionVarious2(48)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various2, one_days_window_label_columns, q)\n",
    "    evaluate_dict[q] = conv_various2.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 7)\n",
    "    pred_y = conv_various2.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "to_submission_csv(submission_df, \"conv_various_2_dhi_dni_ghi_standard_scaled_n_minmaxed_zero.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for index, value in evaluate_dict.items():\n",
    "    s += value[0]\n",
    "s / 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 1] = 0\n",
    "\n",
    "submission_df.to_csv('conv_various_2_using_dhi_dni_ghi_standard_scaled_n_minmaxed_zero_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"id\"] = load_submission_data()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>11.307079</td>\n",
       "      <td>11.288815</td>\n",
       "      <td>14.866284</td>\n",
       "      <td>22.087120</td>\n",
       "      <td>25.393457</td>\n",
       "      <td>33.487309</td>\n",
       "      <td>35.476055</td>\n",
       "      <td>38.118912</td>\n",
       "      <td>47.152512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>13.890485</td>\n",
       "      <td>13.614605</td>\n",
       "      <td>20.065573</td>\n",
       "      <td>26.062469</td>\n",
       "      <td>31.128191</td>\n",
       "      <td>39.822842</td>\n",
       "      <td>39.730099</td>\n",
       "      <td>43.213524</td>\n",
       "      <td>52.196568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>15.178850</td>\n",
       "      <td>16.706284</td>\n",
       "      <td>23.726070</td>\n",
       "      <td>30.328596</td>\n",
       "      <td>35.015965</td>\n",
       "      <td>45.558025</td>\n",
       "      <td>42.415730</td>\n",
       "      <td>47.456474</td>\n",
       "      <td>55.467335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>16.674799</td>\n",
       "      <td>19.862972</td>\n",
       "      <td>26.165211</td>\n",
       "      <td>33.370464</td>\n",
       "      <td>36.937675</td>\n",
       "      <td>48.287983</td>\n",
       "      <td>45.186161</td>\n",
       "      <td>50.209465</td>\n",
       "      <td>56.676674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>16.484295</td>\n",
       "      <td>22.498001</td>\n",
       "      <td>26.015776</td>\n",
       "      <td>34.283318</td>\n",
       "      <td>37.366302</td>\n",
       "      <td>50.602711</td>\n",
       "      <td>47.174088</td>\n",
       "      <td>51.602558</td>\n",
       "      <td>58.138706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>16.075537</td>\n",
       "      <td>24.332014</td>\n",
       "      <td>25.893290</td>\n",
       "      <td>34.068066</td>\n",
       "      <td>36.912647</td>\n",
       "      <td>50.481903</td>\n",
       "      <td>47.958691</td>\n",
       "      <td>52.212326</td>\n",
       "      <td>57.962219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>13.457237</td>\n",
       "      <td>21.882736</td>\n",
       "      <td>24.826523</td>\n",
       "      <td>30.973543</td>\n",
       "      <td>34.812698</td>\n",
       "      <td>48.782070</td>\n",
       "      <td>47.454288</td>\n",
       "      <td>50.487946</td>\n",
       "      <td>56.962021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>10.798873</td>\n",
       "      <td>18.145102</td>\n",
       "      <td>23.966486</td>\n",
       "      <td>28.190048</td>\n",
       "      <td>32.821251</td>\n",
       "      <td>44.015007</td>\n",
       "      <td>44.150204</td>\n",
       "      <td>46.081936</td>\n",
       "      <td>51.935276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>8.501832</td>\n",
       "      <td>14.854031</td>\n",
       "      <td>21.054136</td>\n",
       "      <td>24.827868</td>\n",
       "      <td>30.972931</td>\n",
       "      <td>38.818119</td>\n",
       "      <td>41.102180</td>\n",
       "      <td>40.266037</td>\n",
       "      <td>44.546825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>6.933465</td>\n",
       "      <td>12.814746</td>\n",
       "      <td>16.790699</td>\n",
       "      <td>21.427341</td>\n",
       "      <td>26.813631</td>\n",
       "      <td>31.886116</td>\n",
       "      <td>35.903702</td>\n",
       "      <td>32.919704</td>\n",
       "      <td>38.240013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>4.511205</td>\n",
       "      <td>8.069866</td>\n",
       "      <td>12.129279</td>\n",
       "      <td>16.801497</td>\n",
       "      <td>20.829777</td>\n",
       "      <td>24.470032</td>\n",
       "      <td>28.420780</td>\n",
       "      <td>24.936825</td>\n",
       "      <td>30.087803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>2.455029</td>\n",
       "      <td>4.024774</td>\n",
       "      <td>7.311005</td>\n",
       "      <td>12.356425</td>\n",
       "      <td>13.812083</td>\n",
       "      <td>16.285749</td>\n",
       "      <td>20.295395</td>\n",
       "      <td>17.725584</td>\n",
       "      <td>21.819641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>0.720381</td>\n",
       "      <td>1.316447</td>\n",
       "      <td>3.605329</td>\n",
       "      <td>7.457045</td>\n",
       "      <td>7.308154</td>\n",
       "      <td>9.097566</td>\n",
       "      <td>11.974711</td>\n",
       "      <td>10.841726</td>\n",
       "      <td>14.226097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>0.282430</td>\n",
       "      <td>0.587135</td>\n",
       "      <td>1.310024</td>\n",
       "      <td>3.656383</td>\n",
       "      <td>2.889556</td>\n",
       "      <td>4.695824</td>\n",
       "      <td>6.924719</td>\n",
       "      <td>4.925178</td>\n",
       "      <td>8.832342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "20  0.csv_Day7_10h00m  11.307079  11.288815  14.866284  22.087120  25.393457   \n",
       "21  0.csv_Day7_10h30m  13.890485  13.614605  20.065573  26.062469  31.128191   \n",
       "22  0.csv_Day7_11h00m  15.178850  16.706284  23.726070  30.328596  35.015965   \n",
       "23  0.csv_Day7_11h30m  16.674799  19.862972  26.165211  33.370464  36.937675   \n",
       "24  0.csv_Day7_12h00m  16.484295  22.498001  26.015776  34.283318  37.366302   \n",
       "25  0.csv_Day7_12h30m  16.075537  24.332014  25.893290  34.068066  36.912647   \n",
       "26  0.csv_Day7_13h00m  13.457237  21.882736  24.826523  30.973543  34.812698   \n",
       "27  0.csv_Day7_13h30m  10.798873  18.145102  23.966486  28.190048  32.821251   \n",
       "28  0.csv_Day7_14h00m   8.501832  14.854031  21.054136  24.827868  30.972931   \n",
       "29  0.csv_Day7_14h30m   6.933465  12.814746  16.790699  21.427341  26.813631   \n",
       "30  0.csv_Day7_15h00m   4.511205   8.069866  12.129279  16.801497  20.829777   \n",
       "31  0.csv_Day7_15h30m   2.455029   4.024774   7.311005  12.356425  13.812083   \n",
       "32  0.csv_Day7_16h00m   0.720381   1.316447   3.605329   7.457045   7.308154   \n",
       "33  0.csv_Day7_16h30m   0.282430   0.587135   1.310024   3.656383   2.889556   \n",
       "34  0.csv_Day7_17h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "20  33.487309  35.476055  38.118912  47.152512  \n",
       "21  39.822842  39.730099  43.213524  52.196568  \n",
       "22  45.558025  42.415730  47.456474  55.467335  \n",
       "23  48.287983  45.186161  50.209465  56.676674  \n",
       "24  50.602711  47.174088  51.602558  58.138706  \n",
       "25  50.481903  47.958691  52.212326  57.962219  \n",
       "26  48.782070  47.454288  50.487946  56.962021  \n",
       "27  44.015007  44.150204  46.081936  51.935276  \n",
       "28  38.818119  41.102180  40.266037  44.546825  \n",
       "29  31.886116  35.903702  32.919704  38.240013  \n",
       "30  24.470032  28.420780  24.936825  30.087803  \n",
       "31  16.285749  20.295395  17.725584  21.819641  \n",
       "32   9.097566  11.974711  10.841726  14.226097  \n",
       "33   4.695824   6.924719   4.925178   8.832342  \n",
       "34   0.000000   0.000000   0.000000   0.000000  \n",
       "35   0.000000   0.000000   0.000000   0.000000  \n",
       "36   0.000000   0.000000   0.000000   0.000000  \n",
       "37   0.000000   0.000000   0.000000   0.000000  \n",
       "38   0.000000   0.000000   0.000000   0.000000  \n",
       "39   0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('conv_various_2_using_dhi_dni_ghi_standard_scaled_n_minmaxed_zero_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 7 of dimension 2 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c9ca7a9becf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_days_window_label_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PycharmProjects\\dacon\\235680\\src\\loaders\\window_generator.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, model, plot_col, max_subplots)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{plot_col} [normed]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             plt.plot(self.input_indices, inputs[6 * n, :, plot_col_index],\n\u001b[0m\u001b[0;32m    111\u001b[0m                      label=\"Inputs\", marker=\".\", zorder=-10)\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1217\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10444\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10445\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10446\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10447\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10448\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index 7 of dimension 2 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_days_window_label_columns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n",
      "0.1\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 9s 7ms/step - loss: 1.6023 - mean_absolute_error: 15.1125 - mean_squared_error: 732.7265 - _pinball_loss: 1.6023 - val_loss: 1.7672 - val_mean_absolute_error: 14.7931 - val_mean_squared_error: 616.4991 - val__pinball_loss: 1.7672\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3809 - mean_absolute_error: 11.6673 - mean_squared_error: 441.1002 - _pinball_loss: 1.3809 - val_loss: 1.7444 - val_mean_absolute_error: 14.6703 - val_mean_squared_error: 616.3423 - val__pinball_loss: 1.7444\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3619 - mean_absolute_error: 11.4212 - mean_squared_error: 429.3500 - _pinball_loss: 1.3619 - val_loss: 1.7326 - val_mean_absolute_error: 14.5209 - val_mean_squared_error: 609.3027 - val__pinball_loss: 1.7326\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3533 - mean_absolute_error: 11.3326 - mean_squared_error: 426.5339 - _pinball_loss: 1.3533 - val_loss: 1.7275 - val_mean_absolute_error: 14.3352 - val_mean_squared_error: 597.1745 - val__pinball_loss: 1.7275\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3471 - mean_absolute_error: 11.2440 - mean_squared_error: 422.2520 - _pinball_loss: 1.3471 - val_loss: 1.7248 - val_mean_absolute_error: 14.2495 - val_mean_squared_error: 591.9500 - val__pinball_loss: 1.7248\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3433 - mean_absolute_error: 11.1954 - mean_squared_error: 420.7825 - _pinball_loss: 1.3433 - val_loss: 1.7240 - val_mean_absolute_error: 14.3923 - val_mean_squared_error: 604.1091 - val__pinball_loss: 1.7240\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3393 - mean_absolute_error: 11.1744 - mean_squared_error: 420.1492 - _pinball_loss: 1.3393 - val_loss: 1.7211 - val_mean_absolute_error: 14.1642 - val_mean_squared_error: 590.4042 - val__pinball_loss: 1.7211\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3369 - mean_absolute_error: 11.1383 - mean_squared_error: 418.5453 - _pinball_loss: 1.3369 - val_loss: 1.7215 - val_mean_absolute_error: 14.1518 - val_mean_squared_error: 588.4031 - val__pinball_loss: 1.7215\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3345 - mean_absolute_error: 11.1062 - mean_squared_error: 417.1351 - _pinball_loss: 1.3345 - val_loss: 1.7186 - val_mean_absolute_error: 14.0466 - val_mean_squared_error: 582.6079 - val__pinball_loss: 1.7186\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3322 - mean_absolute_error: 11.0811 - mean_squared_error: 416.0601 - _pinball_loss: 1.3322 - val_loss: 1.7198 - val_mean_absolute_error: 14.0719 - val_mean_squared_error: 584.6621 - val__pinball_loss: 1.7198\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3303 - mean_absolute_error: 11.0647 - mean_squared_error: 415.2761 - _pinball_loss: 1.3303 - val_loss: 1.7183 - val_mean_absolute_error: 14.2002 - val_mean_squared_error: 594.6618 - val__pinball_loss: 1.7183\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3288 - mean_absolute_error: 11.0670 - mean_squared_error: 415.7774 - _pinball_loss: 1.3288 - val_loss: 1.7196 - val_mean_absolute_error: 14.3262 - val_mean_squared_error: 602.5865 - val__pinball_loss: 1.7196\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3264 - mean_absolute_error: 11.0400 - mean_squared_error: 414.3221 - _pinball_loss: 1.3264 - val_loss: 1.7185 - val_mean_absolute_error: 14.2517 - val_mean_squared_error: 599.0848 - val__pinball_loss: 1.7185\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3249 - mean_absolute_error: 11.0084 - mean_squared_error: 412.4858 - _pinball_loss: 1.3249 - val_loss: 1.7179 - val_mean_absolute_error: 14.0939 - val_mean_squared_error: 588.8843 - val__pinball_loss: 1.7179\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3232 - mean_absolute_error: 10.9777 - mean_squared_error: 410.7695 - _pinball_loss: 1.3232 - val_loss: 1.7211 - val_mean_absolute_error: 14.2061 - val_mean_squared_error: 594.7479 - val__pinball_loss: 1.7211\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3227 - mean_absolute_error: 10.9787 - mean_squared_error: 411.0929 - _pinball_loss: 1.3227 - val_loss: 1.7192 - val_mean_absolute_error: 14.0285 - val_mean_squared_error: 583.4931 - val__pinball_loss: 1.7192\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3208 - mean_absolute_error: 10.9606 - mean_squared_error: 410.2194 - _pinball_loss: 1.3208 - val_loss: 1.7209 - val_mean_absolute_error: 14.2772 - val_mean_squared_error: 601.7167 - val__pinball_loss: 1.7209\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3182 - mean_absolute_error: 10.9528 - mean_squared_error: 410.2871 - _pinball_loss: 1.3182 - val_loss: 1.7214 - val_mean_absolute_error: 14.1240 - val_mean_squared_error: 590.4717 - val__pinball_loss: 1.7214\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3170 - mean_absolute_error: 10.9273 - mean_squared_error: 408.7494 - _pinball_loss: 1.3170 - val_loss: 1.7211 - val_mean_absolute_error: 13.9887 - val_mean_squared_error: 580.6801 - val__pinball_loss: 1.7211\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023CE0ACF8B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.2\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 9s 7ms/step - loss: 2.8061 - mean_absolute_error: 12.3300 - mean_squared_error: 513.0121 - _pinball_loss: 2.8061 - val_loss: 2.9046 - val_mean_absolute_error: 11.2477 - val_mean_squared_error: 363.6333 - val__pinball_loss: 2.9046\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.2712 - mean_absolute_error: 8.6130 - mean_squared_error: 245.4837 - _pinball_loss: 2.2712 - val_loss: 2.8499 - val_mean_absolute_error: 10.7763 - val_mean_squared_error: 347.3947 - val__pinball_loss: 2.8499\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.2314 - mean_absolute_error: 8.3892 - mean_squared_error: 239.1639 - _pinball_loss: 2.2314 - val_loss: 2.8275 - val_mean_absolute_error: 10.5734 - val_mean_squared_error: 341.2182 - val__pinball_loss: 2.8275\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.2134 - mean_absolute_error: 8.2879 - mean_squared_error: 236.2472 - _pinball_loss: 2.2134 - val_loss: 2.8183 - val_mean_absolute_error: 10.5512 - val_mean_squared_error: 343.2025 - val__pinball_loss: 2.8183\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.2005 - mean_absolute_error: 8.2274 - mean_squared_error: 234.7432 - _pinball_loss: 2.2005 - val_loss: 2.8231 - val_mean_absolute_error: 10.6466 - val_mean_squared_error: 346.5307 - val__pinball_loss: 2.8231\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1912 - mean_absolute_error: 8.1895 - mean_squared_error: 233.7107 - _pinball_loss: 2.1912 - val_loss: 2.8115 - val_mean_absolute_error: 10.6804 - val_mean_squared_error: 350.1450 - val__pinball_loss: 2.8115\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1854 - mean_absolute_error: 8.1616 - mean_squared_error: 233.0678 - _pinball_loss: 2.1854 - val_loss: 2.8019 - val_mean_absolute_error: 10.5437 - val_mean_squared_error: 342.1666 - val__pinball_loss: 2.8019\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1783 - mean_absolute_error: 8.1215 - mean_squared_error: 231.9326 - _pinball_loss: 2.1783 - val_loss: 2.8024 - val_mean_absolute_error: 10.6426 - val_mean_squared_error: 349.1172 - val__pinball_loss: 2.8024\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1711 - mean_absolute_error: 8.0914 - mean_squared_error: 230.9928 - _pinball_loss: 2.1711 - val_loss: 2.8018 - val_mean_absolute_error: 10.7416 - val_mean_squared_error: 353.9886 - val__pinball_loss: 2.8018\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1686 - mean_absolute_error: 8.0668 - mean_squared_error: 229.9846 - _pinball_loss: 2.1686 - val_loss: 2.7926 - val_mean_absolute_error: 10.5328 - val_mean_squared_error: 343.0084 - val__pinball_loss: 2.7926\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1627 - mean_absolute_error: 8.0474 - mean_squared_error: 229.2721 - _pinball_loss: 2.1627 - val_loss: 2.7913 - val_mean_absolute_error: 10.4132 - val_mean_squared_error: 339.7562 - val__pinball_loss: 2.7913\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1595 - mean_absolute_error: 8.0163 - mean_squared_error: 228.0888 - _pinball_loss: 2.1595 - val_loss: 2.7935 - val_mean_absolute_error: 10.6203 - val_mean_squared_error: 350.9916 - val__pinball_loss: 2.7935\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1551 - mean_absolute_error: 8.0086 - mean_squared_error: 228.1068 - _pinball_loss: 2.1551 - val_loss: 2.7877 - val_mean_absolute_error: 10.5510 - val_mean_squared_error: 346.1575 - val__pinball_loss: 2.7877\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.1537 - mean_absolute_error: 8.0139 - mean_squared_error: 228.5233 - _pinball_loss: 2.1537 - val_loss: 2.7898 - val_mean_absolute_error: 10.5999 - val_mean_squared_error: 349.3120 - val__pinball_loss: 2.7898\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.1517 - mean_absolute_error: 7.9884 - mean_squared_error: 227.2332 - _pinball_loss: 2.1517 - val_loss: 2.7879 - val_mean_absolute_error: 10.5570 - val_mean_squared_error: 346.7682 - val__pinball_loss: 2.7879\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.1450 - mean_absolute_error: 7.9709 - mean_squared_error: 226.9174 - _pinball_loss: 2.1450 - val_loss: 2.7825 - val_mean_absolute_error: 10.3960 - val_mean_squared_error: 338.2493 - val__pinball_loss: 2.7825\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1421 - mean_absolute_error: 7.9492 - mean_squared_error: 225.7118 - _pinball_loss: 2.1421 - val_loss: 2.7911 - val_mean_absolute_error: 10.4464 - val_mean_squared_error: 340.6988 - val__pinball_loss: 2.7911\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1421 - mean_absolute_error: 7.9532 - mean_squared_error: 225.7837 - _pinball_loss: 2.1420 - val_loss: 2.7950 - val_mean_absolute_error: 10.6308 - val_mean_squared_error: 349.0306 - val__pinball_loss: 2.7950\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1403 - mean_absolute_error: 7.9529 - mean_squared_error: 225.9370 - _pinball_loss: 2.1403 - val_loss: 2.7892 - val_mean_absolute_error: 10.4944 - val_mean_squared_error: 345.0683 - val__pinball_loss: 2.7892\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1365 - mean_absolute_error: 7.9312 - mean_squared_error: 225.1070 - _pinball_loss: 2.1365 - val_loss: 2.7927 - val_mean_absolute_error: 10.5118 - val_mean_squared_error: 343.3953 - val__pinball_loss: 2.7927\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1361 - mean_absolute_error: 7.9319 - mean_squared_error: 224.8208 - _pinball_loss: 2.1361 - val_loss: 2.7922 - val_mean_absolute_error: 10.5773 - val_mean_squared_error: 348.0169 - val__pinball_loss: 2.7922\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023A765FFC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.3\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 3.6719 - mean_absolute_error: 10.5259 - mean_squared_error: 392.7875 - _pinball_loss: 3.6719 - val_loss: 3.5289 - val_mean_absolute_error: 8.8159 - val_mean_squared_error: 239.9454 - val__pinball_loss: 3.5289\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7529 - mean_absolute_error: 6.8535 - mean_squared_error: 163.3991 - _pinball_loss: 2.7529 - val_loss: 3.4573 - val_mean_absolute_error: 8.6564 - val_mean_squared_error: 236.8662 - val__pinball_loss: 3.4573\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6968 - mean_absolute_error: 6.6743 - mean_squared_error: 158.6598 - _pinball_loss: 2.6968 - val_loss: 3.4305 - val_mean_absolute_error: 8.5295 - val_mean_squared_error: 235.3384 - val__pinball_loss: 3.4305\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6668 - mean_absolute_error: 6.5733 - mean_squared_error: 156.2127 - _pinball_loss: 2.6668 - val_loss: 3.4097 - val_mean_absolute_error: 8.5127 - val_mean_squared_error: 235.3825 - val__pinball_loss: 3.4097\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6489 - mean_absolute_error: 6.5218 - mean_squared_error: 154.8835 - _pinball_loss: 2.6489 - val_loss: 3.4074 - val_mean_absolute_error: 8.3229 - val_mean_squared_error: 230.0038 - val__pinball_loss: 3.4074\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6365 - mean_absolute_error: 6.4739 - mean_squared_error: 153.5605 - _pinball_loss: 2.6365 - val_loss: 3.3809 - val_mean_absolute_error: 8.3184 - val_mean_squared_error: 228.4694 - val__pinball_loss: 3.3809\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6257 - mean_absolute_error: 6.4497 - mean_squared_error: 152.9395 - _pinball_loss: 2.6257 - val_loss: 3.3752 - val_mean_absolute_error: 8.4761 - val_mean_squared_error: 235.3443 - val__pinball_loss: 3.3752\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6138 - mean_absolute_error: 6.4056 - mean_squared_error: 151.7726 - _pinball_loss: 2.6138 - val_loss: 3.3733 - val_mean_absolute_error: 8.3338 - val_mean_squared_error: 231.6747 - val__pinball_loss: 3.3733\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6066 - mean_absolute_error: 6.3748 - mean_squared_error: 150.8819 - _pinball_loss: 2.6066 - val_loss: 3.3698 - val_mean_absolute_error: 8.2462 - val_mean_squared_error: 227.7596 - val__pinball_loss: 3.3698\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5987 - mean_absolute_error: 6.3567 - mean_squared_error: 150.2869 - _pinball_loss: 2.5987 - val_loss: 3.3714 - val_mean_absolute_error: 8.2752 - val_mean_squared_error: 229.5035 - val__pinball_loss: 3.3714\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5929 - mean_absolute_error: 6.3433 - mean_squared_error: 150.1050 - _pinball_loss: 2.5929 - val_loss: 3.3726 - val_mean_absolute_error: 8.1899 - val_mean_squared_error: 226.0803 - val__pinball_loss: 3.3726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5874 - mean_absolute_error: 6.3188 - mean_squared_error: 149.1146 - _pinball_loss: 2.5874 - val_loss: 3.3513 - val_mean_absolute_error: 8.1831 - val_mean_squared_error: 223.3263 - val__pinball_loss: 3.3513\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5818 - mean_absolute_error: 6.3040 - mean_squared_error: 148.7036 - _pinball_loss: 2.5818 - val_loss: 3.3605 - val_mean_absolute_error: 8.3414 - val_mean_squared_error: 231.8278 - val__pinball_loss: 3.3605\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5783 - mean_absolute_error: 6.2947 - mean_squared_error: 148.5581 - _pinball_loss: 2.5783 - val_loss: 3.3548 - val_mean_absolute_error: 8.1970 - val_mean_squared_error: 224.8898 - val__pinball_loss: 3.3548\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5738 - mean_absolute_error: 6.2810 - mean_squared_error: 148.1732 - _pinball_loss: 2.5738 - val_loss: 3.3529 - val_mean_absolute_error: 8.2482 - val_mean_squared_error: 228.5254 - val__pinball_loss: 3.3529\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5696 - mean_absolute_error: 6.2596 - mean_squared_error: 147.4628 - _pinball_loss: 2.5696 - val_loss: 3.3412 - val_mean_absolute_error: 8.1599 - val_mean_squared_error: 224.7027 - val__pinball_loss: 3.3412\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.5671 - mean_absolute_error: 6.2569 - mean_squared_error: 147.3250 - _pinball_loss: 2.5671 - val_loss: 3.3480 - val_mean_absolute_error: 8.1687 - val_mean_squared_error: 226.3565 - val__pinball_loss: 3.3480\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5611 - mean_absolute_error: 6.2391 - mean_squared_error: 146.6537 - _pinball_loss: 2.5611 - val_loss: 3.3499 - val_mean_absolute_error: 8.1667 - val_mean_squared_error: 226.2125 - val__pinball_loss: 3.3499\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5604 - mean_absolute_error: 6.2329 - mean_squared_error: 146.4770 - _pinball_loss: 2.5604 - val_loss: 3.3684 - val_mean_absolute_error: 8.0785 - val_mean_squared_error: 222.3894 - val__pinball_loss: 3.3684\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5561 - mean_absolute_error: 6.2203 - mean_squared_error: 146.2144 - _pinball_loss: 2.5561 - val_loss: 3.3524 - val_mean_absolute_error: 8.1617 - val_mean_squared_error: 226.7144 - val__pinball_loss: 3.3524\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5530 - mean_absolute_error: 6.2151 - mean_squared_error: 146.1257 - _pinball_loss: 2.5530 - val_loss: 3.3486 - val_mean_absolute_error: 8.2769 - val_mean_squared_error: 228.4295 - val__pinball_loss: 3.3486\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023A9BF11EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.4\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 4.1488 - mean_absolute_error: 9.2921 - mean_squared_error: 319.1963 - _pinball_loss: 4.1488 - val_loss: 3.7828 - val_mean_absolute_error: 7.7760 - val_mean_squared_error: 205.4117 - val__pinball_loss: 3.7828\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.9597 - mean_absolute_error: 6.0838 - mean_squared_error: 140.5970 - _pinball_loss: 2.9597 - val_loss: 3.6842 - val_mean_absolute_error: 7.4761 - val_mean_squared_error: 199.3223 - val__pinball_loss: 3.6842\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.8853 - mean_absolute_error: 5.8978 - mean_squared_error: 135.3827 - _pinball_loss: 2.8853 - val_loss: 3.6470 - val_mean_absolute_error: 7.3943 - val_mean_squared_error: 196.7648 - val__pinball_loss: 3.6470\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.8457 - mean_absolute_error: 5.7979 - mean_squared_error: 132.9098 - _pinball_loss: 2.8457 - val_loss: 3.6099 - val_mean_absolute_error: 7.3242 - val_mean_squared_error: 192.8519 - val__pinball_loss: 3.6099\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.8180 - mean_absolute_error: 5.7298 - mean_squared_error: 131.1560 - _pinball_loss: 2.8180 - val_loss: 3.6088 - val_mean_absolute_error: 7.2902 - val_mean_squared_error: 193.7512 - val__pinball_loss: 3.6088\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7993 - mean_absolute_error: 5.6856 - mean_squared_error: 129.9243 - _pinball_loss: 2.7993 - val_loss: 3.5836 - val_mean_absolute_error: 7.2600 - val_mean_squared_error: 191.4398 - val__pinball_loss: 3.5836\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.7840 - mean_absolute_error: 5.6481 - mean_squared_error: 128.9363 - _pinball_loss: 2.7840 - val_loss: 3.5846 - val_mean_absolute_error: 7.2803 - val_mean_squared_error: 192.7592 - val__pinball_loss: 3.5846\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7734 - mean_absolute_error: 5.6201 - mean_squared_error: 128.2866 - _pinball_loss: 2.7734 - val_loss: 3.5906 - val_mean_absolute_error: 7.1976 - val_mean_squared_error: 193.0577 - val__pinball_loss: 3.5906\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7641 - mean_absolute_error: 5.5995 - mean_squared_error: 127.6781 - _pinball_loss: 2.7641 - val_loss: 3.5689 - val_mean_absolute_error: 7.2124 - val_mean_squared_error: 190.8691 - val__pinball_loss: 3.5689\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7530 - mean_absolute_error: 5.5716 - mean_squared_error: 127.0318 - _pinball_loss: 2.7530 - val_loss: 3.5655 - val_mean_absolute_error: 7.2616 - val_mean_squared_error: 191.6508 - val__pinball_loss: 3.5655\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7464 - mean_absolute_error: 5.5554 - mean_squared_error: 126.7124 - _pinball_loss: 2.7464 - val_loss: 3.5517 - val_mean_absolute_error: 7.1835 - val_mean_squared_error: 189.8239 - val__pinball_loss: 3.5517\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7384 - mean_absolute_error: 5.5372 - mean_squared_error: 126.3194 - _pinball_loss: 2.7384 - val_loss: 3.5636 - val_mean_absolute_error: 7.2140 - val_mean_squared_error: 191.2648 - val__pinball_loss: 3.5636\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7312 - mean_absolute_error: 5.5153 - mean_squared_error: 125.8850 - _pinball_loss: 2.7312 - val_loss: 3.5410 - val_mean_absolute_error: 7.1678 - val_mean_squared_error: 188.9471 - val__pinball_loss: 3.5410\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7270 - mean_absolute_error: 5.5077 - mean_squared_error: 125.5983 - _pinball_loss: 2.7270 - val_loss: 3.5555 - val_mean_absolute_error: 7.1482 - val_mean_squared_error: 190.7072 - val__pinball_loss: 3.5555\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7195 - mean_absolute_error: 5.4890 - mean_squared_error: 125.2009 - _pinball_loss: 2.7195 - val_loss: 3.5446 - val_mean_absolute_error: 7.2018 - val_mean_squared_error: 189.3697 - val__pinball_loss: 3.5446\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7154 - mean_absolute_error: 5.4846 - mean_squared_error: 124.8954 - _pinball_loss: 2.7154 - val_loss: 3.5479 - val_mean_absolute_error: 7.1408 - val_mean_squared_error: 190.6842 - val__pinball_loss: 3.5479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7112 - mean_absolute_error: 5.4679 - mean_squared_error: 124.6215 - _pinball_loss: 2.7112 - val_loss: 3.5425 - val_mean_absolute_error: 7.1028 - val_mean_squared_error: 190.1966 - val__pinball_loss: 3.5425\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.7044 - mean_absolute_error: 5.4539 - mean_squared_error: 124.3415 - _pinball_loss: 2.7044 - val_loss: 3.5264 - val_mean_absolute_error: 7.0949 - val_mean_squared_error: 188.5066 - val__pinball_loss: 3.5264\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7002 - mean_absolute_error: 5.4477 - mean_squared_error: 123.9800 - _pinball_loss: 2.7002 - val_loss: 3.5352 - val_mean_absolute_error: 7.1345 - val_mean_squared_error: 189.8179 - val__pinball_loss: 3.5352\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6953 - mean_absolute_error: 5.4337 - mean_squared_error: 123.8758 - _pinball_loss: 2.6953 - val_loss: 3.5395 - val_mean_absolute_error: 7.1802 - val_mean_squared_error: 190.5676 - val__pinball_loss: 3.5395\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6933 - mean_absolute_error: 5.4286 - mean_squared_error: 123.6939 - _pinball_loss: 2.6933 - val_loss: 3.5277 - val_mean_absolute_error: 7.0920 - val_mean_squared_error: 188.1430 - val__pinball_loss: 3.5277\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6876 - mean_absolute_error: 5.4161 - mean_squared_error: 123.1803 - _pinball_loss: 2.6876 - val_loss: 3.5296 - val_mean_absolute_error: 7.1004 - val_mean_squared_error: 190.0592 - val__pinball_loss: 3.5296\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6843 - mean_absolute_error: 5.4091 - mean_squared_error: 123.1281 - _pinball_loss: 2.6843 - val_loss: 3.5290 - val_mean_absolute_error: 7.0610 - val_mean_squared_error: 189.3215 - val__pinball_loss: 3.5290\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023CCDA03C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.5\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 4.5887 - mean_absolute_error: 9.1775 - mean_squared_error: 306.5169 - _pinball_loss: 4.5887 - val_loss: 3.7391 - val_mean_absolute_error: 7.4783 - val_mean_squared_error: 213.1118 - val__pinball_loss: 3.7391\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.9314 - mean_absolute_error: 5.8629 - mean_squared_error: 143.0225 - _pinball_loss: 2.9314 - val_loss: 3.6136 - val_mean_absolute_error: 7.2271 - val_mean_squared_error: 204.3499 - val__pinball_loss: 3.6136\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.8321 - mean_absolute_error: 5.6643 - mean_squared_error: 138.9158 - _pinball_loss: 2.8321 - val_loss: 3.5428 - val_mean_absolute_error: 7.0856 - val_mean_squared_error: 201.3124 - val__pinball_loss: 3.5428\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7795 - mean_absolute_error: 5.5591 - mean_squared_error: 137.0740 - _pinball_loss: 2.7795 - val_loss: 3.5405 - val_mean_absolute_error: 7.0809 - val_mean_squared_error: 206.8728 - val__pinball_loss: 3.5405\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.7451 - mean_absolute_error: 5.4903 - mean_squared_error: 135.9308 - _pinball_loss: 2.7451 - val_loss: 3.5101 - val_mean_absolute_error: 7.0202 - val_mean_squared_error: 202.2749 - val__pinball_loss: 3.5101\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7182 - mean_absolute_error: 5.4363 - mean_squared_error: 134.7568 - _pinball_loss: 2.7182 - val_loss: 3.4952 - val_mean_absolute_error: 6.9905 - val_mean_squared_error: 203.7483 - val__pinball_loss: 3.4952\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.7025 - mean_absolute_error: 5.4049 - mean_squared_error: 134.2561 - _pinball_loss: 2.7025 - val_loss: 3.4730 - val_mean_absolute_error: 6.9459 - val_mean_squared_error: 202.5940 - val__pinball_loss: 3.4730\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 2.6869 - mean_absolute_error: 5.3737 - mean_squared_error: 133.3993 - _pinball_loss: 2.6869 - val_loss: 3.4609 - val_mean_absolute_error: 6.9218 - val_mean_squared_error: 200.2647 - val__pinball_loss: 3.4609\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6717 - mean_absolute_error: 5.3434 - mean_squared_error: 132.9585 - _pinball_loss: 2.6717 - val_loss: 3.4713 - val_mean_absolute_error: 6.9426 - val_mean_squared_error: 199.6370 - val__pinball_loss: 3.4713\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6631 - mean_absolute_error: 5.3262 - mean_squared_error: 132.6734 - _pinball_loss: 2.6631 - val_loss: 3.4644 - val_mean_absolute_error: 6.9287 - val_mean_squared_error: 202.6803 - val__pinball_loss: 3.4644\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.6560 - mean_absolute_error: 5.3121 - mean_squared_error: 132.3047 - _pinball_loss: 2.6560 - val_loss: 3.4471 - val_mean_absolute_error: 6.8943 - val_mean_squared_error: 200.1408 - val__pinball_loss: 3.4471\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6488 - mean_absolute_error: 5.2976 - mean_squared_error: 131.9252 - _pinball_loss: 2.6488 - val_loss: 3.4411 - val_mean_absolute_error: 6.8821 - val_mean_squared_error: 198.4467 - val__pinball_loss: 3.4411\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6374 - mean_absolute_error: 5.2748 - mean_squared_error: 131.1940 - _pinball_loss: 2.6374 - val_loss: 3.4334 - val_mean_absolute_error: 6.8667 - val_mean_squared_error: 197.8361 - val__pinball_loss: 3.4334\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6327 - mean_absolute_error: 5.2655 - mean_squared_error: 131.3285 - _pinball_loss: 2.6327 - val_loss: 3.4383 - val_mean_absolute_error: 6.8767 - val_mean_squared_error: 198.9429 - val__pinball_loss: 3.4383\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.6267 - mean_absolute_error: 5.2535 - mean_squared_error: 131.0347 - _pinball_loss: 2.6267 - val_loss: 3.4273 - val_mean_absolute_error: 6.8546 - val_mean_squared_error: 197.5013 - val__pinball_loss: 3.4273\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6204 - mean_absolute_error: 5.2408 - mean_squared_error: 130.6610 - _pinball_loss: 2.6204 - val_loss: 3.4179 - val_mean_absolute_error: 6.8358 - val_mean_squared_error: 197.4794 - val__pinball_loss: 3.4179\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.6150 - mean_absolute_error: 5.2300 - mean_squared_error: 130.4517 - _pinball_loss: 2.6150 - val_loss: 3.4217 - val_mean_absolute_error: 6.8435 - val_mean_squared_error: 198.7357 - val__pinball_loss: 3.4217\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6083 - mean_absolute_error: 5.2165 - mean_squared_error: 130.3110 - _pinball_loss: 2.6083 - val_loss: 3.4237 - val_mean_absolute_error: 6.8473 - val_mean_squared_error: 201.6013 - val__pinball_loss: 3.4237\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.6014 - mean_absolute_error: 5.2028 - mean_squared_error: 130.0544 - _pinball_loss: 2.6014 - val_loss: 3.4137 - val_mean_absolute_error: 6.8274 - val_mean_squared_error: 196.8938 - val__pinball_loss: 3.4137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5989 - mean_absolute_error: 5.1979 - mean_squared_error: 129.6918 - _pinball_loss: 2.5989 - val_loss: 3.4184 - val_mean_absolute_error: 6.8368 - val_mean_squared_error: 197.4608 - val__pinball_loss: 3.4184\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5955 - mean_absolute_error: 5.1910 - mean_squared_error: 129.8981 - _pinball_loss: 2.5955 - val_loss: 3.4162 - val_mean_absolute_error: 6.8324 - val_mean_squared_error: 196.5246 - val__pinball_loss: 3.4162\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5917 - mean_absolute_error: 5.1835 - mean_squared_error: 129.5972 - _pinball_loss: 2.5917 - val_loss: 3.4114 - val_mean_absolute_error: 6.8228 - val_mean_squared_error: 199.4383 - val__pinball_loss: 3.4114\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5862 - mean_absolute_error: 5.1724 - mean_squared_error: 129.5060 - _pinball_loss: 2.5862 - val_loss: 3.4238 - val_mean_absolute_error: 6.8476 - val_mean_squared_error: 202.5116 - val__pinball_loss: 3.4238\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5830 - mean_absolute_error: 5.1661 - mean_squared_error: 129.3375 - _pinball_loss: 2.5830 - val_loss: 3.4148 - val_mean_absolute_error: 6.8296 - val_mean_squared_error: 199.8371 - val__pinball_loss: 3.4148\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5837 - mean_absolute_error: 5.1674 - mean_squared_error: 129.3125 - _pinball_loss: 2.5837 - val_loss: 3.4077 - val_mean_absolute_error: 6.8153 - val_mean_squared_error: 199.6189 - val__pinball_loss: 3.4077\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5799 - mean_absolute_error: 5.1598 - mean_squared_error: 129.0260 - _pinball_loss: 2.5799 - val_loss: 3.4133 - val_mean_absolute_error: 6.8266 - val_mean_squared_error: 197.4792 - val__pinball_loss: 3.4133\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5744 - mean_absolute_error: 5.1487 - mean_squared_error: 128.8257 - _pinball_loss: 2.5744 - val_loss: 3.3999 - val_mean_absolute_error: 6.7998 - val_mean_squared_error: 197.9256 - val__pinball_loss: 3.3999\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5737 - mean_absolute_error: 5.1474 - mean_squared_error: 128.7787 - _pinball_loss: 2.5737 - val_loss: 3.4198 - val_mean_absolute_error: 6.8396 - val_mean_squared_error: 202.9738 - val__pinball_loss: 3.4198\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5682 - mean_absolute_error: 5.1363 - mean_squared_error: 128.4704 - _pinball_loss: 2.5682 - val_loss: 3.4082 - val_mean_absolute_error: 6.8164 - val_mean_squared_error: 199.6388 - val__pinball_loss: 3.4082\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5667 - mean_absolute_error: 5.1334 - mean_squared_error: 128.4622 - _pinball_loss: 2.5667 - val_loss: 3.4105 - val_mean_absolute_error: 6.8210 - val_mean_squared_error: 197.3584 - val__pinball_loss: 3.4105\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.5629 - mean_absolute_error: 5.1257 - mean_squared_error: 128.1919 - _pinball_loss: 2.5629 - val_loss: 3.4097 - val_mean_absolute_error: 6.8194 - val_mean_squared_error: 200.5433 - val__pinball_loss: 3.4097\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5628 - mean_absolute_error: 5.1257 - mean_squared_error: 128.1969 - _pinball_loss: 2.5628 - val_loss: 3.4111 - val_mean_absolute_error: 6.8223 - val_mean_squared_error: 196.2423 - val__pinball_loss: 3.4111\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023CCE01F9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.6\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 4.7413 - mean_absolute_error: 9.3675 - mean_squared_error: 305.7060 - _pinball_loss: 4.7413 - val_loss: 3.4880 - val_mean_absolute_error: 7.6533 - val_mean_squared_error: 229.3379 - val__pinball_loss: 3.4880\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.7521 - mean_absolute_error: 6.0809 - mean_squared_error: 161.2967 - _pinball_loss: 2.7521 - val_loss: 3.3213 - val_mean_absolute_error: 7.3469 - val_mean_squared_error: 224.2414 - val__pinball_loss: 3.3213\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.6230 - mean_absolute_error: 5.8506 - mean_squared_error: 157.3396 - _pinball_loss: 2.6230 - val_loss: 3.2599 - val_mean_absolute_error: 7.2040 - val_mean_squared_error: 217.5734 - val__pinball_loss: 3.2599\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.5607 - mean_absolute_error: 5.7420 - mean_squared_error: 156.1828 - _pinball_loss: 2.5607 - val_loss: 3.2179 - val_mean_absolute_error: 7.1674 - val_mean_squared_error: 221.1194 - val__pinball_loss: 3.2179\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.5203 - mean_absolute_error: 5.6688 - mean_squared_error: 155.3301 - _pinball_loss: 2.5203 - val_loss: 3.2012 - val_mean_absolute_error: 7.1353 - val_mean_squared_error: 219.1983 - val__pinball_loss: 3.2012\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.4974 - mean_absolute_error: 5.6249 - mean_squared_error: 154.5439 - _pinball_loss: 2.4974 - val_loss: 3.1773 - val_mean_absolute_error: 7.0837 - val_mean_squared_error: 218.8174 - val__pinball_loss: 3.1773\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.4758 - mean_absolute_error: 5.5888 - mean_squared_error: 154.3752 - _pinball_loss: 2.4758 - val_loss: 3.1672 - val_mean_absolute_error: 7.1408 - val_mean_squared_error: 224.9167 - val__pinball_loss: 3.1672\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.4577 - mean_absolute_error: 5.5574 - mean_squared_error: 154.1287 - _pinball_loss: 2.4577 - val_loss: 3.1729 - val_mean_absolute_error: 7.1531 - val_mean_squared_error: 225.2586 - val__pinball_loss: 3.1729\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.4427 - mean_absolute_error: 5.5271 - mean_squared_error: 153.6550 - _pinball_loss: 2.4427 - val_loss: 3.1336 - val_mean_absolute_error: 7.0718 - val_mean_squared_error: 225.6881 - val__pinball_loss: 3.1336\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.4291 - mean_absolute_error: 5.5020 - mean_squared_error: 153.3349 - _pinball_loss: 2.4291 - val_loss: 3.1335 - val_mean_absolute_error: 7.0708 - val_mean_squared_error: 224.0114 - val__pinball_loss: 3.1335\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.4225 - mean_absolute_error: 5.4915 - mean_squared_error: 153.3038 - _pinball_loss: 2.4225 - val_loss: 3.1324 - val_mean_absolute_error: 7.0384 - val_mean_squared_error: 222.2692 - val__pinball_loss: 3.1324\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.4144 - mean_absolute_error: 5.4761 - mean_squared_error: 152.8668 - _pinball_loss: 2.4144 - val_loss: 3.1284 - val_mean_absolute_error: 7.0863 - val_mean_squared_error: 226.4194 - val__pinball_loss: 3.1284\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.4037 - mean_absolute_error: 5.4594 - mean_squared_error: 153.0202 - _pinball_loss: 2.4037 - val_loss: 3.1165 - val_mean_absolute_error: 7.0272 - val_mean_squared_error: 222.6588 - val__pinball_loss: 3.1165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3975 - mean_absolute_error: 5.4474 - mean_squared_error: 152.7126 - _pinball_loss: 2.3975 - val_loss: 3.1071 - val_mean_absolute_error: 7.0181 - val_mean_squared_error: 225.0522 - val__pinball_loss: 3.1071\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3904 - mean_absolute_error: 5.4322 - mean_squared_error: 152.5533 - _pinball_loss: 2.3904 - val_loss: 3.1082 - val_mean_absolute_error: 7.0968 - val_mean_squared_error: 231.7474 - val__pinball_loss: 3.1082\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3819 - mean_absolute_error: 5.4178 - mean_squared_error: 152.2418 - _pinball_loss: 2.3819 - val_loss: 3.0978 - val_mean_absolute_error: 7.0306 - val_mean_squared_error: 227.1934 - val__pinball_loss: 3.0978\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3759 - mean_absolute_error: 5.4063 - mean_squared_error: 152.2488 - _pinball_loss: 2.3759 - val_loss: 3.0994 - val_mean_absolute_error: 6.9214 - val_mean_squared_error: 216.4903 - val__pinball_loss: 3.0994\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3724 - mean_absolute_error: 5.3993 - mean_squared_error: 152.1503 - _pinball_loss: 2.3724 - val_loss: 3.1027 - val_mean_absolute_error: 7.0420 - val_mean_squared_error: 226.6753 - val__pinball_loss: 3.1027\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3661 - mean_absolute_error: 5.3891 - mean_squared_error: 151.9299 - _pinball_loss: 2.3661 - val_loss: 3.0975 - val_mean_absolute_error: 6.9726 - val_mean_squared_error: 221.9640 - val__pinball_loss: 3.0975\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3628 - mean_absolute_error: 5.3813 - mean_squared_error: 151.7221 - _pinball_loss: 2.3628 - val_loss: 3.0997 - val_mean_absolute_error: 7.0582 - val_mean_squared_error: 229.9128 - val__pinball_loss: 3.0997\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3584 - mean_absolute_error: 5.3737 - mean_squared_error: 151.7175 - _pinball_loss: 2.3584 - val_loss: 3.1044 - val_mean_absolute_error: 7.0693 - val_mean_squared_error: 229.9257 - val__pinball_loss: 3.1044\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3531 - mean_absolute_error: 5.3639 - mean_squared_error: 151.4480 - _pinball_loss: 2.3531 - val_loss: 3.0968 - val_mean_absolute_error: 7.0303 - val_mean_squared_error: 227.0119 - val__pinball_loss: 3.0968\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3472 - mean_absolute_error: 5.3528 - mean_squared_error: 151.3601 - _pinball_loss: 2.3472 - val_loss: 3.0940 - val_mean_absolute_error: 6.9647 - val_mean_squared_error: 221.6072 - val__pinball_loss: 3.0940\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3459 - mean_absolute_error: 5.3502 - mean_squared_error: 151.3264 - _pinball_loss: 2.3459 - val_loss: 3.0954 - val_mean_absolute_error: 6.9804 - val_mean_squared_error: 223.3230 - val__pinball_loss: 3.0954\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3421 - mean_absolute_error: 5.3417 - mean_squared_error: 150.9249 - _pinball_loss: 2.3421 - val_loss: 3.0945 - val_mean_absolute_error: 7.0484 - val_mean_squared_error: 230.2435 - val__pinball_loss: 3.0945\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3393 - mean_absolute_error: 5.3349 - mean_squared_error: 150.8568 - _pinball_loss: 2.3393 - val_loss: 3.0874 - val_mean_absolute_error: 6.9954 - val_mean_squared_error: 225.5113 - val__pinball_loss: 3.0874\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3320 - mean_absolute_error: 5.3207 - mean_squared_error: 150.4929 - _pinball_loss: 2.3320 - val_loss: 3.0889 - val_mean_absolute_error: 6.9553 - val_mean_squared_error: 222.5559 - val__pinball_loss: 3.0889\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3305 - mean_absolute_error: 5.3140 - mean_squared_error: 150.1662 - _pinball_loss: 2.3305 - val_loss: 3.0829 - val_mean_absolute_error: 7.0094 - val_mean_squared_error: 227.6925 - val__pinball_loss: 3.0829\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3291 - mean_absolute_error: 5.3150 - mean_squared_error: 150.3583 - _pinball_loss: 2.3291 - val_loss: 3.0855 - val_mean_absolute_error: 6.9857 - val_mean_squared_error: 224.4976 - val__pinball_loss: 3.0855\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3272 - mean_absolute_error: 5.3131 - mean_squared_error: 150.5108 - _pinball_loss: 2.3272 - val_loss: 3.0803 - val_mean_absolute_error: 7.0090 - val_mean_squared_error: 228.1302 - val__pinball_loss: 3.0803\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.3209 - mean_absolute_error: 5.2988 - mean_squared_error: 150.1494 - _pinball_loss: 2.3209 - val_loss: 3.0938 - val_mean_absolute_error: 7.0924 - val_mean_squared_error: 233.7494 - val__pinball_loss: 3.0938\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3220 - mean_absolute_error: 5.3033 - mean_squared_error: 150.3547 - _pinball_loss: 2.3220 - val_loss: 3.0765 - val_mean_absolute_error: 7.0124 - val_mean_squared_error: 229.4479 - val__pinball_loss: 3.0765\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3189 - mean_absolute_error: 5.2952 - mean_squared_error: 149.9416 - _pinball_loss: 2.3189 - val_loss: 3.0778 - val_mean_absolute_error: 6.9486 - val_mean_squared_error: 222.0020 - val__pinball_loss: 3.0778\n",
      "Epoch 34/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3137 - mean_absolute_error: 5.2824 - mean_squared_error: 149.5148 - _pinball_loss: 2.3137 - val_loss: 3.0723 - val_mean_absolute_error: 6.9337 - val_mean_squared_error: 221.1833 - val__pinball_loss: 3.0723\n",
      "Epoch 35/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3177 - mean_absolute_error: 5.2916 - mean_squared_error: 149.9231 - _pinball_loss: 2.3177 - val_loss: 3.0786 - val_mean_absolute_error: 7.0149 - val_mean_squared_error: 228.5520 - val__pinball_loss: 3.0786\n",
      "Epoch 36/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3098 - mean_absolute_error: 5.2761 - mean_squared_error: 149.5862 - _pinball_loss: 2.3098 - val_loss: 3.0808 - val_mean_absolute_error: 6.9274 - val_mean_squared_error: 221.0998 - val__pinball_loss: 3.0808\n",
      "Epoch 37/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3067 - mean_absolute_error: 5.2683 - mean_squared_error: 149.2914 - _pinball_loss: 2.3067 - val_loss: 3.0734 - val_mean_absolute_error: 6.9744 - val_mean_squared_error: 225.6055 - val__pinball_loss: 3.0734\n",
      "Epoch 38/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3032 - mean_absolute_error: 5.2629 - mean_squared_error: 149.2941 - _pinball_loss: 2.3032 - val_loss: 3.0574 - val_mean_absolute_error: 6.9760 - val_mean_squared_error: 228.2921 - val__pinball_loss: 3.0574\n",
      "Epoch 39/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.2991 - mean_absolute_error: 5.2531 - mean_squared_error: 148.9344 - _pinball_loss: 2.2991 - val_loss: 3.0726 - val_mean_absolute_error: 6.9605 - val_mean_squared_error: 224.9098 - val__pinball_loss: 3.0726\n",
      "Epoch 40/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.3030 - mean_absolute_error: 5.2587 - mean_squared_error: 148.9371 - _pinball_loss: 2.3030 - val_loss: 3.0729 - val_mean_absolute_error: 6.9825 - val_mean_squared_error: 227.1525 - val__pinball_loss: 3.0729\n",
      "Epoch 41/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3019 - mean_absolute_error: 5.2578 - mean_squared_error: 149.0201 - _pinball_loss: 2.3019 - val_loss: 3.0799 - val_mean_absolute_error: 7.0493 - val_mean_squared_error: 232.7268 - val__pinball_loss: 3.0799\n",
      "Epoch 42/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 2.2999 - mean_absolute_error: 5.2532 - mean_squared_error: 148.6941 - _pinball_loss: 2.2999 - val_loss: 3.0688 - val_mean_absolute_error: 6.9667 - val_mean_squared_error: 225.5891 - val__pinball_loss: 3.0688\n",
      "Epoch 43/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.2947 - mean_absolute_error: 5.2441 - mean_squared_error: 148.5866 - _pinball_loss: 2.2947 - val_loss: 3.0656 - val_mean_absolute_error: 6.9794 - val_mean_squared_error: 226.5527 - val__pinball_loss: 3.0656\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023CCDBDC558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.7\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 6ms/step - loss: 4.8253 - mean_absolute_error: 10.3847 - mean_squared_error: 335.3254 - _pinball_loss: 4.8253 - val_loss: 2.9702 - val_mean_absolute_error: 8.1474 - val_mean_squared_error: 265.3786 - val__pinball_loss: 2.9702\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.3594 - mean_absolute_error: 6.5188 - mean_squared_error: 183.3015 - _pinball_loss: 2.3594 - val_loss: 2.8057 - val_mean_absolute_error: 7.7770 - val_mean_squared_error: 256.2453 - val__pinball_loss: 2.8057\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.2310 - mean_absolute_error: 6.2569 - mean_squared_error: 179.8236 - _pinball_loss: 2.2310 - val_loss: 2.7352 - val_mean_absolute_error: 7.6784 - val_mean_squared_error: 257.0540 - val__pinball_loss: 2.7352\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1701 - mean_absolute_error: 6.1368 - mean_squared_error: 178.9273 - _pinball_loss: 2.1701 - val_loss: 2.6922 - val_mean_absolute_error: 7.6566 - val_mean_squared_error: 258.9035 - val__pinball_loss: 2.6922\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.1285 - mean_absolute_error: 6.0605 - mean_squared_error: 178.6548 - _pinball_loss: 2.1285 - val_loss: 2.6698 - val_mean_absolute_error: 7.4679 - val_mean_squared_error: 250.5819 - val__pinball_loss: 2.6698\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.0995 - mean_absolute_error: 5.9977 - mean_squared_error: 177.6451 - _pinball_loss: 2.0995 - val_loss: 2.6427 - val_mean_absolute_error: 7.4525 - val_mean_squared_error: 252.4891 - val__pinball_loss: 2.6427\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.0767 - mean_absolute_error: 5.9558 - mean_squared_error: 177.3022 - _pinball_loss: 2.0767 - val_loss: 2.6314 - val_mean_absolute_error: 7.5009 - val_mean_squared_error: 257.9730 - val__pinball_loss: 2.6314\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.0565 - mean_absolute_error: 5.9152 - mean_squared_error: 177.2614 - _pinball_loss: 2.0565 - val_loss: 2.6198 - val_mean_absolute_error: 7.4517 - val_mean_squared_error: 254.9779 - val__pinball_loss: 2.6198\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.0421 - mean_absolute_error: 5.8858 - mean_squared_error: 176.8365 - _pinball_loss: 2.0421 - val_loss: 2.6163 - val_mean_absolute_error: 7.3821 - val_mean_squared_error: 253.4134 - val__pinball_loss: 2.6163\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 2.0307 - mean_absolute_error: 5.8591 - mean_squared_error: 176.3977 - _pinball_loss: 2.0307 - val_loss: 2.6109 - val_mean_absolute_error: 7.3268 - val_mean_squared_error: 249.4078 - val__pinball_loss: 2.6109\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.0196 - mean_absolute_error: 5.8338 - mean_squared_error: 176.1237 - _pinball_loss: 2.0196 - val_loss: 2.5933 - val_mean_absolute_error: 7.4894 - val_mean_squared_error: 259.3026 - val__pinball_loss: 2.5933\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 2.0088 - mean_absolute_error: 5.8217 - mean_squared_error: 176.4353 - _pinball_loss: 2.0088 - val_loss: 2.5897 - val_mean_absolute_error: 7.3072 - val_mean_squared_error: 248.7145 - val__pinball_loss: 2.5897\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9990 - mean_absolute_error: 5.8012 - mean_squared_error: 176.3427 - _pinball_loss: 1.9990 - val_loss: 2.5737 - val_mean_absolute_error: 7.4009 - val_mean_squared_error: 257.7604 - val__pinball_loss: 2.5737\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9929 - mean_absolute_error: 5.7861 - mean_squared_error: 175.9421 - _pinball_loss: 1.9929 - val_loss: 2.5753 - val_mean_absolute_error: 7.2602 - val_mean_squared_error: 249.8205 - val__pinball_loss: 2.5753\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9873 - mean_absolute_error: 5.7737 - mean_squared_error: 175.7180 - _pinball_loss: 1.9873 - val_loss: 2.5757 - val_mean_absolute_error: 7.3431 - val_mean_squared_error: 253.8774 - val__pinball_loss: 2.5757\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 1.9822 - mean_absolute_error: 5.7657 - mean_squared_error: 175.8032 - _pinball_loss: 1.9822 - val_loss: 2.5661 - val_mean_absolute_error: 7.2319 - val_mean_squared_error: 248.6701 - val__pinball_loss: 2.5661\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9742 - mean_absolute_error: 5.7471 - mean_squared_error: 175.5212 - _pinball_loss: 1.9742 - val_loss: 2.5623 - val_mean_absolute_error: 7.2933 - val_mean_squared_error: 252.9691 - val__pinball_loss: 2.5623\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9696 - mean_absolute_error: 5.7377 - mean_squared_error: 175.3342 - _pinball_loss: 1.9696 - val_loss: 2.5684 - val_mean_absolute_error: 7.2776 - val_mean_squared_error: 251.2486 - val__pinball_loss: 2.5684\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9648 - mean_absolute_error: 5.7275 - mean_squared_error: 175.1556 - _pinball_loss: 1.9648 - val_loss: 2.5560 - val_mean_absolute_error: 7.3812 - val_mean_squared_error: 259.6723 - val__pinball_loss: 2.5560\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9611 - mean_absolute_error: 5.7285 - mean_squared_error: 175.5301 - _pinball_loss: 1.9611 - val_loss: 2.5466 - val_mean_absolute_error: 7.3460 - val_mean_squared_error: 258.4442 - val__pinball_loss: 2.5466\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9561 - mean_absolute_error: 5.7108 - mean_squared_error: 175.0861 - _pinball_loss: 1.9561 - val_loss: 2.5534 - val_mean_absolute_error: 7.2382 - val_mean_squared_error: 250.2870 - val__pinball_loss: 2.5534\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9539 - mean_absolute_error: 5.7070 - mean_squared_error: 175.0099 - _pinball_loss: 1.9539 - val_loss: 2.5526 - val_mean_absolute_error: 7.2630 - val_mean_squared_error: 251.7115 - val__pinball_loss: 2.5526\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9482 - mean_absolute_error: 5.6958 - mean_squared_error: 174.9097 - _pinball_loss: 1.9482 - val_loss: 2.5477 - val_mean_absolute_error: 7.2686 - val_mean_squared_error: 254.0316 - val__pinball_loss: 2.5477\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9433 - mean_absolute_error: 5.6848 - mean_squared_error: 174.9087 - _pinball_loss: 1.9433 - val_loss: 2.5396 - val_mean_absolute_error: 7.3847 - val_mean_squared_error: 260.2413 - val__pinball_loss: 2.5396\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9413 - mean_absolute_error: 5.6804 - mean_squared_error: 174.6374 - _pinball_loss: 1.9413 - val_loss: 2.5377 - val_mean_absolute_error: 7.2625 - val_mean_squared_error: 252.6837 - val__pinball_loss: 2.5377\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9382 - mean_absolute_error: 5.6745 - mean_squared_error: 174.5023 - _pinball_loss: 1.9382 - val_loss: 2.5537 - val_mean_absolute_error: 7.2185 - val_mean_squared_error: 251.0840 - val__pinball_loss: 2.5537\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9373 - mean_absolute_error: 5.6685 - mean_squared_error: 174.2674 - _pinball_loss: 1.9373 - val_loss: 2.5400 - val_mean_absolute_error: 7.2849 - val_mean_squared_error: 256.4890 - val__pinball_loss: 2.5400\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9288 - mean_absolute_error: 5.6564 - mean_squared_error: 174.4404 - _pinball_loss: 1.9289 - val_loss: 2.5391 - val_mean_absolute_error: 7.2449 - val_mean_squared_error: 251.6037 - val__pinball_loss: 2.5391\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9281 - mean_absolute_error: 5.6529 - mean_squared_error: 174.2608 - _pinball_loss: 1.9281 - val_loss: 2.5348 - val_mean_absolute_error: 7.3418 - val_mean_squared_error: 259.2316 - val__pinball_loss: 2.5348\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9251 - mean_absolute_error: 5.6453 - mean_squared_error: 174.0438 - _pinball_loss: 1.9251 - val_loss: 2.5377 - val_mean_absolute_error: 7.2325 - val_mean_squared_error: 252.9648 - val__pinball_loss: 2.5377\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.9206 - mean_absolute_error: 5.6362 - mean_squared_error: 173.9396 - _pinball_loss: 1.9206 - val_loss: 2.5246 - val_mean_absolute_error: 7.2856 - val_mean_squared_error: 256.1162 - val__pinball_loss: 2.5246\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9210 - mean_absolute_error: 5.6411 - mean_squared_error: 174.4187 - _pinball_loss: 1.9210 - val_loss: 2.5364 - val_mean_absolute_error: 7.2461 - val_mean_squared_error: 252.3844 - val__pinball_loss: 2.5364\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9178 - mean_absolute_error: 5.6279 - mean_squared_error: 173.5398 - _pinball_loss: 1.9178 - val_loss: 2.5385 - val_mean_absolute_error: 7.2445 - val_mean_squared_error: 252.7520 - val__pinball_loss: 2.5385\n",
      "Epoch 34/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9157 - mean_absolute_error: 5.6273 - mean_squared_error: 173.9997 - _pinball_loss: 1.9157 - val_loss: 2.5325 - val_mean_absolute_error: 7.3281 - val_mean_squared_error: 257.6905 - val__pinball_loss: 2.5325\n",
      "Epoch 35/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.9136 - mean_absolute_error: 5.6241 - mean_squared_error: 173.8773 - _pinball_loss: 1.9136 - val_loss: 2.5293 - val_mean_absolute_error: 7.2126 - val_mean_squared_error: 251.3977 - val__pinball_loss: 2.5293\n",
      "Epoch 36/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 1.9125 - mean_absolute_error: 5.6155 - mean_squared_error: 173.4752 - _pinball_loss: 1.9125 - val_loss: 2.5314 - val_mean_absolute_error: 7.2325 - val_mean_squared_error: 252.5715 - val__pinball_loss: 2.5314\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023A7662DB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.8\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 4.5661 - mean_absolute_error: 11.9797 - mean_squared_error: 394.4670 - _pinball_loss: 4.5661 - val_loss: 2.3339 - val_mean_absolute_error: 9.4557 - val_mean_squared_error: 321.7967 - val__pinball_loss: 2.3339\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.8684 - mean_absolute_error: 7.4864 - mean_squared_error: 220.6693 - _pinball_loss: 1.8684 - val_loss: 2.1276 - val_mean_absolute_error: 8.6012 - val_mean_squared_error: 296.5224 - val__pinball_loss: 2.1276\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.7290 - mean_absolute_error: 7.0818 - mean_squared_error: 212.9647 - _pinball_loss: 1.7290 - val_loss: 2.0548 - val_mean_absolute_error: 8.4026 - val_mean_squared_error: 294.4483 - val__pinball_loss: 2.0548\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.6533 - mean_absolute_error: 6.8658 - mean_squared_error: 210.4080 - _pinball_loss: 1.6533 - val_loss: 2.0214 - val_mean_absolute_error: 8.3366 - val_mean_squared_error: 295.0234 - val__pinball_loss: 2.0214\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.6096 - mean_absolute_error: 6.7344 - mean_squared_error: 208.8945 - _pinball_loss: 1.6096 - val_loss: 1.9831 - val_mean_absolute_error: 8.1155 - val_mean_squared_error: 289.9330 - val__pinball_loss: 1.9831\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.5807 - mean_absolute_error: 6.6483 - mean_squared_error: 207.5994 - _pinball_loss: 1.5807 - val_loss: 1.9643 - val_mean_absolute_error: 8.1775 - val_mean_squared_error: 293.3318 - val__pinball_loss: 1.9643\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.5622 - mean_absolute_error: 6.6022 - mean_squared_error: 207.3427 - _pinball_loss: 1.5622 - val_loss: 1.9504 - val_mean_absolute_error: 8.1595 - val_mean_squared_error: 297.1472 - val__pinball_loss: 1.9504\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.5427 - mean_absolute_error: 6.5425 - mean_squared_error: 206.7998 - _pinball_loss: 1.5427 - val_loss: 1.9453 - val_mean_absolute_error: 8.2687 - val_mean_squared_error: 301.1149 - val__pinball_loss: 1.9453\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.5314 - mean_absolute_error: 6.5131 - mean_squared_error: 206.4921 - _pinball_loss: 1.5314 - val_loss: 1.9318 - val_mean_absolute_error: 8.0375 - val_mean_squared_error: 290.6401 - val__pinball_loss: 1.9318\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.5206 - mean_absolute_error: 6.4815 - mean_squared_error: 206.2628 - _pinball_loss: 1.5206 - val_loss: 1.9101 - val_mean_absolute_error: 7.9784 - val_mean_squared_error: 291.1465 - val__pinball_loss: 1.9101\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.5094 - mean_absolute_error: 6.4463 - mean_squared_error: 205.5314 - _pinball_loss: 1.5094 - val_loss: 1.9117 - val_mean_absolute_error: 8.1327 - val_mean_squared_error: 298.8298 - val__pinball_loss: 1.9117\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.5014 - mean_absolute_error: 6.4296 - mean_squared_error: 205.8037 - _pinball_loss: 1.5014 - val_loss: 1.9060 - val_mean_absolute_error: 7.9741 - val_mean_squared_error: 293.2993 - val__pinball_loss: 1.9060\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4914 - mean_absolute_error: 6.4000 - mean_squared_error: 205.3331 - _pinball_loss: 1.4914 - val_loss: 1.9045 - val_mean_absolute_error: 8.1733 - val_mean_squared_error: 303.5579 - val__pinball_loss: 1.9045\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4840 - mean_absolute_error: 6.3807 - mean_squared_error: 204.9584 - _pinball_loss: 1.4840 - val_loss: 1.8956 - val_mean_absolute_error: 7.9806 - val_mean_squared_error: 292.4808 - val__pinball_loss: 1.8956\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4779 - mean_absolute_error: 6.3625 - mean_squared_error: 204.8177 - _pinball_loss: 1.4779 - val_loss: 1.8842 - val_mean_absolute_error: 8.1041 - val_mean_squared_error: 301.1913 - val__pinball_loss: 1.8842\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4692 - mean_absolute_error: 6.3337 - mean_squared_error: 204.3457 - _pinball_loss: 1.4692 - val_loss: 1.8734 - val_mean_absolute_error: 7.9400 - val_mean_squared_error: 294.0505 - val__pinball_loss: 1.8734\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 1.4665 - mean_absolute_error: 6.3275 - mean_squared_error: 204.5786 - _pinball_loss: 1.4665 - val_loss: 1.8866 - val_mean_absolute_error: 8.1164 - val_mean_squared_error: 302.0226 - val__pinball_loss: 1.8866\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4607 - mean_absolute_error: 6.3144 - mean_squared_error: 204.5994 - _pinball_loss: 1.4607 - val_loss: 1.8747 - val_mean_absolute_error: 7.8063 - val_mean_squared_error: 289.7359 - val__pinball_loss: 1.8747\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4565 - mean_absolute_error: 6.2906 - mean_squared_error: 203.4128 - _pinball_loss: 1.4565 - val_loss: 1.8771 - val_mean_absolute_error: 8.0313 - val_mean_squared_error: 297.1671 - val__pinball_loss: 1.8771\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4527 - mean_absolute_error: 6.2896 - mean_squared_error: 203.8478 - _pinball_loss: 1.4527 - val_loss: 1.8891 - val_mean_absolute_error: 7.7820 - val_mean_squared_error: 284.7980 - val__pinball_loss: 1.8891\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4485 - mean_absolute_error: 6.2714 - mean_squared_error: 203.5212 - _pinball_loss: 1.4485 - val_loss: 1.8707 - val_mean_absolute_error: 8.0402 - val_mean_squared_error: 298.7165 - val__pinball_loss: 1.8707\n",
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4446 - mean_absolute_error: 6.2678 - mean_squared_error: 203.8067 - _pinball_loss: 1.4446 - val_loss: 1.8733 - val_mean_absolute_error: 7.8720 - val_mean_squared_error: 292.3827 - val__pinball_loss: 1.8733\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 1.4411 - mean_absolute_error: 6.2545 - mean_squared_error: 203.4179 - _pinball_loss: 1.4411 - val_loss: 1.8835 - val_mean_absolute_error: 8.1364 - val_mean_squared_error: 305.4902 - val__pinball_loss: 1.8835\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4386 - mean_absolute_error: 6.2516 - mean_squared_error: 203.7026 - _pinball_loss: 1.4386 - val_loss: 1.8655 - val_mean_absolute_error: 7.9227 - val_mean_squared_error: 294.1236 - val__pinball_loss: 1.8655\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4311 - mean_absolute_error: 6.2256 - mean_squared_error: 203.1059 - _pinball_loss: 1.4311 - val_loss: 1.8548 - val_mean_absolute_error: 8.0005 - val_mean_squared_error: 299.7334 - val__pinball_loss: 1.8548\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4303 - mean_absolute_error: 6.2296 - mean_squared_error: 203.3063 - _pinball_loss: 1.4303 - val_loss: 1.8642 - val_mean_absolute_error: 8.0597 - val_mean_squared_error: 300.5142 - val__pinball_loss: 1.8642\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4280 - mean_absolute_error: 6.2207 - mean_squared_error: 203.0228 - _pinball_loss: 1.4280 - val_loss: 1.8598 - val_mean_absolute_error: 8.0822 - val_mean_squared_error: 303.4782 - val__pinball_loss: 1.8598\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4229 - mean_absolute_error: 6.2079 - mean_squared_error: 202.6780 - _pinball_loss: 1.4229 - val_loss: 1.8477 - val_mean_absolute_error: 7.8282 - val_mean_squared_error: 293.4402 - val__pinball_loss: 1.8477\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4191 - mean_absolute_error: 6.1889 - mean_squared_error: 202.3613 - _pinball_loss: 1.4191 - val_loss: 1.8756 - val_mean_absolute_error: 8.1805 - val_mean_squared_error: 306.1193 - val__pinball_loss: 1.8756\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4208 - mean_absolute_error: 6.2039 - mean_squared_error: 203.0249 - _pinball_loss: 1.4208 - val_loss: 1.8708 - val_mean_absolute_error: 8.1250 - val_mean_squared_error: 305.5085 - val__pinball_loss: 1.8708\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4152 - mean_absolute_error: 6.1825 - mean_squared_error: 202.5271 - _pinball_loss: 1.4152 - val_loss: 1.8535 - val_mean_absolute_error: 7.9449 - val_mean_squared_error: 297.1812 - val__pinball_loss: 1.8535\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4115 - mean_absolute_error: 6.1727 - mean_squared_error: 202.4008 - _pinball_loss: 1.4115 - val_loss: 1.8581 - val_mean_absolute_error: 7.7200 - val_mean_squared_error: 285.9398 - val__pinball_loss: 1.8581\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4118 - mean_absolute_error: 6.1720 - mean_squared_error: 202.5030 - _pinball_loss: 1.4118 - val_loss: 1.8425 - val_mean_absolute_error: 8.0968 - val_mean_squared_error: 307.0989 - val__pinball_loss: 1.8425\n",
      "Epoch 34/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.4079 - mean_absolute_error: 6.1667 - mean_squared_error: 202.6934 - _pinball_loss: 1.4079 - val_loss: 1.8509 - val_mean_absolute_error: 7.8191 - val_mean_squared_error: 291.7192 - val__pinball_loss: 1.8509\n",
      "Epoch 35/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4048 - mean_absolute_error: 6.1530 - mean_squared_error: 202.2126 - _pinball_loss: 1.4048 - val_loss: 1.8655 - val_mean_absolute_error: 7.6813 - val_mean_squared_error: 283.5408 - val__pinball_loss: 1.8655\n",
      "Epoch 36/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 1.4046 - mean_absolute_error: 6.1478 - mean_squared_error: 202.1342 - _pinball_loss: 1.4046 - val_loss: 1.8440 - val_mean_absolute_error: 7.9514 - val_mean_squared_error: 298.4974 - val__pinball_loss: 1.8440\n",
      "Epoch 37/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4011 - mean_absolute_error: 6.1414 - mean_squared_error: 202.0153 - _pinball_loss: 1.4011 - val_loss: 1.8386 - val_mean_absolute_error: 8.1269 - val_mean_squared_error: 307.9456 - val__pinball_loss: 1.8386\n",
      "Epoch 38/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.4006 - mean_absolute_error: 6.1458 - mean_squared_error: 202.4118 - _pinball_loss: 1.4006 - val_loss: 1.8321 - val_mean_absolute_error: 7.7872 - val_mean_squared_error: 292.0651 - val__pinball_loss: 1.8321\n",
      "Epoch 39/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.3965 - mean_absolute_error: 6.1267 - mean_squared_error: 201.6282 - _pinball_loss: 1.3965 - val_loss: 1.8313 - val_mean_absolute_error: 7.9482 - val_mean_squared_error: 299.8759 - val__pinball_loss: 1.8313\n",
      "Epoch 40/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3947 - mean_absolute_error: 6.1265 - mean_squared_error: 202.0591 - _pinball_loss: 1.3947 - val_loss: 1.8301 - val_mean_absolute_error: 7.7445 - val_mean_squared_error: 290.5064 - val__pinball_loss: 1.8301\n",
      "Epoch 41/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 1.3929 - mean_absolute_error: 6.1125 - mean_squared_error: 201.2648 - _pinball_loss: 1.3929 - val_loss: 1.8334 - val_mean_absolute_error: 7.7918 - val_mean_squared_error: 291.8756 - val__pinball_loss: 1.8334\n",
      "Epoch 42/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3891 - mean_absolute_error: 6.1007 - mean_squared_error: 201.3390 - _pinball_loss: 1.3891 - val_loss: 1.8457 - val_mean_absolute_error: 7.8103 - val_mean_squared_error: 290.2631 - val__pinball_loss: 1.8457\n",
      "Epoch 43/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3901 - mean_absolute_error: 6.1050 - mean_squared_error: 201.4962 - _pinball_loss: 1.3901 - val_loss: 1.8217 - val_mean_absolute_error: 7.8715 - val_mean_squared_error: 297.1280 - val__pinball_loss: 1.8217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3864 - mean_absolute_error: 6.0928 - mean_squared_error: 201.2193 - _pinball_loss: 1.3864 - val_loss: 1.8303 - val_mean_absolute_error: 7.9188 - val_mean_squared_error: 298.1212 - val__pinball_loss: 1.8303\n",
      "Epoch 45/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 1.3848 - mean_absolute_error: 6.0971 - mean_squared_error: 201.7798 - _pinball_loss: 1.3848 - val_loss: 1.8328 - val_mean_absolute_error: 7.7192 - val_mean_squared_error: 290.0334 - val__pinball_loss: 1.8328\n",
      "Epoch 46/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3839 - mean_absolute_error: 6.0812 - mean_squared_error: 200.8480 - _pinball_loss: 1.3839 - val_loss: 1.8265 - val_mean_absolute_error: 7.7721 - val_mean_squared_error: 292.0384 - val__pinball_loss: 1.8265\n",
      "Epoch 47/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3798 - mean_absolute_error: 6.0740 - mean_squared_error: 201.0116 - _pinball_loss: 1.3798 - val_loss: 1.8295 - val_mean_absolute_error: 7.9733 - val_mean_squared_error: 300.7301 - val__pinball_loss: 1.8295\n",
      "Epoch 48/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.3817 - mean_absolute_error: 6.0799 - mean_squared_error: 201.0406 - _pinball_loss: 1.3817 - val_loss: 1.8303 - val_mean_absolute_error: 7.9506 - val_mean_squared_error: 299.1167 - val__pinball_loss: 1.8303\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023AA504DB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.9\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 4.2155 - mean_absolute_error: 16.4525 - mean_squared_error: 601.3465 - _pinball_loss: 4.2155 - val_loss: 1.4547 - val_mean_absolute_error: 11.1815 - val_mean_squared_error: 392.3055 - val__pinball_loss: 1.4547\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 1.1798 - mean_absolute_error: 9.4890 - mean_squared_error: 290.2126 - _pinball_loss: 1.1798 - val_loss: 1.3150 - val_mean_absolute_error: 10.0443 - val_mean_squared_error: 352.6508 - val__pinball_loss: 1.3150\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.0682 - mean_absolute_error: 8.7527 - mean_squared_error: 269.3815 - _pinball_loss: 1.0682 - val_loss: 1.2572 - val_mean_absolute_error: 10.0180 - val_mean_squared_error: 352.3800 - val__pinball_loss: 1.2572\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 1.0134 - mean_absolute_error: 8.3968 - mean_squared_error: 261.4928 - _pinball_loss: 1.0134 - val_loss: 1.2177 - val_mean_absolute_error: 9.8076 - val_mean_squared_error: 348.3845 - val__pinball_loss: 1.2177\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.9805 - mean_absolute_error: 8.2008 - mean_squared_error: 257.2346 - _pinball_loss: 0.9805 - val_loss: 1.1873 - val_mean_absolute_error: 9.5847 - val_mean_squared_error: 347.3820 - val__pinball_loss: 1.1873\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.9544 - mean_absolute_error: 8.0241 - mean_squared_error: 253.5887 - _pinball_loss: 0.9544 - val_loss: 1.1794 - val_mean_absolute_error: 9.2067 - val_mean_squared_error: 329.4076 - val__pinball_loss: 1.1794\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 7s 7ms/step - loss: 0.9371 - mean_absolute_error: 7.9127 - mean_squared_error: 251.2519 - _pinball_loss: 0.9371 - val_loss: 1.1676 - val_mean_absolute_error: 8.9502 - val_mean_squared_error: 324.8600 - val__pinball_loss: 1.1676\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.9207 - mean_absolute_error: 7.7994 - mean_squared_error: 249.1973 - _pinball_loss: 0.9207 - val_loss: 1.1479 - val_mean_absolute_error: 9.0761 - val_mean_squared_error: 330.8630 - val__pinball_loss: 1.1479\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.9085 - mean_absolute_error: 7.7344 - mean_squared_error: 248.1019 - _pinball_loss: 0.9085 - val_loss: 1.1319 - val_mean_absolute_error: 9.2201 - val_mean_squared_error: 341.4067 - val__pinball_loss: 1.1319\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8970 - mean_absolute_error: 7.6642 - mean_squared_error: 247.0403 - _pinball_loss: 0.8970 - val_loss: 1.1418 - val_mean_absolute_error: 8.9095 - val_mean_squared_error: 326.9918 - val__pinball_loss: 1.1418\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8895 - mean_absolute_error: 7.6097 - mean_squared_error: 245.4614 - _pinball_loss: 0.8895 - val_loss: 1.1123 - val_mean_absolute_error: 9.3337 - val_mean_squared_error: 347.6111 - val__pinball_loss: 1.1123\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8840 - mean_absolute_error: 7.5911 - mean_squared_error: 245.6983 - _pinball_loss: 0.8840 - val_loss: 1.1071 - val_mean_absolute_error: 9.3811 - val_mean_squared_error: 351.1689 - val__pinball_loss: 1.1071\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8743 - mean_absolute_error: 7.5330 - mean_squared_error: 244.6762 - _pinball_loss: 0.8743 - val_loss: 1.1162 - val_mean_absolute_error: 9.1417 - val_mean_squared_error: 338.6330 - val__pinball_loss: 1.1162\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8692 - mean_absolute_error: 7.5002 - mean_squared_error: 244.0962 - _pinball_loss: 0.8692 - val_loss: 1.1307 - val_mean_absolute_error: 8.9364 - val_mean_squared_error: 331.0188 - val__pinball_loss: 1.1307\n",
      "Epoch 15/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8651 - mean_absolute_error: 7.4676 - mean_squared_error: 243.0061 - _pinball_loss: 0.8651 - val_loss: 1.0992 - val_mean_absolute_error: 9.2886 - val_mean_squared_error: 348.0543 - val__pinball_loss: 1.0992\n",
      "Epoch 16/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8584 - mean_absolute_error: 7.4313 - mean_squared_error: 242.3459 - _pinball_loss: 0.8584 - val_loss: 1.0902 - val_mean_absolute_error: 9.0138 - val_mean_squared_error: 337.8406 - val__pinball_loss: 1.0902\n",
      "Epoch 17/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8519 - mean_absolute_error: 7.3922 - mean_squared_error: 241.8321 - _pinball_loss: 0.8519 - val_loss: 1.1066 - val_mean_absolute_error: 8.8983 - val_mean_squared_error: 330.2593 - val__pinball_loss: 1.1066\n",
      "Epoch 18/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8513 - mean_absolute_error: 7.3888 - mean_squared_error: 241.8340 - _pinball_loss: 0.8513 - val_loss: 1.1129 - val_mean_absolute_error: 8.9355 - val_mean_squared_error: 332.4478 - val__pinball_loss: 1.1129\n",
      "Epoch 19/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8469 - mean_absolute_error: 7.3550 - mean_squared_error: 241.3208 - _pinball_loss: 0.8469 - val_loss: 1.0973 - val_mean_absolute_error: 9.3708 - val_mean_squared_error: 352.5347 - val__pinball_loss: 1.0973\n",
      "Epoch 20/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8422 - mean_absolute_error: 7.3328 - mean_squared_error: 240.6761 - _pinball_loss: 0.8422 - val_loss: 1.0798 - val_mean_absolute_error: 8.8760 - val_mean_squared_error: 338.0331 - val__pinball_loss: 1.0798\n",
      "Epoch 21/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8374 - mean_absolute_error: 7.2960 - mean_squared_error: 239.9299 - _pinball_loss: 0.8374 - val_loss: 1.0781 - val_mean_absolute_error: 8.9106 - val_mean_squared_error: 335.7822 - val__pinball_loss: 1.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8338 - mean_absolute_error: 7.2680 - mean_squared_error: 239.4068 - _pinball_loss: 0.8338 - val_loss: 1.0733 - val_mean_absolute_error: 8.8934 - val_mean_squared_error: 337.8684 - val__pinball_loss: 1.0733\n",
      "Epoch 23/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8310 - mean_absolute_error: 7.2548 - mean_squared_error: 239.4357 - _pinball_loss: 0.8310 - val_loss: 1.0827 - val_mean_absolute_error: 8.8434 - val_mean_squared_error: 332.2170 - val__pinball_loss: 1.0827\n",
      "Epoch 24/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8293 - mean_absolute_error: 7.2448 - mean_squared_error: 239.1191 - _pinball_loss: 0.8293 - val_loss: 1.0728 - val_mean_absolute_error: 8.7734 - val_mean_squared_error: 331.5699 - val__pinball_loss: 1.0728\n",
      "Epoch 25/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8274 - mean_absolute_error: 7.2356 - mean_squared_error: 238.8267 - _pinball_loss: 0.8274 - val_loss: 1.0965 - val_mean_absolute_error: 8.5313 - val_mean_squared_error: 318.8289 - val__pinball_loss: 1.0965\n",
      "Epoch 26/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8256 - mean_absolute_error: 7.2097 - mean_squared_error: 238.1264 - _pinball_loss: 0.8256 - val_loss: 1.0757 - val_mean_absolute_error: 8.9134 - val_mean_squared_error: 333.9277 - val__pinball_loss: 1.0757\n",
      "Epoch 27/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8225 - mean_absolute_error: 7.1981 - mean_squared_error: 238.0299 - _pinball_loss: 0.8225 - val_loss: 1.0669 - val_mean_absolute_error: 8.7558 - val_mean_squared_error: 332.1689 - val__pinball_loss: 1.0669\n",
      "Epoch 28/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8205 - mean_absolute_error: 7.1855 - mean_squared_error: 237.9278 - _pinball_loss: 0.8205 - val_loss: 1.0733 - val_mean_absolute_error: 8.6896 - val_mean_squared_error: 326.3497 - val__pinball_loss: 1.0733\n",
      "Epoch 29/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8192 - mean_absolute_error: 7.1838 - mean_squared_error: 238.1698 - _pinball_loss: 0.8192 - val_loss: 1.0671 - val_mean_absolute_error: 8.9613 - val_mean_squared_error: 340.0320 - val__pinball_loss: 1.0671\n",
      "Epoch 30/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8169 - mean_absolute_error: 7.1708 - mean_squared_error: 237.9653 - _pinball_loss: 0.8169 - val_loss: 1.0775 - val_mean_absolute_error: 8.8225 - val_mean_squared_error: 332.1131 - val__pinball_loss: 1.0775\n",
      "Epoch 31/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8128 - mean_absolute_error: 7.1430 - mean_squared_error: 237.3657 - _pinball_loss: 0.8128 - val_loss: 1.0631 - val_mean_absolute_error: 8.7246 - val_mean_squared_error: 328.7245 - val__pinball_loss: 1.0631\n",
      "Epoch 32/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8123 - mean_absolute_error: 7.1393 - mean_squared_error: 237.3837 - _pinball_loss: 0.8123 - val_loss: 1.0569 - val_mean_absolute_error: 8.7909 - val_mean_squared_error: 334.7511 - val__pinball_loss: 1.0569\n",
      "Epoch 33/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8092 - mean_absolute_error: 7.1239 - mean_squared_error: 236.9446 - _pinball_loss: 0.8092 - val_loss: 1.0711 - val_mean_absolute_error: 8.6107 - val_mean_squared_error: 327.6162 - val__pinball_loss: 1.0711\n",
      "Epoch 34/1000\n",
      "1146/1146 [==============================] - 8s 7ms/step - loss: 0.8086 - mean_absolute_error: 7.1088 - mean_squared_error: 236.2543 - _pinball_loss: 0.8086 - val_loss: 1.0547 - val_mean_absolute_error: 8.7945 - val_mean_squared_error: 336.9688 - val__pinball_loss: 1.0547\n",
      "Epoch 35/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8063 - mean_absolute_error: 7.1018 - mean_squared_error: 236.7121 - _pinball_loss: 0.8063 - val_loss: 1.0619 - val_mean_absolute_error: 8.5489 - val_mean_squared_error: 326.2249 - val__pinball_loss: 1.0619\n",
      "Epoch 36/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8058 - mean_absolute_error: 7.1042 - mean_squared_error: 237.0261 - _pinball_loss: 0.8058 - val_loss: 1.0567 - val_mean_absolute_error: 8.7817 - val_mean_squared_error: 333.0986 - val__pinball_loss: 1.0567\n",
      "Epoch 37/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8033 - mean_absolute_error: 7.0820 - mean_squared_error: 235.9129 - _pinball_loss: 0.8033 - val_loss: 1.0511 - val_mean_absolute_error: 8.8538 - val_mean_squared_error: 339.1321 - val__pinball_loss: 1.0511\n",
      "Epoch 38/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8033 - mean_absolute_error: 7.0850 - mean_squared_error: 236.3965 - _pinball_loss: 0.8033 - val_loss: 1.0540 - val_mean_absolute_error: 8.7733 - val_mean_squared_error: 334.4746 - val__pinball_loss: 1.0540\n",
      "Epoch 39/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8002 - mean_absolute_error: 7.0677 - mean_squared_error: 235.6233 - _pinball_loss: 0.8002 - val_loss: 1.0564 - val_mean_absolute_error: 8.5839 - val_mean_squared_error: 327.0659 - val__pinball_loss: 1.0564\n",
      "Epoch 40/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.8000 - mean_absolute_error: 7.0616 - mean_squared_error: 235.6953 - _pinball_loss: 0.8000 - val_loss: 1.0547 - val_mean_absolute_error: 8.8412 - val_mean_squared_error: 335.9016 - val__pinball_loss: 1.0547\n",
      "Epoch 41/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.7975 - mean_absolute_error: 7.0417 - mean_squared_error: 235.4033 - _pinball_loss: 0.7975 - val_loss: 1.0570 - val_mean_absolute_error: 8.7145 - val_mean_squared_error: 334.4561 - val__pinball_loss: 1.0570\n",
      "Epoch 42/1000\n",
      "1146/1146 [==============================] - 7s 6ms/step - loss: 0.7965 - mean_absolute_error: 7.0303 - mean_squared_error: 234.7562 - _pinball_loss: 0.7965 - val_loss: 1.0525 - val_mean_absolute_error: 8.8254 - val_mean_squared_error: 335.7243 - val__pinball_loss: 1.0525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023A76D9F708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "\n",
    "from src.model.multiple_output.convolution import ConvolutionVariousSmall\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "\n",
    "ONE_DAY_STEPS=48\n",
    "OUTPUT_STEPS=96\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS * 1,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * 1)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    print(q)\n",
    "    \n",
    "    conv_various_small = ConvolutionVariousSmall(48)\n",
    "\n",
    "    compile_and_fit_with_pinball_loss(conv_various_small, one_days_window_label_columns, q)\n",
    "    evaluate_dict[q] = conv_various_small.evaluate(one_days_window_label_columns.test, verbose=0)\n",
    "    predict_np = predict_df.reshape(-1, 48, 7)\n",
    "    pred_y = conv_various_small.predict(predict_np)[:, :, -1]\n",
    "    submission_df[f\"q_{q}\"] = pred_y.reshape(-1)\n",
    "\n",
    "s = 0\n",
    "for index, value in evaluate_dict.items():\n",
    "    s += value[0]\n",
    "s / 10\n",
    "\n",
    "to_submission_csv(submission_df, \"conv_various_small_dhi_dni_ghi_standard_scaled_n_minmaxed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for index, value in evaluate_dict.items():\n",
    "    s += value[0]\n",
    "s / 10\n",
    "\n",
    "submission_df.to_csv('conv_various_small_using_dhi_dni_ghi_standard_scaled_n_minmaxed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio should be 3 length list, example: [0.6, 0.3, 0.1]\n",
      "sum of ration should be 1, example: [0.7, 0.2, 0.1]\n",
      "shape of train, valid, test: (36792, 17), (10511, 17), (5257, 17)\n",
      "Epoch 1/1000\n",
      "1146/1146 [==============================] - 13s 11ms/step - loss: 1.7452 - mean_absolute_error: 17.4503 - mean_squared_error: 952.7478 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7931\n",
      "Epoch 2/1000\n",
      "1146/1146 [==============================] - 12s 10ms/step - loss: 1.7446 - mean_absolute_error: 17.4460 - mean_squared_error: 952.5681 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7924\n",
      "Epoch 3/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7446 - mean_absolute_error: 17.4463 - mean_squared_error: 952.4923 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7914\n",
      "Epoch 4/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7449 - mean_absolute_error: 17.4487 - mean_squared_error: 952.6843 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7925\n",
      "Epoch 5/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7446 - mean_absolute_error: 17.4459 - mean_squared_error: 952.4358 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7930\n",
      "Epoch 6/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7442 - mean_absolute_error: 17.4420 - mean_squared_error: 952.1719 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7916\n",
      "Epoch 7/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7451 - mean_absolute_error: 17.4506 - mean_squared_error: 952.8467 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7932\n",
      "Epoch 8/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7443 - mean_absolute_error: 17.4426 - mean_squared_error: 952.2316 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7925\n",
      "Epoch 9/1000\n",
      "1146/1146 [==============================] - 12s 10ms/step - loss: 1.7443 - mean_absolute_error: 17.4434 - mean_squared_error: 952.2612 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7919\n",
      "Epoch 10/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7451 - mean_absolute_error: 17.4512 - mean_squared_error: 952.8843 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7926\n",
      "Epoch 11/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7440 - mean_absolute_error: 17.4397 - mean_squared_error: 952.0532 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7922\n",
      "Epoch 12/1000\n",
      "1146/1146 [==============================] - 11s 10ms/step - loss: 1.7445 - mean_absolute_error: 17.4450 - mean_squared_error: 952.4180 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7924\n",
      "Epoch 13/1000\n",
      "1146/1146 [==============================] - 12s 10ms/step - loss: 1.7441 - mean_absolute_error: 17.4409 - mean_squared_error: 952.0380 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7922\n",
      "Epoch 14/1000\n",
      "1146/1146 [==============================] - 12s 10ms/step - loss: 1.7440 - mean_absolute_error: 17.4401 - mean_squared_error: 951.9458 - val_loss: 2.1811 - val_mean_absolute_error: 21.8107 - val_mean_squared_error: 1310.7936\n"
     ]
    }
   ],
   "source": [
    "import src.model.multiple_output.convolution\n",
    "import src.trainers\n",
    "import importlib\n",
    "importlib.reload(src.model.multiple_output.convolution)\n",
    "importlib.reload(src.trainers)\n",
    "\n",
    "from src.model.multiple_output.convolution import ConvolutionVariousSmallReturnOnce\n",
    "from src.loaders.data_loader import load_test_features, load_basic_preprocessed_predict\n",
    "from src.trainers import compile_and_fit_with_pinball_loss_once\n",
    "\n",
    "ONE_DAY_STEPS=48\n",
    "OUTPUT_STEPS=96\n",
    "\n",
    "one_days_window_label_columns = WindowGenerator(\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    test_df,\n",
    "    input_width=ONE_DAY_STEPS * 1,\n",
    "    label_width=OUTPUT_STEPS,\n",
    "    shift=OUTPUT_STEPS,\n",
    "    label_columns=[\"TARGET\"]\n",
    ")\n",
    "submission_df = load_submission_data()\n",
    "_, predict_df = load_basic_preprocessed_predict()\n",
    "predict_df[\"scaled_TARGET\"] = predict_df[\"TARGET\"]\n",
    "predict_df = predict_df[cutter]\n",
    "predict_df.drop(\"TARGET\", axis=1, inplace=True)\n",
    "predict_df = load_test_features(predict_df, 48 * 1)\n",
    "\n",
    "evaluate_dict = {}\n",
    "\n",
    "    \n",
    "conv_various_small_return_once = ConvolutionVariousSmallReturnOnce(48)\n",
    "\n",
    "compile_and_fit_with_pinball_loss_once(conv_various_small_return_once, one_days_window_label_columns)\n",
    "predict_np = predict_df.reshape(-1, 48, 7)\n",
    "pred_y = conv_various_small_return_once.predict(predict_np)[:, :, -1]\n",
    "\n",
    "\n",
    "to_submission_csv(submission_df, \"conv_various_small_return_once_dhi_dni_ghi_standard_scaled_n_minmaxed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 96, 9)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_np = predict_df.reshape(-1, 48, 7)\n",
    "pred_y = conv_various_small_return_once.predict(predict_np)\n",
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('conv_various_small_return_once_using_dhi_dni_ghi_standard_scaled_n_minmaxed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.012439</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>-0.073527</td>\n",
       "      <td>-0.029060</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>0.224904</td>\n",
       "      <td>-0.143813</td>\n",
       "      <td>0.014173</td>\n",
       "      <td>0.405526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>-0.063830</td>\n",
       "      <td>0.038834</td>\n",
       "      <td>-0.032453</td>\n",
       "      <td>0.041972</td>\n",
       "      <td>0.141368</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>-0.017666</td>\n",
       "      <td>0.317269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.006193</td>\n",
       "      <td>-0.056022</td>\n",
       "      <td>-0.039268</td>\n",
       "      <td>-0.032808</td>\n",
       "      <td>0.122649</td>\n",
       "      <td>0.190037</td>\n",
       "      <td>-0.072631</td>\n",
       "      <td>0.082722</td>\n",
       "      <td>0.417650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.046119</td>\n",
       "      <td>-0.167568</td>\n",
       "      <td>-0.084419</td>\n",
       "      <td>0.111410</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>0.118749</td>\n",
       "      <td>-0.028045</td>\n",
       "      <td>0.034287</td>\n",
       "      <td>0.357527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.013862</td>\n",
       "      <td>-0.053064</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>0.300753</td>\n",
       "      <td>-0.112016</td>\n",
       "      <td>0.138389</td>\n",
       "      <td>0.208718</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>0.835670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>-0.046949</td>\n",
       "      <td>-0.060607</td>\n",
       "      <td>-0.158245</td>\n",
       "      <td>-0.130741</td>\n",
       "      <td>-0.269549</td>\n",
       "      <td>0.137537</td>\n",
       "      <td>-0.171087</td>\n",
       "      <td>0.378671</td>\n",
       "      <td>0.306352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>-0.047090</td>\n",
       "      <td>-0.069049</td>\n",
       "      <td>-0.033668</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>-0.285276</td>\n",
       "      <td>0.398138</td>\n",
       "      <td>0.050684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>-0.063624</td>\n",
       "      <td>-0.012024</td>\n",
       "      <td>-0.023656</td>\n",
       "      <td>0.049942</td>\n",
       "      <td>0.100720</td>\n",
       "      <td>-0.021225</td>\n",
       "      <td>-0.084797</td>\n",
       "      <td>0.152913</td>\n",
       "      <td>0.237711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.051610</td>\n",
       "      <td>-0.072732</td>\n",
       "      <td>0.168911</td>\n",
       "      <td>-0.078392</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.093835</td>\n",
       "      <td>-0.077666</td>\n",
       "      <td>0.315724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>0.017110</td>\n",
       "      <td>-0.025213</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>0.152653</td>\n",
       "      <td>0.059267</td>\n",
       "      <td>0.117831</td>\n",
       "      <td>0.075108</td>\n",
       "      <td>-0.172803</td>\n",
       "      <td>0.250365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     q_0.1     q_0.2     q_0.3     q_0.4     q_0.5  \\\n",
       "0       0.csv_Day7_0h00m -0.012439 -0.011767 -0.073527 -0.029060  0.033504   \n",
       "1       0.csv_Day7_0h30m  0.006988 -0.063830  0.038834 -0.032453  0.041972   \n",
       "2       0.csv_Day7_1h00m -0.006193 -0.056022 -0.039268 -0.032808  0.122649   \n",
       "3       0.csv_Day7_1h30m -0.046119 -0.167568 -0.084419  0.111410 -0.012235   \n",
       "4       0.csv_Day7_2h00m  0.013862 -0.053064 -0.006279  0.300753 -0.112016   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "7771  80.csv_Day8_21h30m -0.046949 -0.060607 -0.158245 -0.130741 -0.269549   \n",
       "7772  80.csv_Day8_22h00m -0.004267 -0.047090 -0.069049 -0.033668 -0.019169   \n",
       "7773  80.csv_Day8_22h30m -0.063624 -0.012024 -0.023656  0.049942  0.100720   \n",
       "7774  80.csv_Day8_23h00m -0.005158 -0.051610 -0.072732  0.168911 -0.078392   \n",
       "7775  80.csv_Day8_23h30m  0.017110 -0.025213  0.015386  0.152653  0.059267   \n",
       "\n",
       "         q_0.6     q_0.7     q_0.8     q_0.9  \n",
       "0     0.224904 -0.143813  0.014173  0.405526  \n",
       "1     0.141368 -0.001862 -0.017666  0.317269  \n",
       "2     0.190037 -0.072631  0.082722  0.417650  \n",
       "3     0.118749 -0.028045  0.034287  0.357527  \n",
       "4     0.138389  0.208718  0.022814  0.835670  \n",
       "...        ...       ...       ...       ...  \n",
       "7771  0.137537 -0.171087  0.378671  0.306352  \n",
       "7772  0.066999 -0.285276  0.398138  0.050684  \n",
       "7773 -0.021225 -0.084797  0.152913  0.237711  \n",
       "7774  0.033603  0.093835 -0.077666  0.315724  \n",
       "7775  0.117831  0.075108 -0.172803  0.250365  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.read_csv('data/submission_history/conv_various_2_using_dhi_dni_ghi_standard_scaled_n_minmaxed.csv')\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bees1\\anaconda3\\envs\\dacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  q_0.1  q_0.2  q_0.3  q_0.4  q_0.5  q_0.6  q_0.7  \\\n",
       "0       0.csv_Day7_0h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.csv_Day7_0h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.csv_Day7_1h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.csv_Day7_1h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.csv_Day7_2h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...                  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7771  80.csv_Day8_21h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7772  80.csv_Day8_22h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7773  80.csv_Day8_22h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7774  80.csv_Day8_23h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7775  80.csv_Day8_23h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      q_0.8  q_0.9  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "...     ...    ...  \n",
       "7771    0.0    0.0  \n",
       "7772    0.0    0.0  \n",
       "7773    0.0    0.0  \n",
       "7774    0.0    0.0  \n",
       "7775    0.0    0.0  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    q = i/10\n",
    "    submission_df[f\"q_{q}\"][submission_df[f\"q_{q}\"] < 1] = 0\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('conv_various_2_using_dhi_dni_ghi_standard_scaled_n_minmaxed_smaller_than_1_zero.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (dacon)",
   "language": "python",
   "name": "pycharm-549c67b6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
